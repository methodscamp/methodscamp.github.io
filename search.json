[
  {
    "objectID": "index.html#class-schedule",
    "href": "index.html#class-schedule",
    "title": "Methods Camp",
    "section": "Class schedule",
    "text": "Class schedule\n\n\n\nDate\nTime\nLocation\n\n\n\n\nThurs, Aug. 10\n9:00 AM - 4:00 PM\nRLP 1.302D\n\n\nFri, Aug. 11\n9:00 AM - 4:00 PM\nRLP 1.302E\n\n\nSat, Aug. 12\nNo class\n-\n\n\nSun, Aug. 13\nNo class\n-\n\n\nMon, Aug. 14\n9:00 AM - 4:00 PM\nRLP 1.302E\n\n\nTues, Aug. 15\n9:00 AM - 4:00 PM\nRLP 1.302E\n\n\nWeds, Aug. 16\n9:00 AM - 4:00 PM\nRLP 1.302E\n\n\n\nOn class days, we will have a lunch break from 12:00-1:00 PM. We’ll also take short breaks periodically during the morning and afternoon sessions as needed."
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "Methods Camp",
    "section": "Description",
    "text": "Description\nWelcome to Introduction to Methods for Political Science, aka “Methods Camp”! In the past our incoming students have told us their math skills are rusty and they would like to be better prepared for UT’s methods courses. Methods Camp is designed to give everyone a chance to brush up on some skills in preparation for the Stats I and Formal Theory I courses. The other goal of Methods Camp is to allow you to get to know your cohort. We hope that struggling with matrix algebra and the dreaded chain rule will still prove to be a good bonding exercise.\nAs you can see from the above schedule, we’ll be meeting on Thursday, August 10th and Friday, August 11th as well as from Monday, August 14th through Wednesday, August 16th. Classes at UT begin the start of the following week on Monday, August 22nd. Below is a tentaive schedule outlining what will be covered in the class, although we may rearrange things a bit if we find we’re going too slowly or too quickly through any of the material."
  },
  {
    "objectID": "index.html#course-outline",
    "href": "index.html#course-outline",
    "title": "Methods Camp",
    "section": "Course outline",
    "text": "Course outline\n1 Thursday morning: R and RStudio\n\nIntroductions\nRStudio (materials are on the website as zipped RStudio projects)\nObjects (vectors, matrices, data frames)\nBasic functions (mean(), length(), etc.)\n\n2 Thursday afternoon: tidyverse basics I\n\nPackages: installation and loading (including the tidyverse)\nData wrangling with dplyr (basic verbs, including the new .by = syntax)\nData visualization basics with ggplot2\nData loading (.csv, .rds, .dta, .xlsx)\nQuarto fundamentals\n\n3 Friday morning: Matrices\n\nMatrices\nSystems of linear equations\nMatrix operations (multiplication, transpose, inverse, determinant).\nSolving systems of linear equations in matrix form (and why that’s cool)\nIntroduction to OLS\n\n4 Friday afternoon: tidyverse basics II\n\nData merging and pivoting (*_join(), pivot_*())\nValue recoding (if_else(), case_when())\nMissing values\nData visualization extensions: facets, text annotations\n\n5 Monday morning: Functions and loops\n\nFunctions\nFor-loops and lapply()\nFinding R help (help files, effective Googling, ChatGPT)\n\n6 Monday afternoon: Calculus\n\nLimits (not sure how to teach this in an R-centric way yet, but there must be a way)\nDerivatives (symbolic, numerical, automatic)\nIntegrals\n\n7 Tuesday morning: Probability\n\nConcepts: probability, random variables, etc.\nPMF, PDF, CDF, etc.\nDistributions (binomial, normal; different functions in R and how to use them)\nExpectation and variance\n\n8 Tuesday afternoon: Simulations\n\nSimulations (ideas, seed setting, etc.)\nSampling\nBootstrapping\n\n9 Wednesday morning: Text analysis\n\nString manipulation with stringr\nSimple text analysis (counts, tf-idf, etc.) with tidytext and visualization\n\n10 Wednesday afternoon: Wrap-up\n\nProject management fundamentals (RStudio projects, keeping raw data, etc.)\nSelf-study resources and materials\nOther software (Overleaf, Zotero, etc.)\nMethods at UT"
  },
  {
    "objectID": "index.html#contact-info",
    "href": "index.html#contact-info",
    "title": "Methods Camp",
    "section": "Contact info",
    "text": "Contact info\nIf you have any questions during or outside of methods camp, you can contact us via email:\n\nAndrés Cruz: andres.cruz at utexas dot edu\nMatt Martin: mjmartin at utexas dot edu\n\nIf you are interested in learning more about our research, you can also check out our respective websites:\n\nAndrés Cruz via GitHub Pages\nMatt Martin via GitHub Pages\n\nOr, follow us on Twitter (or should we say X…):\n\nAndrés Cruz: https://twitter.com/arcruz0\nMatt Martin: https://twitter.com/MattJ_Martin\n\n\n\n\n\nArel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman. 2018. “Countrycode: An r Package to Convert Country Names and Country Codes.” Journal of Open Source Software 3 (28): 848. https://doi.org/10.21105/joss.00848.\n\n\nBank, World. 2023. “World Bank Open Data.” https://data.worldbank.org/.\n\n\nDahlberg, Stefan, Aksen Sundström, Sören Holmberg, Bo Rothstein, Natalia Alvarado Pachon, Cem Mert Dalli, and Yente Meijers. 2023. “The Quality of Government Basic Dataset, Version Jan23.” University of Gothenburg: The Quality of Government Institute. https://www.gu.se/en/quality-government doi:10.18157/qogbasjan23.\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nRobinson, David. 2020. Fuzzyjoin: Join Tables Together on Inexact Matching. https://github.com/dgrtwo/fuzzyjoin.\n\n\nSmith, Danny. 2020. Survey Research Datasets and R. https://socialresearchcentre.github.io/r_survey_datasets/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "00_setup.html#installing-r-and-rstudio",
    "href": "00_setup.html#installing-r-and-rstudio",
    "title": "Setup",
    "section": "Installing R and RStudio",
    "text": "Installing R and RStudio\nR is a programming language optimized for statistics and data analysis. Most people use R from RStudio, a graphical user interface (GUI) that includes a file pane, a graphics pane, and other goodies. Both R and RStudio are open source, i.e., free as in beer and free as in freedom!\nYour first steps should be to install R and RStudio, in that order (if you have installed these programs before, make sure that your versions are up-to-date—if they are not, follow the instructions below):\n\nDownload and install R from the official website, CRAN. Click on “Download R for &lt;Windows/Mac&gt;” and follow the instructions. If you have a Mac, make sure to select the version appropriate for your system (Apple Silicon for newer M1/M2 Macs and Intel for older Macs).\nDownload and install RStudio from the official website. Scroll down and select the installer for your operating system.\n\nAfter these two steps, you can open RStudio in your system, as you would with any program. You should see something like this:\n\n\n\nFigure 1: How RStudio looks after a clean installation.\n\n\nThat’s it for the installation! We also strongly recommend that you change a couple of RStudio’s default settings.1 You can change settings by clicking on Tools &gt; Global Options in the menubar. Here are our recommendations:\n\nGeneral &gt; Uncheck \"Restore .RData into workspace at startup\"\nGeneral &gt; Save workspace to .RData on Exit &gt; Select \"Never\"\nCode &gt; Check \"Use native pipe operator\"\nTools &gt; Global Options &gt; Appearance to change to a dark theme, if you want! Pros: better for night sessions, hacker vibes…"
  },
  {
    "objectID": "00_setup.html#setting-up-for-methods-camp",
    "href": "00_setup.html#setting-up-for-methods-camp",
    "title": "Setup",
    "section": "Setting up for Methods Camp",
    "text": "Setting up for Methods Camp\nAll materials for Methods Camp are both on this website and an RStudio project. An RStudio project is simply a folder where one keeps scripts, datasets, and other files needed for a data analysis project.\nYou can download our RStudio project here, as a .zip compressed file. On MacOS, the file will be uncompressed automatically. On Windows, you should do Right click &gt; Extract all.\n\n\n\n\n\n\nWarning\n\n\n\nMake sure to properly unzip the materials. Double-clicking the .zip file on most Windows systems will not unzip the folder—you must do Right click &gt; Extract all.\n\n\nYou should now have a folder called methodscamp/ on your computer. Navigate to the methodscamp.Rproj file within it and open it. RStudio should open the project right away. You should see methodscamp on the top-right of RStudio—this indicates that you are working in our RStudio project.\n\n\n\nFigure 2: How the bottom-right corner of RStudio looks after opening our project.\n\n\nThat’s all for setup! We can now start coding. After opening our RStudio project, we’ll begin by opening the 01_r_intro.qmd file from the “Files” panel, in the bottom-right portion of RStudio. This is a Quarto document,2 which contains both code and explanations (you can also read in the next chapter of this website).\n\n\n\n\nArel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman. 2018. “Countrycode: An r Package to Convert Country Names and Country Codes.” Journal of Open Source Software 3 (28): 848. https://doi.org/10.21105/joss.00848.\n\n\nBank, World. 2023. “World Bank Open Data.” https://data.worldbank.org/.\n\n\nDahlberg, Stefan, Aksen Sundström, Sören Holmberg, Bo Rothstein, Natalia Alvarado Pachon, Cem Mert Dalli, and Yente Meijers. 2023. “The Quality of Government Basic Dataset, Version Jan23.” University of Gothenburg: The Quality of Government Institute. https://www.gu.se/en/quality-government doi:10.18157/qogbasjan23.\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nRobinson, David. 2020. Fuzzyjoin: Join Tables Together on Inexact Matching. https://github.com/dgrtwo/fuzzyjoin.\n\n\nSmith, Danny. 2020. Survey Research Datasets and R. https://socialresearchcentre.github.io/r_survey_datasets/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "00_setup.html#footnotes",
    "href": "00_setup.html#footnotes",
    "title": "Setup",
    "section": "",
    "text": "The idea behind these settings (or at least the first two) is to force R to start from scratch with each new session. No lingering objects from previous coding sessions avoids misunderstandings and helps with reproducibility!↩︎\nPerhaps you have used R Markdown before. Quarto is the next iteration of R Markdown, and is both more flexible and more powerful!↩︎"
  },
  {
    "objectID": "01_r_intro.html#objects",
    "href": "01_r_intro.html#objects",
    "title": "1  Intro to R",
    "section": "1.1 Objects",
    "text": "1.1 Objects\nA huge part of R is working with objects. Let’s see how they work:\n\nmy_object &lt;- 10 # opt/alt + minus sign will make the arrow \n\n\nmy_object # to print the value of an object, just call its name\n\n[1] 10\n\n\nWe can now use this object in our operations:\n\n2 ^ my_object\n\n[1] 1024\n\n\nOr even create another object out of it:\n\nmy_object2 &lt;- my_object * 2\n\n\nmy_object2\n\n[1] 20\n\n\nYou can delete objects with the rm() function (for “remove”):\n\nrm(my_object2)"
  },
  {
    "objectID": "01_r_intro.html#vectors-and-functions",
    "href": "01_r_intro.html#vectors-and-functions",
    "title": "1  Intro to R",
    "section": "1.2 Vectors and functions",
    "text": "1.2 Vectors and functions\nObjects can be of different types. One of the most useful ones is the vector, which holds a series of values. To create one manually, we can use the c() function (for “combine”):\n\nmy_vector &lt;- c(6, -11, my_object, 0, 20)\n\n\nmy_vector\n\n[1]   6 -11  10   0  20\n\n\nOne can also define vectors by sequences:\n\n3:10\n\n[1]  3  4  5  6  7  8  9 10\n\n\nWe can use square brackets to retrieve parts of vectors:\n\nmy_vector[4] # fourth element\n\n[1] 0\n\n\n\nmy_vector[1:2] # first two elements\n\n[1]   6 -11\n\n\nLet’s check out some basic functions we can use with numbers and numeric vectors:\n\nsqrt(my_object) # squared root\n\n[1] 3.162278\n\n\n\nlog(my_object) # logarithm (natural by default)\n\n[1] 2.302585\n\n\n\nabs(-5) # absolute value\n\n[1] 5\n\n\n\nmean(my_vector)\n\n[1] 5\n\n\n\nmedian(my_vector)\n\n[1] 6\n\n\n\nsd(my_vector) # standard deviation\n\n[1] 11.53256\n\n\n\nsum(my_vector)\n\n[1] 25\n\n\n\nmin(my_vector) # minimum value\n\n[1] -11\n\n\n\nmax(my_vector) # maximum value\n\n[1] 20\n\n\n\nlength(my_vector) # length (number of elements)\n\n[1] 5\n\n\nNotice that if we wanted to save any of these results for later, we would need to assign them:\n\nmy_mean &lt;- mean(my_vector)\n\n\nmy_mean\n\n[1] 5\n\n\nThese functions are quite simple: they take one object and do one operation. A lot of functions are a bit more complex—they take multiple objects or take options. For example, see the sort() function, which by default sorts a vector increasingly:\n\nsort(my_vector)\n\n[1] -11   0   6  10  20\n\n\nIf we instead want to sort our vector decreasingly, we can use the decreasing = TRUE argument (T also works as an abbreviation for TRUE).\n\nsort(my_vector, decreasing = TRUE)\n\n[1]  20  10   6   0 -11\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you use the argument values in order, you can avoid writing the argument names (see below). This is sometimes useful, but can also lead to confusing code—use it with caution.\n\nsort(my_vector, T)\n\n[1]  20  10   6   0 -11\n\n\n\n\nA useful function to create vectors in sequence is seq(). Notice its arguments:\n\nseq(from = 30, to = 100, by = 5)\n\n [1]  30  35  40  45  50  55  60  65  70  75  80  85  90  95 100\n\n\nTo check the arguments of a function, you can examine its help file: look the function up on the “Help” panel on RStudio or use a command like the following: ?sort.\n\n\n\n\n\n\nExercise\n\n\n\nExamine the help file of the log() function. How can we compute the the base-10 logarithm of my_object? Your code:\n\n\nOther than numeric vectors, character vectors are also useful:\n\nmy_character_vector &lt;- c(\"Apple\", \"Orange\", \"Watermelon\", \"Banana\")\n\n\nmy_character_vector[3]\n\n[1] \"Watermelon\"\n\n\n\nnchar(my_character_vector) # count number of characters\n\n[1]  5  6 10  6"
  },
  {
    "objectID": "01_r_intro.html#data-frames-and-lists",
    "href": "01_r_intro.html#data-frames-and-lists",
    "title": "1  Intro to R",
    "section": "1.3 Data frames and lists",
    "text": "1.3 Data frames and lists\nAnother useful object type is the data frame. Data frames can store multiple vectors in a tabular format. We can manually create one with the data.frame() function:\n\nmy_data_frame &lt;- data.frame(fruit = my_character_vector,\n                            calories_per_100g = c(52, 47, 30, 89),\n                            water_per_100g = c(85.6, 86.8, 91.4, 74.9))\n\n\nmy_data_frame\n\n       fruit calories_per_100g water_per_100g\n1      Apple                52           85.6\n2     Orange                47           86.8\n3 Watermelon                30           91.4\n4     Banana                89           74.9\n\n\nNow we have a little 4x3 data frame of fruits with their calorie counts and water composition. We gathered the nutritional information from the USDA (2019).\nWe can use the data_frame$column construct to access the vectors within the data frame:\n\nmean(my_data_frame$calories_per_100g)\n\n[1] 54.5\n\n\n\n\n\n\n\n\nExercise\n\n\n\nObtain the maximum value of water content per 100g in the data. Your code:\n\n\nSome useful commands to learn attributes of our data frame:\n\ndim(my_data_frame)\n\n[1] 4 3\n\n\n\nnrow(my_data_frame)\n\n[1] 4\n\n\n\nnames(my_data_frame) # column names\n\n[1] \"fruit\"             \"calories_per_100g\" \"water_per_100g\"   \n\n\nWe will learn much more about data frames in our next module on data analysis.\nAfter talking about vectors and data frames, the last object type that we will cover is the list. Lists are super flexible objects that can contain just about anything:\n\nmy_list &lt;- list(my_object, my_vector, my_data_frame)\n\n\nmy_list\n\n[[1]]\n[1] 10\n\n[[2]]\n[1]   6 -11  10   0  20\n\n[[3]]\n       fruit calories_per_100g water_per_100g\n1      Apple                52           85.6\n2     Orange                47           86.8\n3 Watermelon                30           91.4\n4     Banana                89           74.9\n\n\nTo retrieve the elements of a list, we need to use double square brackets:\n\nmy_list[[1]]\n\n[1] 10\n\n\nLists are sometimes useful due to their flexibility, but are much less common in routine data analysis compared to vectors or data frames."
  },
  {
    "objectID": "01_r_intro.html#packages",
    "href": "01_r_intro.html#packages",
    "title": "1  Intro to R",
    "section": "1.4 Packages",
    "text": "1.4 Packages\nThe R community has developed thousands of packages, which are specialized collections of functions, datasets, and other resources. To install one, you should use the install.packages() command. Below we will install the tidyverse package, a suite for data analysis that we will use in the next modules. You just need to install packages once, and then they will be available system-wide.\n\ninstall.packages(\"tidyverse\") # this can take a couple of minutes\n\nIf you want to use an installed package in your script, you must load it with the library() function. Some packages, as shown below, will print descriptive messages once loaded.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\nWarning\n\n\n\nRemember that install.packages(\"package\") needs to be executed just once, while library(package) needs to be in each script in which you plan to use the package. In general, never include install.packages(\"package\") as part of your scripts or Quarto documents!\n\n\n\n\n\n\nArel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman. 2018. “Countrycode: An r Package to Convert Country Names and Country Codes.” Journal of Open Source Software 3 (28): 848. https://doi.org/10.21105/joss.00848.\n\n\nBank, World. 2023. “World Bank Open Data.” https://data.worldbank.org/.\n\n\nDahlberg, Stefan, Aksen Sundström, Sören Holmberg, Bo Rothstein, Natalia Alvarado Pachon, Cem Mert Dalli, and Yente Meijers. 2023. “The Quality of Government Basic Dataset, Version Jan23.” University of Gothenburg: The Quality of Government Institute. https://www.gu.se/en/quality-government doi:10.18157/qogbasjan23.\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nRobinson, David. 2020. Fuzzyjoin: Join Tables Together on Inexact Matching. https://github.com/dgrtwo/fuzzyjoin.\n\n\nSmith, Danny. 2020. Survey Research Datasets and R. https://socialresearchcentre.github.io/r_survey_datasets/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "02_tidy_data1.html#loading-data",
    "href": "02_tidy_data1.html#loading-data",
    "title": "2  Tidy data analysis I",
    "section": "2.1 Loading data",
    "text": "2.1 Loading data\nThroughout this module we will work with a dataset of senators during the Trump presidency, which was adapted from FiveThirtyEight (2021).\nWe have stored the dataset in .csv format under the data/ subfolder. Loading it into R is simple (notice that we need to assign it to an object):\n\ntrump_scores &lt;- read_csv(\"data/trump_scores_538.csv\")\n\nRows: 122 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): bioguide, last_name, state, party\ndbl (4): num_votes, agree, agree_pred, margin_trump\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ntrump_scores\n\n# A tibble: 122 × 8\n   bioguide last_name  state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 A000360  Alexander  TN    R           118 0.890      0.856       26.0  \n 2 B000575  Blunt      MO    R           128 0.906      0.787       18.6  \n 3 B000944  Brown      OH    D           128 0.258      0.642        8.13 \n 4 B001135  Burr       NC    R           121 0.893      0.560        3.66 \n 5 B001230  Baldwin    WI    D           128 0.227      0.510        0.764\n 6 B001236  Boozman    AR    R           129 0.915      0.851       26.9  \n 7 B001243  Blackburn  TN    R           131 0.885      0.889       26.0  \n 8 B001261  Barrasso   WY    R           129 0.891      0.895       46.3  \n 9 B001267  Bennet     CO    D           121 0.273      0.417       -4.91 \n10 B001277  Blumenthal CT    D           128 0.203      0.294      -13.6  \n# ℹ 112 more rows\n\n\nLet’s review the dataset’s columns:\n\nbioguide: A unique ID for each politician, from the Congress Bioguide.\nlast_name\nstate\nparty\nnum_votes: Number of votes for which data was available.\nagree: Proportion (0-1) of votes in which the senator voted in agreement with Trump.\nagree_pred: Predicted proportion of vote agreement, calculated using Trump’s margin (see next variable).\nmargin_trump: Margin of victory (percentage points) of Trump in the senator’s state.\n\nWe can inspect our data by using the interface above. An alternative is to run the command View(trump_scores) or click on the object in RStudio’s environment panel (in the top-right section).\nDo you have any questions about the data?\nBy the way, the tidyverse works amazingly with tidy data. If you can get your data to this format (and we will see ways to do this), your life will be much easier:\n\n\n\n\n\n\n\n\n\n\n\nSource: Illustrations from the Openscapes blog Tidy Data for reproducibility, efficiency, and collaboration by Julia Lowndes and Allison Horst."
  },
  {
    "objectID": "02_tidy_data1.html#wrangling-data-with-dplyr",
    "href": "02_tidy_data1.html#wrangling-data-with-dplyr",
    "title": "2  Tidy data analysis I",
    "section": "2.2 Wrangling data with dplyr",
    "text": "2.2 Wrangling data with dplyr\nWe often need to modify data to conduct our analyses, e.g., creating columns, filtering rows, etc. In the tidyverse, these operations are conducted with multiple verbs, which we will review now.\n\n2.2.1 Selecting columns\nWe can select specific columns in our dataset with the select() function. All dplyr wrangling verbs take a data frame as their first argument—in this case, the columns we want to select are the other arguments.\n\nselect(trump_scores, last_name, party)\n\n# A tibble: 122 × 2\n   last_name  party\n   &lt;chr&gt;      &lt;chr&gt;\n 1 Alexander  R    \n 2 Blunt      R    \n 3 Brown      D    \n 4 Burr       R    \n 5 Baldwin    D    \n 6 Boozman    R    \n 7 Blackburn  R    \n 8 Barrasso   R    \n 9 Bennet     D    \n10 Blumenthal D    \n# ℹ 112 more rows\n\n\nThis is a good moment to talk about “pipes.” Notice how the code below produces the same output as the one above, but with a slightly different syntax. Pipes (|&gt;) “kick” the object on the left of the pipe to the first argument of the function on the right. One can read pipes as “then,” so the code below can be read as “take trump_scores, then select the columns last_name and party.” Pipes are very useful to chain multiple operations, as we will see in a moment.\n\ntrump_scores |&gt; \n  select(last_name, party)\n\n# A tibble: 122 × 2\n   last_name  party\n   &lt;chr&gt;      &lt;chr&gt;\n 1 Alexander  R    \n 2 Blunt      R    \n 3 Brown      D    \n 4 Burr       R    \n 5 Baldwin    D    \n 6 Boozman    R    \n 7 Blackburn  R    \n 8 Barrasso   R    \n 9 Bennet     D    \n10 Blumenthal D    \n# ℹ 112 more rows\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can insert a pipe with the Cmd/Ctrl + Shift + M shortcut. If you have not changed the default RStudio settings, an “old” pipe (%&gt;%) might appear. While most of the functionality is the same, the |&gt; “new” pipes are more readable. You can change this RStudio option in Tools &gt; Global Options &gt; Code &gt; Use native pipe operator. Make sure to check the other suggested settings in our Setup module!\n\n\nGoing back to selecting columns, you can select ranges:\n\ntrump_scores |&gt; \n  select(bioguide:party)\n\n# A tibble: 122 × 4\n   bioguide last_name  state party\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;\n 1 A000360  Alexander  TN    R    \n 2 B000575  Blunt      MO    R    \n 3 B000944  Brown      OH    D    \n 4 B001135  Burr       NC    R    \n 5 B001230  Baldwin    WI    D    \n 6 B001236  Boozman    AR    R    \n 7 B001243  Blackburn  TN    R    \n 8 B001261  Barrasso   WY    R    \n 9 B001267  Bennet     CO    D    \n10 B001277  Blumenthal CT    D    \n# ℹ 112 more rows\n\n\nYou can also deselect columns using a minus sign:\n\ntrump_scores |&gt; \n  select(-last_name)\n\n# A tibble: 122 × 7\n   bioguide state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 A000360  TN    R           118 0.890      0.856       26.0  \n 2 B000575  MO    R           128 0.906      0.787       18.6  \n 3 B000944  OH    D           128 0.258      0.642        8.13 \n 4 B001135  NC    R           121 0.893      0.560        3.66 \n 5 B001230  WI    D           128 0.227      0.510        0.764\n 6 B001236  AR    R           129 0.915      0.851       26.9  \n 7 B001243  TN    R           131 0.885      0.889       26.0  \n 8 B001261  WY    R           129 0.891      0.895       46.3  \n 9 B001267  CO    D           121 0.273      0.417       -4.91 \n10 B001277  CT    D           128 0.203      0.294      -13.6  \n# ℹ 112 more rows\n\n\nAnd use a few helper functions, like matches():\n\ntrump_scores |&gt; \n  select(last_name, matches(\"agree\"))\n\n# A tibble: 122 × 3\n   last_name  agree agree_pred\n   &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 Alexander  0.890      0.856\n 2 Blunt      0.906      0.787\n 3 Brown      0.258      0.642\n 4 Burr       0.893      0.560\n 5 Baldwin    0.227      0.510\n 6 Boozman    0.915      0.851\n 7 Blackburn  0.885      0.889\n 8 Barrasso   0.891      0.895\n 9 Bennet     0.273      0.417\n10 Blumenthal 0.203      0.294\n# ℹ 112 more rows\n\n\nOr everything(), which we usually use to reorder columns:\n\ntrump_scores |&gt; \n  select(last_name, everything())\n\n# A tibble: 122 × 8\n   last_name  bioguide state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 Alexander  A000360  TN    R           118 0.890      0.856       26.0  \n 2 Blunt      B000575  MO    R           128 0.906      0.787       18.6  \n 3 Brown      B000944  OH    D           128 0.258      0.642        8.13 \n 4 Burr       B001135  NC    R           121 0.893      0.560        3.66 \n 5 Baldwin    B001230  WI    D           128 0.227      0.510        0.764\n 6 Boozman    B001236  AR    R           129 0.915      0.851       26.9  \n 7 Blackburn  B001243  TN    R           131 0.885      0.889       26.0  \n 8 Barrasso   B001261  WY    R           129 0.891      0.895       46.3  \n 9 Bennet     B001267  CO    D           121 0.273      0.417       -4.91 \n10 Blumenthal B001277  CT    D           128 0.203      0.294      -13.6  \n# ℹ 112 more rows\n\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that all these commands have not edited our existent objects—they have just printed the requested outputs to the screen. In order to modify objects, you need to use the assignment operator (&lt;-). For example:\n\ntrump_scores_reduced &lt;- trump_scores |&gt; \n  select(last_name, matches(\"agree\"))\n\n\ntrump_scores_reduced\n\n# A tibble: 122 × 3\n   last_name  agree agree_pred\n   &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 Alexander  0.890      0.856\n 2 Blunt      0.906      0.787\n 3 Brown      0.258      0.642\n 4 Burr       0.893      0.560\n 5 Baldwin    0.227      0.510\n 6 Boozman    0.915      0.851\n 7 Blackburn  0.885      0.889\n 8 Barrasso   0.891      0.895\n 9 Bennet     0.273      0.417\n10 Blumenthal 0.203      0.294\n# ℹ 112 more rows\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nSelect the variables last_name, party, num_votes, and agree from the data frame. Your code:\n\n\n\n\n2.2.2 Renaming columns\nWe can use the rename() function to rename columns, with the syntax new_name = old_name. For example:\n\ntrump_scores |&gt; \n  rename(prop_agree = agree, prop_agree_pred = agree_pred)\n\n# A tibble: 122 × 8\n   bioguide last_name  state party num_votes prop_agree prop_agree_pred\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;\n 1 A000360  Alexander  TN    R           118      0.890           0.856\n 2 B000575  Blunt      MO    R           128      0.906           0.787\n 3 B000944  Brown      OH    D           128      0.258           0.642\n 4 B001135  Burr       NC    R           121      0.893           0.560\n 5 B001230  Baldwin    WI    D           128      0.227           0.510\n 6 B001236  Boozman    AR    R           129      0.915           0.851\n 7 B001243  Blackburn  TN    R           131      0.885           0.889\n 8 B001261  Barrasso   WY    R           129      0.891           0.895\n 9 B001267  Bennet     CO    D           121      0.273           0.417\n10 B001277  Blumenthal CT    D           128      0.203           0.294\n# ℹ 112 more rows\n# ℹ 1 more variable: margin_trump &lt;dbl&gt;\n\n\nThis is a good occasion to show how pipes allow us to chain operations. How do we read the following code out loud? (Remember that pipes are read as “then”).\n\ntrump_scores |&gt; \n  select(last_name, matches(\"agree\")) |&gt; \n  rename(prop_agree = agree, prop_agree_pred = agree_pred)\n\n# A tibble: 122 × 3\n   last_name  prop_agree prop_agree_pred\n   &lt;chr&gt;           &lt;dbl&gt;           &lt;dbl&gt;\n 1 Alexander       0.890           0.856\n 2 Blunt           0.906           0.787\n 3 Brown           0.258           0.642\n 4 Burr            0.893           0.560\n 5 Baldwin         0.227           0.510\n 6 Boozman         0.915           0.851\n 7 Blackburn       0.885           0.889\n 8 Barrasso        0.891           0.895\n 9 Bennet          0.273           0.417\n10 Blumenthal      0.203           0.294\n# ℹ 112 more rows\n\n\n\n\n2.2.3 Creating columns\nIt is common to want to create columns, based on existing ones. We can use mutate() to do so. For example, we could want our main variables of interest in terms of percentages instead of proportions:\n\ntrump_scores |&gt; \n  select(last_name, agree, agree_pred) |&gt; # select just for clarity\n  mutate(pct_agree = 100 * agree,\n         pct_agree_pred = 100 * agree_pred)\n\n# A tibble: 122 × 5\n   last_name  agree agree_pred pct_agree pct_agree_pred\n   &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;\n 1 Alexander  0.890      0.856      89.0           85.6\n 2 Blunt      0.906      0.787      90.6           78.7\n 3 Brown      0.258      0.642      25.8           64.2\n 4 Burr       0.893      0.560      89.3           56.0\n 5 Baldwin    0.227      0.510      22.7           51.0\n 6 Boozman    0.915      0.851      91.5           85.1\n 7 Blackburn  0.885      0.889      88.5           88.9\n 8 Barrasso   0.891      0.895      89.1           89.5\n 9 Bennet     0.273      0.417      27.3           41.7\n10 Blumenthal 0.203      0.294      20.3           29.4\n# ℹ 112 more rows\n\n\nWe can also use multiple columns for creating a new one. For example, let’s retrieve the total number of votes in which the senator agreed with Trump:\n\ntrump_scores |&gt; \n  select(last_name, num_votes, agree) |&gt; # select just for clarity\n  mutate(num_votes_agree = num_votes * agree)\n\n# A tibble: 122 × 4\n   last_name  num_votes agree num_votes_agree\n   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;           &lt;dbl&gt;\n 1 Alexander        118 0.890           105  \n 2 Blunt            128 0.906           116  \n 3 Brown            128 0.258            33  \n 4 Burr             121 0.893           108  \n 5 Baldwin          128 0.227            29  \n 6 Boozman          129 0.915           118  \n 7 Blackburn        131 0.885           116  \n 8 Barrasso         129 0.891           115  \n 9 Bennet           121 0.273            33.0\n10 Blumenthal       128 0.203            26  \n# ℹ 112 more rows\n\n\n\n\n2.2.4 Filtering rows\nAnother common operation is to filter rows based on logical conditions. We can do so with the filter() function. For example, we can filter to only get Democrats:\n\ntrump_scores |&gt; \n  filter(party == \"D\")\n\n# A tibble: 55 × 8\n   bioguide last_name  state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 B000944  Brown      OH    D           128 0.258      0.642        8.13 \n 2 B001230  Baldwin    WI    D           128 0.227      0.510        0.764\n 3 B001267  Bennet     CO    D           121 0.273      0.417       -4.91 \n 4 B001277  Blumenthal CT    D           128 0.203      0.294      -13.6  \n 5 B001288  Booker     NJ    D           119 0.160      0.290      -14.1  \n 6 C000127  Cantwell   WA    D           128 0.242      0.276      -15.5  \n 7 C000141  Cardin     MD    D           128 0.25       0.209      -26.4  \n 8 C000174  Carper     DE    D           129 0.295      0.318      -11.4  \n 9 C001070  Casey      PA    D           129 0.287      0.508        0.724\n10 C001088  Coons      DE    D           128 0.289      0.319      -11.4  \n# ℹ 45 more rows\n\n\nNotice that == here is a logical operator, read as “is equal to.” So our full chain of operations says the following: take trump_scores, then filter it to get rows where party is equal to “D”.\nThere are other logical operators:\n\n\n\nLogical operator\nMeaning\n\n\n\n\n==\n“is equal to”\n\n\n!=\n“is not equal to”\n\n\n&gt;\n“is greater than”\n\n\n&lt;\n“is less than”\n\n\n&gt;=\n“is greater than or equal to”\n\n\n&lt;=\n“is less than or equal to”\n\n\n%in%\n“is contained in”\n\n\n&\n“and” (intersection)\n\n\n|\n“or” (union)\n\n\n\nLet’s see a couple of other examples.\n\ntrump_scores |&gt; \n  filter(agree &gt; 0.5)\n\n# A tibble: 69 × 8\n   bioguide last_name state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 A000360  Alexander TN    R           118 0.890      0.856        26.0 \n 2 B000575  Blunt     MO    R           128 0.906      0.787        18.6 \n 3 B001135  Burr      NC    R           121 0.893      0.560         3.66\n 4 B001236  Boozman   AR    R           129 0.915      0.851        26.9 \n 5 B001243  Blackburn TN    R           131 0.885      0.889        26.0 \n 6 B001261  Barrasso  WY    R           129 0.891      0.895        46.3 \n 7 B001310  Braun     IN    R            44 0.909      0.713        19.2 \n 8 C000567  Cochran   MS    R            68 0.971      0.830        17.8 \n 9 C000880  Crapo     ID    R           125 0.904      0.870        31.8 \n10 C001035  Collins   ME    R           129 0.651      0.441        -2.96\n# ℹ 59 more rows\n\n\n\ntrump_scores |&gt; \n  filter(state %in% c(\"CA\", \"TX\"))\n\n# A tibble: 4 × 8\n  bioguide last_name state party num_votes agree agree_pred margin_trump\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n1 C001056  Cornyn    TX    R           129 0.922      0.659         9.00\n2 C001098  Cruz      TX    R           126 0.921      0.663         9.00\n3 F000062  Feinstein CA    D           128 0.242      0.201       -30.1 \n4 H001075  Harris    CA    D           116 0.164      0.209       -30.1 \n\n\n\ntrump_scores |&gt; \n  filter(state == \"WV\" & party == \"D\")\n\n# A tibble: 1 × 8\n  bioguide last_name state party num_votes agree agree_pred margin_trump\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n1 M001183  Manchin   WV    D           129 0.504      0.893         42.2\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nAdd a new column to the data frame, called diff_agree, which subtracts agree and agree_pred. How would you create abs_diff_agree, defined as the absolute value of diff_agree? Your code:\nFilter the data frame to only get senators for which we have information on fewer than (or equal to) five votes. Your code:\nFilter the data frame to only get Democrats who agreed with Trump in at least 30% of votes. Your code:\n\n\n\n\n\n2.2.5 Ordering rows\nThe arrange() function allows us to order rows according to values. For example, let’s order based on the agree variable:\n\ntrump_scores |&gt; \n  arrange(agree)\n\n# A tibble: 122 × 8\n   bioguide last_name    state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 H000273  Hickenlooper CO    D             2 0         0.0302        -4.91\n 2 H000601  Hagerty      TN    R             2 0         0.115         26.0 \n 3 L000570  Luján        NM    D           186 0.124     0.243         -8.21\n 4 G000555  Gillibrand   NY    D           121 0.124     0.242        -22.5 \n 5 M001176  Merkley      OR    D           129 0.155     0.323        -11.0 \n 6 W000817  Warren       MA    D           116 0.155     0.216        -27.2 \n 7 B001288  Booker       NJ    D           119 0.160     0.290        -14.1 \n 8 S000033  Sanders      VT    D           112 0.161     0.221        -26.4 \n 9 H001075  Harris       CA    D           116 0.164     0.209        -30.1 \n10 M000133  Markey       MA    D           127 0.165     0.213        -27.2 \n# ℹ 112 more rows\n\n\nMaybe we only want senators with more than a few data points. Remember that we can chain operations:\n\ntrump_scores |&gt; \n  filter(num_votes &gt;= 10) |&gt; \n  arrange(agree)\n\n# A tibble: 115 × 8\n   bioguide last_name  state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 L000570  Luján      NM    D           186 0.124      0.243        -8.21\n 2 G000555  Gillibrand NY    D           121 0.124      0.242       -22.5 \n 3 M001176  Merkley    OR    D           129 0.155      0.323       -11.0 \n 4 W000817  Warren     MA    D           116 0.155      0.216       -27.2 \n 5 B001288  Booker     NJ    D           119 0.160      0.290       -14.1 \n 6 S000033  Sanders    VT    D           112 0.161      0.221       -26.4 \n 7 H001075  Harris     CA    D           116 0.164      0.209       -30.1 \n 8 M000133  Markey     MA    D           127 0.165      0.213       -27.2 \n 9 W000779  Wyden      OR    D           129 0.186      0.323       -11.0 \n10 B001277  Blumenthal CT    D           128 0.203      0.294       -13.6 \n# ℹ 105 more rows\n\n\nBy default, arrange() uses increasing order (like sort()). To use decreasing order, add a minus sign:\n\ntrump_scores |&gt; \n  filter(num_votes &gt;= 10) |&gt; \n  arrange(-agree)\n\n# A tibble: 115 × 8\n   bioguide last_name state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 M001198  Marshall  KS    R           183 0.973      0.933        20.6 \n 2 C000567  Cochran   MS    R            68 0.971      0.830        17.8 \n 3 H000338  Hatch     UT    R            84 0.964      0.825        18.1 \n 4 M001197  McSally   AZ    R           136 0.949      0.562         3.55\n 5 P000612  Perdue    GA    R           119 0.941      0.606         5.16\n 6 C001096  Cramer    ND    R           135 0.941      0.908        35.7 \n 7 R000307  Roberts   KS    R           127 0.937      0.818        20.6 \n 8 C001056  Cornyn    TX    R           129 0.922      0.659         9.00\n 9 H001061  Hoeven    ND    R           129 0.922      0.883        35.7 \n10 C001047  Capito    WV    R           127 0.921      0.896        42.2 \n# ℹ 105 more rows\n\n\nYou can also order rows by more than one variable. What this does is to order by the first variable, and resolve any ties by ordering by the second variable (and so forth if you have more than two ordering variables). For example, let’s first order our data frame by party, and then within party order by agreement with Trump:\n\ntrump_scores |&gt; \n  filter(num_votes &gt;= 10) |&gt; \n  arrange(party, agree)\n\n# A tibble: 115 × 8\n   bioguide last_name  state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 L000570  Luján      NM    D           186 0.124      0.243        -8.21\n 2 G000555  Gillibrand NY    D           121 0.124      0.242       -22.5 \n 3 M001176  Merkley    OR    D           129 0.155      0.323       -11.0 \n 4 W000817  Warren     MA    D           116 0.155      0.216       -27.2 \n 5 B001288  Booker     NJ    D           119 0.160      0.290       -14.1 \n 6 S000033  Sanders    VT    D           112 0.161      0.221       -26.4 \n 7 H001075  Harris     CA    D           116 0.164      0.209       -30.1 \n 8 M000133  Markey     MA    D           127 0.165      0.213       -27.2 \n 9 W000779  Wyden      OR    D           129 0.186      0.323       -11.0 \n10 B001277  Blumenthal CT    D           128 0.203      0.294       -13.6 \n# ℹ 105 more rows\n\n\n\n\n\n\n\n\nExercise\n\n\n\nArrange the data by diff_pred, the difference between agreement and predicted agreement with Trump. (You should have code on how to create this variable from the last exercise). Your code:\n\n\n\n\n2.2.6 Summarizing data\ndplyr makes summarizing data a breeze using the summarize() function:\n\ntrump_scores |&gt; \n  summarize(mean_agree = mean(agree),\n            mean_agree_pred = mean(agree_pred))\n\n# A tibble: 1 × 2\n  mean_agree mean_agree_pred\n       &lt;dbl&gt;           &lt;dbl&gt;\n1      0.592           0.572\n\n\nTo make summaries, we can use any function that takes a vector and returns one value. Another example:\n\ntrump_scores |&gt; \n  filter(num_votes &gt;= 5) |&gt; # to filter out senators with few data points\n  summarize(max_agree = max(agree),\n            min_agree = min(agree))\n\n# A tibble: 1 × 2\n  max_agree min_agree\n      &lt;dbl&gt;     &lt;dbl&gt;\n1         1     0.124\n\n\nGrouped summaries allow us to disaggregate summaries according to other variables (usually categorical):\n\ntrump_scores |&gt; \n  filter(num_votes &gt;= 5) |&gt; # to filter out senators with few data points\n  summarize(mean_agree = mean(agree),\n            max_agree = max(agree),\n            min_agree = min(agree),\n            .by = party) # to group by party\n\n# A tibble: 2 × 4\n  party mean_agree max_agree min_agree\n  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 R          0.876     1         0.651\n2 D          0.272     0.548     0.124\n\n\n\n\n\n\n\n\nExercise\n\n\n\nObtain the maximum absolute difference in agreement with Trump (the abs_diff_agree variable from before) for each party.\n\n\n\n\n2.2.7 Overview\n\n\n\nFunction\nPurpose\n\n\n\n\nselect()\nSelect columns\n\n\nrename()\nRename columns\n\n\nmutate()\nCreating columns\n\n\nfilter()\nFiltering rows\n\n\narrange()\nOrdering rows\n\n\nsummarize()\nSummarizing data\n\n\nsummarize(…, .by = )\nSummarizing data (by groups)"
  },
  {
    "objectID": "02_tidy_data1.html#visualizing-data-with-ggplot2",
    "href": "02_tidy_data1.html#visualizing-data-with-ggplot2",
    "title": "2  Tidy data analysis I",
    "section": "2.3 Visualizing data with ggplot2",
    "text": "2.3 Visualizing data with ggplot2\nggplot2 is the package in charge of data visualization in the tidyverse. It is extremely flexible and allows us to draw bar plots, box plots, histograms, scatter plots, and many other types of plots (see examples at R Charts).\nThroughout this module we will use a subset of our data frame, which only includes senators with more than a few data points:\n\ntrump_scores_ss &lt;- trump_scores |&gt; \n  filter(num_votes &gt;= 10)\n\nThe ggplot2 syntax provides a unifying interface (the “grammar of graphics” or “gg”) for drawing all different types of plots. One draws plots by adding different “layers,” and the core code always includes the following:\n\nA ggplot() command with a data = argument specifying a data frame and a mapping = aes() argument specifying “aesthetic mappings,” i.e., how we want to use the columns in the data frame in the plot (for example, in the x-axis, as color, etc.).\n“geoms,” such as geom_bar() or geom_point(), specifying what to draw on the plot.\n\nSo all ggplot2 commands will have at least three elements: data, aesthetic mappings, and geoms.\n\n2.3.1 Univariate plots: categorical\nLet’s see an example of a bar plot with a categorical variable:\n\nggplot(data = trump_scores_ss, mapping = aes(x = party)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nAs with any other function, we can drop the argument names if we specify the argument values in order. This is common in ggplot2 code:\n\nggplot(trump_scores_ss, aes(x = party)) +\n  geom_bar()\n\n\n\n\n\n\nNotice how geom_bar() automatically computes the number of observations in each category for us. Sometimes we want to use numbers in our data frame as part of a bar plot. Here we can use the geom_col() geom specifying both x and y aesthetic mappings, in which is sometimes called a “column plot:”\n\nggplot(trump_scores_ss |&gt; filter(state == \"ME\"),\n       aes(x = last_name, y = agree)) +\n  geom_col()\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nDraw a column plot with the agreement with Trump of Bernie Sanders and Ted Cruz. What happens if you use last_name as the y aesthetic mapping and agree in the x aesthetic mapping? Your code:\n\n\n\n\n2.3.2 Univariate plots: numerical\nWe can draw a histogram with geom_histogram():\n\nggplot(trump_scores_ss, aes(x = agree)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNotice the warning message above. It’s telling us that, by default, geom_histogram() will draw 30 bins. Sometimes we want to modify this behavior. The following code has some common options for geom_histogram() and their explanations:\n\nggplot(trump_scores_ss, aes(x = agree)) +\n  geom_histogram(binwidth = 0.05,   # draw bins every 0.05 jumps in x\n                 boundary = 0,      # don't shift bins to integers\n                 closed   = \"left\") # close bins on the left\n\n\n\n\nSometimes we want to manually alter a scale. This is accomplished with the scale_*() family of ggplot2 functions. Here we use the scale_x_continuous() function to make the x-axis go from 0 to 1:\n\nggplot(trump_scores_ss, aes(x = agree)) +\n  geom_histogram(binwidth = 0.05, boundary = 0, closed   = \"left\") +   \n  scale_x_continuous(limits = c(0, 1))\n\n\n\n\nAdding the fill aesthetic mapping to a histogram will divide it according to a categorical variable. This is actually a bivariate plot!\n\nggplot(trump_scores_ss, aes(x = agree, fill = party)) +\n  geom_histogram(binwidth = 0.05, boundary = 0, closed   = \"left\") +   \n  scale_x_continuous(limits = c(0, 1)) +\n  # change default colors:\n  scale_fill_manual(values = c(\"D\" = \"blue\", \"R\" = \"red\"))\n\n\n\n\n\n\n2.3.3 Bivariate plots\nAnother common bivariate plot for categorical and numerical variables is the grouped box plot:\n\nggplot(trump_scores_ss, aes(x = agree, y = party)) +\n  geom_boxplot() +\n  scale_x_continuous(limits = c(0, 1)) # same change as before\n\n\n\n\nFor bivariate plots of numerical variables, scatter plots are made with geom_point():\n\nggplot(trump_scores_ss, aes(x = margin_trump, y = agree)) +\n  geom_point()\n\n\n\n\nWe can add the color aesthetic mapping to add a third variable:\n\nggplot(trump_scores_ss, aes(x = margin_trump, y = agree, color = party)) +\n  geom_point() +\n  scale_color_manual(values = c(\"D\" = \"blue\", \"R\" = \"red\"))\n\n\n\n\nLet’s finish our plot with the labs() function, which allows us to add labels to our aesthetic mappings, as well as titles and notes:\n\nggplot(trump_scores, aes(x = margin_trump, y = agree, color = party)) +\n  geom_point() +\n  scale_color_manual(values = c(\"D\" = \"blue\", \"R\" = \"red\")) +\n  labs(x = \"Trump margin in the senator's state (p.p.)\",\n       y = \"Votes in agreement with Trump (prop.)\",\n       color = \"Party\",\n       title = \"Relationship between Trump margins and senators' votes\",\n       caption = \"Data source: FiveThirtyEight (2021)\")\n\n\n\n\nWe will review a few more customization options, including text labels and facets, in a subsequent module.\n\n\n\n\nArel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman. 2018. “Countrycode: An r Package to Convert Country Names and Country Codes.” Journal of Open Source Software 3 (28): 848. https://doi.org/10.21105/joss.00848.\n\n\nBank, World. 2023. “World Bank Open Data.” https://data.worldbank.org/.\n\n\nDahlberg, Stefan, Aksen Sundström, Sören Holmberg, Bo Rothstein, Natalia Alvarado Pachon, Cem Mert Dalli, and Yente Meijers. 2023. “The Quality of Government Basic Dataset, Version Jan23.” University of Gothenburg: The Quality of Government Institute. https://www.gu.se/en/quality-government doi:10.18157/qogbasjan23.\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nRobinson, David. 2020. Fuzzyjoin: Join Tables Together on Inexact Matching. https://github.com/dgrtwo/fuzzyjoin.\n\n\nSmith, Danny. 2020. Survey Research Datasets and R. https://socialresearchcentre.github.io/r_survey_datasets/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "03_matrices.html#introduction",
    "href": "03_matrices.html#introduction",
    "title": "3  Matrices",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\n\n3.1.1 Scalars\nOne number (for example, 12) is referred to as a scalar.\n\\[\na = 12\n\\]\n\n\n3.1.2 Vectors\nWe can put several scalars together to make a vector. Here is an example:\n\\[\n\\overrightarrow b =\n\\begin{bmatrix}\n  12 \\\\\n  14 \\\\\n  15\n\\end{bmatrix}\n\\]\nSince this is a column of numbers, we cleverly refer to it as a column vector.\nHere is another example of a vector, this time represented as a row vector:\n\\[\n\\overrightarrow c = \\begin{bmatrix}\n  12 & 14 & 15\n\\end{bmatrix}\n\\]\nColumn vectors are possibly more common and useful, but we sometimes write things down using row vectors to\nVectors are fairly easy to construct in R. As we saw before, we can use the c() function to combine elements:\n\nc(5, 25, -2, 1)\n\n[1]  5 25 -2  1\n\n\n\n\n\n\n\n\nWarning\n\n\n\nRemember that the code above does not create any objects. To do so, you’d need to use the assignment operator (&lt;-):\n\nvector_example &lt;- c(5, 25, -2, 1)\nvector_example\n\n[1]  5 25 -2  1\n\n\n\n\nOr we can also create vectors from sequences with the : operator or the seq() function:\n\n10:20\n\n [1] 10 11 12 13 14 15 16 17 18 19 20\n\n\n\nseq(from = 3, to = 27, by = 3)\n\n[1]  3  6  9 12 15 18 21 24 27"
  },
  {
    "objectID": "03_matrices.html#operators",
    "href": "03_matrices.html#operators",
    "title": "3  Matrices",
    "section": "3.2 Operators",
    "text": "3.2 Operators\n\n3.2.1 Summation\nThe summation operator \\(\\sum\\) (i.e., the uppercase Sigma letter) lets us perform an operation on a sequence of numbers, which is often but not always a vector.\n\\[\\overrightarrow d = \\begin{bmatrix}\n12 & 7 & -2 & 3 & -1\n\\end{bmatrix}\\]\nWe can then calculate the sum of the first three elements of the vector, which is expressed as follows: \\[\\sum_{i=1}^3 d_i\\]\nThen we do the following math: \\[12+7+(-2)=17\\]\nIt is also common to use \\(n\\) in the superscript to indicate that we want to sum all elements:\n\\[\n\\sum_{i=1}^n d_i = 12 + 7 + (-2) + 3 + (-1) = 19\n\\] We can perform these operations using the sum() function in R:\n\nvector_d &lt;- c(12, 7, -2, 3, -1)\n\n\nsum(vector_d[1:3])\n\n[1] 17\n\n\n\nsum(vector_d)\n\n[1] 19\n\n\n\n\n3.2.2 Product\nThe product operator \\(\\prod\\) (i.e., the uppercase Pi letter) can also perform operations over a sequence of elements in a vector. Recall our previous vector:\n\\[\\overrightarrow d = \\begin{bmatrix}\n12 & 7 & -2 & 3 & 1\n\\end{bmatrix}\\]\nWe might want to calculate the product of all its elements, which is expressed as follows: \\[\\prod_{i=1}^n d_i = 12 \\cdot 7 \\cdot (-2) \\cdot 3 \\cdot (-1) = 504\\]\nIn R, we can compute products using the prod() function:\n\nprod(vector_d)\n\n[1] 504\n\n\n\n\n\n\n\n\nExercise\n\n\n\nGet the product of the first three elements of vector \\(d\\). Write the notation by hand and use R to obtain the number."
  },
  {
    "objectID": "03_matrices.html#matrices",
    "href": "03_matrices.html#matrices",
    "title": "3  Matrices",
    "section": "3.3 Matrices",
    "text": "3.3 Matrices\n\n3.3.1 Basics\nWe can append vectors together to form a matrix:\n\\[A = \\begin{bmatrix}\n12 & 14 & 15 \\\\\n115 & 22 & 127 \\\\\n193 & 29 & 219\n\\end{bmatrix}\\]\nThe number of rows and columns of a matrix constitute the dimensions of the matrix. The first number is the number of rows (“r”) and the second number is the number of columns (“c”) in the matrix.\n\n\n\n\n\n\nImportant\n\n\n\nFind a way to remember “r x c” permanently. The order of the dimensions never changes.\n\n\nMatrix \\(A\\) above, for example, is a \\(3x3\\) matrix. Sometimes we’d refer to it as \\(A_{3x3}\\).\n\n\n\n\n\n\nTip\n\n\n\nIt is common to use capital letters (sometimes bold-faced) to represent matrices. In contrast, vectors are usually represented with either bold lowercase letters or lowercase letters with an arrow on top (e.g., \\(\\overrightarrow v\\)).\n\n\n\nConstructing matrices in R\nThere are different ways to create matrices in R. One of the simplest is via rbind() or cbind(), which paste vectors together (either by rows or by columns):\n\n# Create some vectors\nvector1 &lt;- 1:4\nvector2 &lt;- 5:8\nvector3 &lt;- 9:12\nvector4 &lt;- 13:16\n\n\n# Using rbind(), each vector will be a row \nrbind_mat &lt;- rbind(vector1, vector2, vector3, vector4)\nrbind_mat\n\n        [,1] [,2] [,3] [,4]\nvector1    1    2    3    4\nvector2    5    6    7    8\nvector3    9   10   11   12\nvector4   13   14   15   16\n\n\n\n# Using cbind(), each vector will be a column\ncbind_mat &lt;- cbind(vector1, vector2, vector3, vector4)\ncbind_mat\n\n     vector1 vector2 vector3 vector4\n[1,]       1       5       9      13\n[2,]       2       6      10      14\n[3,]       3       7      11      15\n[4,]       4       8      12      16\n\n\nAn alternative is to use to properly named matrix() function. The basic syntax is matrix(data, nrow, ncol, byrow):\n\ndata is the input vector which becomes the data elements of the matrix.\nnrow is the number of rows to be created.\nncol is the number of columns to be created.\nbyrow is a logical clue. If TRUE then the input vector elements are arranged by row. By default (FALSE), elements are arranged by column.\n\nLet’s see some examples:\n\n# Elements are arranged sequentially by row.\nM &lt;- matrix(c(1:12), nrow = 4, byrow = T)\nM\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n[4,]   10   11   12\n\n\n\n# Elements are arranged sequentially by column (byrow = F by default).\nN &lt;- matrix(c(1:12), nrow = 4)\nN\n\n     [,1] [,2] [,3]\n[1,]    1    5    9\n[2,]    2    6   10\n[3,]    3    7   11\n[4,]    4    8   12\n\n\n\n\n\n3.3.2 Structure\nHow do we refer to specific elements of the matrix? For example, matrix \\(A\\) is an \\(m\\times n\\) matrix where \\(m=n=3\\). This is sometimes called a square matrix.\nMore generally, matrix \\(B\\) is an \\(m\\times n\\) matrix where the elements look like this: \\[B=\n\\begin{bmatrix}\nb_{11} & b_{12} & b_{13} & \\ldots & b_{1n} \\\\\nb_{21} & b_{22} & b_{23} & \\ldots & b_{2n} \\\\\n\\vdots & \\vdots & \\vdots & \\ldots & \\vdots \\\\\nb_{m1} & b_{m2} & b_{m3} & \\ldots & b_{mn}\n\\end{bmatrix}\\]\nThus \\(b_{23}\\) refers to the second unit down and third across. More generally, we refer to row indices as \\(i\\) and to column indices as \\(j\\).\nIn R, we can access a matrix’s elements using square brackets:\n\n# In matrix N, access the element at 1st row and 3rd column.\nN[1,3]\n\n[1] 9\n\n\n\n# In matrix N, access the element at 4th row and 2nd column.\nN[4,2]\n\n[1] 8\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhen trying to identify a specific element, the first subscript is the element’s row and the second subscript is the element’s column (always in that order)."
  },
  {
    "objectID": "03_matrices.html#matrix-operations",
    "href": "03_matrices.html#matrix-operations",
    "title": "3  Matrices",
    "section": "3.4 Matrix operations",
    "text": "3.4 Matrix operations\n\n3.4.1 Addition and subtraction\n\nAddition and subtraction are straightforward operations.\nMatrices must have exactly the same dimensions for both of these operations.\nWe add or subtract each element with the corresponding element from the other matrix.\nThis is expressed as follows:\n\n\\[A \\pm B=C\\]\n\\[c_{ij}=a_{ij} \\pm b_{ij} \\text{ }\\forall i,j\\]\n\\[\\begin{bmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\n\\pm\n\\begin{bmatrix}\nb_{11} & b_{12} & b_{13}\\\\\nb_{21} & b_{22} & b_{23}\\\\\nb_{31} & b_{32} & b_{33}\n\\end{bmatrix}\\] \\[=\\] \\[\\begin{bmatrix}\na_{11}\\pm b_{11} & a_{12}\\pm b_{12} & a_{13}\\pm b_{13}\\\\\na_{21}\\pm b_{21} & a_{22}\\pm b_{22} & a_{23}\\pm b_{23}\\\\\na_{31}\\pm b_{31} & a_{32}\\pm b_{32} & a_{33}\\pm b_{33}\n\\end{bmatrix}\\]\n\nAddition and subtraction in R\nWe start by creating two 2x3 matrices:\n\n# Create two 2x3 matrices.\nmatrix1 &lt;- matrix(c(3, 9, -1, 4, 2, 6), nrow = 2)\nmatrix1\n\n     [,1] [,2] [,3]\n[1,]    3   -1    2\n[2,]    9    4    6\n\n\n\nmatrix2 &lt;- matrix(c(5, 2, 0, 9, 3, 4), nrow = 2)\nmatrix2\n\n     [,1] [,2] [,3]\n[1,]    5    0    3\n[2,]    2    9    4\n\n\nWe can simply use the + and - operators for addition and substraction:\n\nmatrix1 + matrix2\n\n     [,1] [,2] [,3]\n[1,]    8   -1    5\n[2,]   11   13   10\n\n\n\nmatrix1 - matrix2\n\n     [,1] [,2] [,3]\n[1,]   -2   -1   -1\n[2,]    7   -5    2\n\n\n\n\n\n\n\n\nExercise\n\n\n\n(Use code for one of these and do the other one by hand!)\n1) Calculate \\(A + B\\)\n\\[A= \\begin{bmatrix}\n1 & 0 \\\\\n-2 & -1\n\\end{bmatrix}\\]\n\\[B = \\begin{bmatrix}\n5 & 1 \\\\\n2 & -1\n\\end{bmatrix}\\]\n\n2) Calculate \\(A - B\\)\n\\[A= \\begin{bmatrix}\n6 & -2 & 8 & 12 \\\\\n4 & 42 & 8 & -6\n\\end{bmatrix}\\]\n\\[B = \\begin{bmatrix}\n18 & 42 & 3 & 7 \\\\\n0 & -42 & 15 & 4\n\\end{bmatrix}\\]\n\n\n\n\n\n3.4.2 Scalar multiplication\nScalar multiplication is very intuitive. As we know, a scalar is a single number. We multiply each value in the matrix by the scalar to perform this operation.\nFormally, this is expressed as follows: \\[A =\n\\begin{bmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\\] \\[cA =\n\\begin{bmatrix}\nca_{11} & ca_{12} & ca_{13}\\\\\nca_{21} & ca_{22} & ca_{23}\\\\\nca_{31} & ca_{32} & ca_{33}\n\\end{bmatrix}\\]\nIn R, all we need to do is take an established matrix and multiply it by some scalar:\n\n# matrix1 from our previous example\nmatrix1\n\n     [,1] [,2] [,3]\n[1,]    3   -1    2\n[2,]    9    4    6\n\n\n\nmatrix1 * 3\n\n     [,1] [,2] [,3]\n[1,]    9   -3    6\n[2,]   27   12   18\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCalculate \\(2\\times A\\) and \\(-3 \\times B\\). Again, do one by hand and the other one using R.\n\\[A= \\begin{bmatrix}\n    1 & 4 & 8 \\\\\n    0 & -1 & 3\n    \\end{bmatrix}\\] \\[ B = \\begin{bmatrix}\n    -15 & 1 & 5 \\\\\n    2 & -42 & 0 \\\\\n    7 & 1 & 6\n    \\end{bmatrix}\\]\n\n\n\n\n3.4.3 Matrix multiplication\n\nMultiplying matrices is slightly trickier than multiplying scalars.\nTwo matrices must be conformable for them to be multiplied together. This means that the number of columns in the first matrix equals the number of rows in the second.\nWhen multiplying \\(A \\times B\\), if \\(A\\) is \\(m \\times n\\), \\(B\\) must have \\(n\\) rows.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe conformability requirement never changes. Before multiplying anything, check to make sure the matrices are indeed conformable.\n\n\n\nThe resulting matrix will have the same number of rows as the first matrix and the number of columns in the second. For example, if \\(A\\) is \\(i \\times k\\) and \\(B\\) is \\(k \\times j\\), then \\(A \\times B\\) will be \\(i \\times j\\).\n\n\nWhich of the following can we multiply? What will be the dimensions of the resulting matrix? \\[\\begin{aligned}\nB=\n\\begin{bmatrix}\n2 \\\\\n3\\\\\n4\\\\\n1\n\\end{bmatrix}\nM =\n\\begin{bmatrix}\n1 & 0 & 2\\\\\n1 & 2 & 4\\\\\n2 & 3 & 2\n\\end{bmatrix}\nL =\n\\begin{bmatrix}\n6 & 5 & -1\\\\\n1 & 4 & 3\n\\end{bmatrix}\n\\end{aligned}\\]\nWhy can’t we multiply in the opposite order?\n\n\n\n\n\n\nWarning\n\n\n\nWhen multiplying matrices, order matters. Even if multiplication is possible in both directions, in general \\(AB \\neq BA\\).\n\n\n\nMultiplication steps\n\nMultiply each row by each column, summing up each pair of multiplied terms.\n\n\n\n\n\n\n\nTip\n\n\n\nThis is sometimes to referred to as the “dot product,” where we multiply matching members, then sum up.\n\n\n\nThe element in position \\(ij\\) is the sum of the products of elements in the \\(i\\)th row of the first matrix (\\(A\\)) and the corresponding elements in the \\(j\\)th column of the second matrix (\\(B\\)). \\[c_{ij}=\\sum_{k=1}^n a_{ik}b_{kj}\\]\n\n\n\nExample\nSuppose a company manufactures two kinds of furniture: chairs and sofas.\n\nA chair costs $100 for wood, $270 for cloth, and $130 for feathers.\nEach sofa costs $150 for wood, $420 for cloth, and $195 for feathers.\n\n\n\n\n\nChair\nSofa\n\n\n\n\nWood\n100\n150\n\n\nCloth\n270\n420\n\n\nFeathers\n130\n195\n\n\n\nThe same information about unit cost (\\(C\\)) can be presented as a matrix.\n\\[C = \\begin{bmatrix}\n100 & 150\\\\\n270 & 420\\\\\n130 & 195\n\\end{bmatrix}\\]\nNote that each of the three rows of this 3 x 2 matrix represents a material (wood, cloth, or feathers), and each of the two columns represents a product (chair or coach). The elements are the unit cost (in USD).\n\nNow, suppose that the company will produce 45 chairs and 30 sofas this month. This production quantity can be represented in the following table, and also as a 2 x 1 matrix (\\(Q\\)):\n\n\n\nProduct\nQuantity\n\n\n\n\nChair\n45\n\n\nSofa\n30\n\n\n\n\\[Q = \\begin{bmatrix}\n45 \\\\\n30\n\\end{bmatrix}\\]\nWhat will be the company’s total cost? The “total expenditure” is equal to the “unit cost” times the “production quantity” (the number of units).\nThe total expenditure (\\(E\\)) for each material this month is calculated by multiplying these two matrices.\n\\[\\begin{aligned} E = CQ =\n\\begin{bmatrix}\n100 & 150\\\\\n270 & 420\\\\\n130 & 195\n\\end{bmatrix}\n\\begin{bmatrix}\n45 \\\\\n30\n\\end{bmatrix} =\n\\begin{bmatrix}\n(100)(45) + (150)(30) \\\\\n(270)(45) + (420)(30) \\\\\n(130)(45) + (195)(30)\n\\end{bmatrix} =\n\\begin{bmatrix}\n9,000 \\\\\n24,750 \\\\\n11,700\n\\end{bmatrix}\n\\end{aligned}\\]\nMultiplying the 3x2 Cost matrix (\\(C\\)) times the 2x1 Quantity matrix (\\(Q\\)) yields the 3x1 Expenditure matrix (\\(E\\)).\nAs a result of this matrix multiplication, we determine that this month the company will incur expenditures of:\n\n$9,000 for wood\n$24,750 for cloth\n$11,700 for feathers.\n\n\n\nMatrix multiplication in R\nBefore attempting matrix multiplication, we must make sure the matrices are conformable (as we do for our manual calculations).\nThen we can multiply our matrices together using the %*% operator.\n\nC &lt;- matrix(c(100, 270, 130, 150, 420, 195), nrow = 3)\nC\n\n     [,1] [,2]\n[1,]  100  150\n[2,]  270  420\n[3,]  130  195\n\n\n\nQ &lt;- matrix(c(45, 30), nrow = 2)\nQ\n\n     [,1]\n[1,]   45\n[2,]   30\n\n\n\nC %*% Q\n\n      [,1]\n[1,]  9000\n[2,] 24750\n[3,] 11700\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you have a missing value or NA in one of the matrices you are trying to multiply (something we will discuss in further detail in the next module), you will have NAs in your resulting matrix.\n\n\n\n\n\n\n3.4.4 Properties of operations\n\nAddition and subtraction:\n\nAssociative: \\((A \\pm B) \\pm C = A \\pm (B \\pm C)\\)\nCommunicative: \\(A \\pm B = B \\pm A\\)\n\nMultiplication:\n\n\\(AB \\neq BA\\)\n\\(A(BC) = (AB)C\\)\n\\(A(B+C) = AB + AC\\)\n\\((A+B)C = AC + BC\\)"
  },
  {
    "objectID": "03_matrices.html#special-matrices",
    "href": "03_matrices.html#special-matrices",
    "title": "3  Matrices",
    "section": "3.5 Special matrices",
    "text": "3.5 Special matrices\nSquare matrix\n\nIn a square matrix, the number of rows equals the number of columns (\\(m=n\\)):\nThe diagonal of a matrix is a set of numbers consisting of the elements on the line from the upper-left-hand to the lower-right-hand corner of the matrix. Diagonals are particularly useful in square matrices.\nThe trace of a matrix, denoted as \\(tr(A)\\), is the sum of the diagonal elements of the matrix.\n\nDiagonal matrix:\n\nIn a diagonal matrix, all of the elements of the matrix that are not on the diagonal are equal to zero.\n\nScalar matrix:\n\nA scalar matrix is a diagonal matrix where the diagonal elements are all equal to each other. In other words, we’re really only concerned with one scalar (or element) held in the diagonal.\n\nIdentity matrix:\n\nThe identity matrix is a scalar matrix with all of the diagonal elements equal to one.\nRemember that, as with all diagonal matrices, the off-diagonal elements are equal to zero.\nThe capital letter \\(I\\) is reserved for the identity matrix. For convenience, a 3x3 identity matrix can be denoted as \\(I_3\\)."
  },
  {
    "objectID": "03_matrices.html#transpose",
    "href": "03_matrices.html#transpose",
    "title": "3  Matrices",
    "section": "3.6 Transpose",
    "text": "3.6 Transpose\nThe transpose is the original matrix with the rows and the columns interchanged.\nThe notation is either \\(J'\\) (“J prime”) or \\(J^T\\) (“J transpose”).\n\\[J =\n\\begin{bmatrix}\n4 & 5\\\\\n3 & 0\\\\\n7 & -2\n\\end{bmatrix}\\]\n\\[J' = J^T =\n\\begin{bmatrix}\n4 & 3 & 7 \\\\\n5 & 0 & -2\n\\end{bmatrix}\\]\nIn R, we use t() to get the transpose.\n\nJ &lt;- matrix(c(4, 3, 7, 5, 0, -2), ncol = 2)\nJ\n\n     [,1] [,2]\n[1,]    4    5\n[2,]    3    0\n[3,]    7   -2\n\n\n\nt(J)\n\n     [,1] [,2] [,3]\n[1,]    4    3    7\n[2,]    5    0   -2"
  },
  {
    "objectID": "03_matrices.html#inverse",
    "href": "03_matrices.html#inverse",
    "title": "3  Matrices",
    "section": "3.7 Inverse",
    "text": "3.7 Inverse\n\nJust like a number has a reciprocal, a matrix has an inverse.\nWhen we multiply a matrix by its inverse we get the identity matrix (which is like “1” for matrices).\n\n\\[A × A^{-1} = I\\]\n\nThe inverse of A is \\(A^{-1}\\) only when:\n\n\\[AA^{-1} = A^{-1}A = I\\]\n\nSometimes there is no inverse at all.\n\n\n\n\n\n\n\nNote\n\n\n\nFor now, don’t worry about calculating the inverse of a matrix manually. This is the type of task we use R for.\n\n\n\nIn R, we use the solve() function to calculate the inverse of a matrix:\n\n\nA &lt;- matrix(c(3, 2, 5, 2, 3, 2, 5, 2, 4), ncol = 3)\nA\n\n     [,1] [,2] [,3]\n[1,]    3    2    5\n[2,]    2    3    2\n[3,]    5    2    4\n\n\n\nsolve(A)\n\n            [,1]        [,2]       [,3]\n[1,] -0.29629630 -0.07407407  0.4074074\n[2,] -0.07407407  0.48148148 -0.1481481\n[3,]  0.40740741 -0.14814815 -0.1851852"
  },
  {
    "objectID": "03_matrices.html#linear-systems-and-matrices",
    "href": "03_matrices.html#linear-systems-and-matrices",
    "title": "3  Matrices",
    "section": "3.8 Linear systems and matrices",
    "text": "3.8 Linear systems and matrices\n\nA system of equations can be represented by an augmented matrix.\nSystem of equations: \\[{\\color{red}{3}}x + {\\color{green}{6}}y = {\\color{blue}{12}}\\] \\[{\\color{red}{5}}x + {\\color{green}{10}}y = {\\color{blue}{25}}\\]\nIn an augmented matrix, each row represents one equation in the system and each column represents a variable or the constant terms. \\[\\begin{bmatrix}\n{\\color{red}{3}} & {\\color{green}{6}} & {\\color{blue}{12}}\\\\\n{\\color{red}{5}} & {\\color{green}{10}} & {\\color{blue}{25}}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "03_matrices.html#ols-and-matrices",
    "href": "03_matrices.html#ols-and-matrices",
    "title": "3  Matrices",
    "section": "3.9 OLS and matrices",
    "text": "3.9 OLS and matrices\n\nWe can use the logic above to calculate estimates for our ordinary least squares (OLS) models.\nOLS is a linear regression technique used to find the best-fitting line for a set of data points (observations) by minimizing the residuals (the differences between the observed and predicted values).\nWe minimize the sum of the squared errors.\n\n\n3.9.1 Dependent variable\n\nSuppose, for example, we have a sample consisting of \\(n\\) observations.\nThe dependent variable is denoted as an \\(n \\times1\\) column vector.\n\n\\[Y = \\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\ny_3 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix}\\]\n\n\n3.9.2 Independent variables\n\nSuppose there are \\(k\\) independent variables and a constant term, meaning \\(k+1\\) columns and \\(n\\) rows.\nWe can represent these variables as an \\(n \\times (k+1)\\) matrix, expressed as follows:\n\n\\[X= \\begin{bmatrix}\n1 & x_{11} & \\dots & x_{1k} \\\\\n1 & x_{21} & \\dots & x_{2k} \\\\\n\\vdots & \\vdots & \\dots & \\vdots \\\\\n1 & x_{n1} & \\dots & x_{nk}\n\\end{bmatrix}\\]\n\n\\(x_{ij}\\) is the \\(i\\)-th observation of the \\(j\\)-th independent variable.\n\n\n\n3.9.3 Linear regression model\n\nLet’s say we have 173 observations (n = 173) and 2 IVs (k = 3).\nThis can be expressed as the following linear equation: \\[y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\epsilon\\]\nIn matrix form, we have: \\[\\begin{aligned} \\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} = \\begin{bmatrix}\n1 & x_{11} & x_{21} \\\\\n1 & x_{21} & x_{22} \\\\\n\\vdots & \\vdots & \\vdots \\\\\n1 & x_{1173} & x_{2173}\n\\end{bmatrix} \\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\beta_2\n\\end{bmatrix} + \\begin{bmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\vdots \\\\\n\\epsilon_{173}\n\\end{bmatrix}\\end{aligned} \\]\nAll 173 equations can be represented by: \\[y=X\\beta+\\epsilon\\]\n\n\n\n3.9.4 Estimates\n\nWithout getting too much into the mechanics, we can calculate our coefficient estimates with matrix algebra using the following equation:\n\n\\[\\hat{\\beta} = (X'X)^{-1}X'Y\\]\n\nRead aloud, we say “X prime X inverse, X prime Y”.\nThe little hat on our beta (\\(\\hat{\\beta}\\)) signifies that these are estimates, that is our OLS estimators.\nRemember, the OLS method is to choose \\(\\hat{\\beta}\\) such that the sum of squared residuals (“SSR”) is minimized.\n\n\n3.9.4.1 Example in R\n\nWe will load the mtcars data set (our favorite) for this example, which contains data about many different car models.\n\n\ncars_df &lt;- mtcars\n\n\nNow, we want to estimate the association between hp (horsepower) and wt (weight), our independent variables, and mpg (miles per gallon), our dependent variable.\nFirst, we transform our dependent variable into a matrix, using the as.matrix function and specifying the column of the mtcars data set to create a column vector of our observed values for the DV.\n\n\nY &lt;- as.matrix(cars_df[,1])\nY\n\n      [,1]\n [1,] 21.0\n [2,] 21.0\n [3,] 22.8\n [4,] 21.4\n [5,] 18.7\n [6,] 18.1\n [7,] 14.3\n [8,] 24.4\n [9,] 22.8\n[10,] 19.2\n[11,] 17.8\n[12,] 16.4\n[13,] 17.3\n[14,] 15.2\n[15,] 10.4\n[16,] 10.4\n[17,] 14.7\n[18,] 32.4\n[19,] 30.4\n[20,] 33.9\n[21,] 21.5\n[22,] 15.5\n[23,] 15.2\n[24,] 13.3\n[25,] 19.2\n[26,] 27.3\n[27,] 26.0\n[28,] 30.4\n[29,] 15.8\n[30,] 19.7\n[31,] 15.0\n[32,] 21.4\n\n\n\nNext, we do the same thing for our independent variables of interest, and our constant.\n\n\n# create two separate matrices for IVs\nX1 &lt;- as.matrix(cars_df[,4])\nX2 &lt;- as.matrix(cars_df[,6])\n\n# create constant column\n\n# bind them altogether into one matrix\nconstant &lt;-  rep(1,nrow(X1))\nX &lt;- cbind(constant,X1,X2)\nX\n\n      constant          \n [1,]        1 110 2.620\n [2,]        1 110 2.875\n [3,]        1  93 2.320\n [4,]        1 110 3.215\n [5,]        1 175 3.440\n [6,]        1 105 3.460\n [7,]        1 245 3.570\n [8,]        1  62 3.190\n [9,]        1  95 3.150\n[10,]        1 123 3.440\n[11,]        1 123 3.440\n[12,]        1 180 4.070\n[13,]        1 180 3.730\n[14,]        1 180 3.780\n[15,]        1 205 5.250\n[16,]        1 215 5.424\n[17,]        1 230 5.345\n[18,]        1  66 2.200\n[19,]        1  52 1.615\n[20,]        1  65 1.835\n[21,]        1  97 2.465\n[22,]        1 150 3.520\n[23,]        1 150 3.435\n[24,]        1 245 3.840\n[25,]        1 175 3.845\n[26,]        1  66 1.935\n[27,]        1  91 2.140\n[28,]        1 113 1.513\n[29,]        1 264 3.170\n[30,]        1 175 2.770\n[31,]        1 335 3.570\n[32,]        1 109 2.780\n\n\n\nNext, we calculate \\(X'X\\), \\(X'Y\\), and \\((X'X)^{-1}\\).\n\n\nDon’t forget to use %*% for matrix multiplication!\n\n\n# X prime X\nXpX &lt;- t(X)%*%X\n\n# X prime X inverse\nXpXinv &lt;- solve(XpX)\n\n# X prime Y\nXpY &lt;- t(X)%*%Y\n\n# beta coefficient estimates\nbhat &lt;- XpXinv %*% XpY\nbhat\n\n                [,1]\nconstant 37.22727012\n         -0.03177295\n         -3.87783074\n\n\n\n\n\n\nArel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman. 2018. “Countrycode: An r Package to Convert Country Names and Country Codes.” Journal of Open Source Software 3 (28): 848. https://doi.org/10.21105/joss.00848.\n\n\nBank, World. 2023. “World Bank Open Data.” https://data.worldbank.org/.\n\n\nDahlberg, Stefan, Aksen Sundström, Sören Holmberg, Bo Rothstein, Natalia Alvarado Pachon, Cem Mert Dalli, and Yente Meijers. 2023. “The Quality of Government Basic Dataset, Version Jan23.” University of Gothenburg: The Quality of Government Institute. https://www.gu.se/en/quality-government doi:10.18157/qogbasjan23.\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nRobinson, David. 2020. Fuzzyjoin: Join Tables Together on Inexact Matching. https://github.com/dgrtwo/fuzzyjoin.\n\n\nSmith, Danny. 2020. Survey Research Datasets and R. https://socialresearchcentre.github.io/r_survey_datasets/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "04_tidy_data2.html#loading-data-in-different-formats.",
    "href": "04_tidy_data2.html#loading-data-in-different-formats.",
    "title": "4  Tidy data analysis II",
    "section": "4.1 Loading data in different formats.",
    "text": "4.1 Loading data in different formats.\nIn this module we will use cross-national data from the Quality of Government (QoG) project (Dahlberg et al., 2023).\nNotice how in the data/ folder we have multiple versions of the same dataset (a subset of the QOG basic dataset): .csv (comma-separated values), .rds (R), .xlsx (Excel), .dta (Stata), and .sav (SPSS).\n\n4.1.1 CSV and R data files\nWe can use the read_csv() and read_rds() functions from the tidyverse1 to read the .csv and .rds (R) data files:\n\nqog_csv &lt;- read_csv(\"data/sample_qog_bas_ts_jan23.csv\")\n\nRows: 1085 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): cname, ccodealp, region, ht_colonial\ndbl (4): year, wdi_pop, vdem_polyarchy, vdem_corr\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nqog_rds &lt;- read_rds(\"data/sample_qog_bas_ts_jan23.rds\")\n\nFor reading files from other software (Excel, Stata, or SPSS), we need to load additional packages. Luckily, they are automatically installed when one installs the tidyverse.\n\n\n4.1.2 Excel data files\nFor Excel files (.xls or .xlsx files), the readxl package has a handy read_excel() function.\n\nlibrary(readxl)\nqog_excel &lt;- read_excel(\"data/sample_qog_bas_ts_jan23.xlsx\")\n\n\n\n\n\n\n\nTip\n\n\n\nUseful arguments of the read_excel() function include sheet =, which reads particular sheets (specified via their positions or sheet names), and range =, which extracts a particular cell range (e.g., `A5:E25`).\n\n\n\n\n4.1.3 Stata and SPSS data files\nTo load files from Stata (.dta) or SPSS (.spss), one needs the haven package and its properly-named read_stata() and read_spss() functions:\n\nlibrary(haven)\nqog_stata &lt;- read_stata(\"data/sample_qog_bas_ts_jan23.dta\")\nqog_spss &lt;- read_spss(\"data/sample_qog_bas_ts_jan23.sav\")\n\n\n\n\n\n\n\nTip\n\n\n\nDatasets from Stata and SPSS can have additional properties, like variable labels and special types of missing values. To learn more about this, check out the “Labelled data” chapter from Danny Smith’s Survey Research Datasets and R (2020).\n\n\n\n\n4.1.4 Our data for this session\nWe will rename one of our objects to qog:\n\nqog &lt;- qog_csv\nqog\n\n# A tibble: 1,085 × 8\n   cname      ccodealp  year region wdi_pop vdem_polyarchy vdem_corr ht_colonial\n   &lt;chr&gt;      &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      \n 1 Antigua a… ATG       1990 Carib…   63328             NA        NA British    \n 2 Antigua a… ATG       1991 Carib…   63634             NA        NA British    \n 3 Antigua a… ATG       1992 Carib…   64659             NA        NA British    \n 4 Antigua a… ATG       1993 Carib…   65834             NA        NA British    \n 5 Antigua a… ATG       1994 Carib…   67072             NA        NA British    \n 6 Antigua a… ATG       1995 Carib…   68398             NA        NA British    \n 7 Antigua a… ATG       1996 Carib…   69798             NA        NA British    \n 8 Antigua a… ATG       1997 Carib…   71218             NA        NA British    \n 9 Antigua a… ATG       1998 Carib…   72572             NA        NA British    \n10 Antigua a… ATG       1999 Carib…   73821             NA        NA British    \n# ℹ 1,075 more rows\n\n\nThis dataset is a small sample of QOG, which contains data for countries in the Americas from 1990 to 2020. The observational unit is thus country-year. You can access the full codebook online. The variables are as follows:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ncname\nCountry name\n\n\nccodealp\nCountry code (ISO-3 character convention)\n\n\nyear\nYear\n\n\nregion\nRegion (following legacy WDI convention). Added to QOG by us.\n\n\nwdi_pop\nTotal population, from the World Development Indicators\n\n\nvdem_polyarchy\nV-Dem’s polyarchy index (electoral democracy)\n\n\nvdem_corr\nV-Dem’s corruption index\n\n\nht_colonial\nFormer colonial ruler"
  },
  {
    "objectID": "04_tidy_data2.html#recoding-variables",
    "href": "04_tidy_data2.html#recoding-variables",
    "title": "4  Tidy data analysis II",
    "section": "4.2 Recoding variables",
    "text": "4.2 Recoding variables\nTake a look at the ht_colonial variable. We can do a simple tabulation with count():\n\nqog |&gt; \n  count(ht_colonial)\n\n# A tibble: 6 × 2\n  ht_colonial         n\n  &lt;chr&gt;           &lt;int&gt;\n1 British           372\n2 Dutch              31\n3 French             31\n4 Never colonized    62\n5 Portuguese         31\n6 Spanish           558\n\n\nWe might want to recode this variable. For instance, we could create a dummy/binary variable for whether the country was a British colony. We can do this with if_else(), which works with logical conditions:\n\nqog |&gt; \n  # the arguments are condition, true (what to do if true), false\n  mutate(d_britishcol = if_else(ht_colonial == \"British\", 1, 0)) |&gt; \n  count(d_britishcol)\n\n# A tibble: 2 × 2\n  d_britishcol     n\n         &lt;dbl&gt; &lt;int&gt;\n1            0   713\n2            1   372\n\n\nInstead of a numeric classification (0 and 1), we could use characters:\n\nqog |&gt; \n  mutate(cat_britishcol = if_else(ht_colonial == \"British\", \"British\", \"Other\")) |&gt; \n  count(cat_britishcol)\n\n# A tibble: 2 × 2\n  cat_britishcol     n\n  &lt;chr&gt;          &lt;int&gt;\n1 British          372\n2 Other            713\n\n\nif_else() is great for binary recoding. But sometimes we want to create more than two categories. We can use case_when():\n\nqog |&gt; \n  # syntax is condition ~ value\n  mutate(cat_col = case_when(\n    ht_colonial == \"British\" ~ \"British\",\n    ht_colonial == \"Spanish\" ~ \"Spanish\", \n    .default = \"Other\" # what to do in all other cases\n  )) |&gt; \n  count(cat_col)\n\n# A tibble: 3 × 2\n  cat_col     n\n  &lt;chr&gt;   &lt;int&gt;\n1 British   372\n2 Other     155\n3 Spanish   558\n\n\nThe .default = argument in case_when() can also be used to leave the variable as-is for non-specified cases. For example, let’s combine Portuguese and Spanish colonies:\n\nqog |&gt; \n  # syntax is condition ~ value\n  mutate(cat_col = case_when(\n    ht_colonial %in% c(\"Spanish\", \"Portuguese\") ~ \"Spanish/Portuguese\",\n    .default = ht_colonial # what to do in all other cases\n  )) |&gt; \n  count(cat_col)\n\n# A tibble: 5 × 2\n  cat_col                n\n  &lt;chr&gt;              &lt;int&gt;\n1 British              372\n2 Dutch                 31\n3 French                31\n4 Never colonized       62\n5 Spanish/Portuguese   589\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nCreate a dummy variable, d_large_pop, for whether the country-year has a population of more than 1 million. Then compute its mean. Your code:\nWhich countries are recorded as “Never colonized”? Change their values to other reasonable codings and compute a tabulation with count(). Your code:"
  },
  {
    "objectID": "04_tidy_data2.html#missing-values",
    "href": "04_tidy_data2.html#missing-values",
    "title": "4  Tidy data analysis II",
    "section": "4.3 Missing values",
    "text": "4.3 Missing values\nMissing values are commonplace in real datasets. In R, missing values are a special type of value in vectors, denoted as NA.\n\n\n\n\n\n\nWarning\n\n\n\nThe special value NA is different from the character value “NA”. For example, notice that a numeric vector can have NAs, while it obviously cannot hold the character value “NA”:\n\nc(5, 4.6, NA, 8)\n\n[1] 5.0 4.6  NA 8.0\n\n\n\n\nA quick way to check for missing values in small datasets is with the summary() function:\n\nsummary(qog)\n\n    cname             ccodealp              year         region         \n Length:1085        Length:1085        Min.   :1990   Length:1085       \n Class :character   Class :character   1st Qu.:1997   Class :character  \n Mode  :character   Mode  :character   Median :2005   Mode  :character  \n                                       Mean   :2005                     \n                                       3rd Qu.:2013                     \n                                       Max.   :2020                     \n                                                                        \n    wdi_pop          vdem_polyarchy     vdem_corr      ht_colonial       \n Min.   :    40542   Min.   :0.0710   Min.   :0.0260   Length:1085       \n 1st Qu.:   389131   1st Qu.:0.5570   1st Qu.:0.1890   Class :character  \n Median :  5687744   Median :0.7030   Median :0.5550   Mode  :character  \n Mean   : 25004057   Mean   :0.6569   Mean   :0.4922                     \n 3rd Qu.: 16195902   3rd Qu.:0.8030   3rd Qu.:0.7540                     \n Max.   :331501080   Max.   :0.9160   Max.   :0.9630                     \n                     NA's   :248      NA's   :248                        \n\n\nNotice that we have missingness in the vdem_polyarchy and vdem_corr variables. We might want to filter the dataset to see which observations are in this situation:\n\nqog |&gt; \n  filter(vdem_polyarchy == NA | vdem_corr == NA)\n\n# A tibble: 0 × 8\n# ℹ 8 variables: cname &lt;chr&gt;, ccodealp &lt;chr&gt;, year &lt;dbl&gt;, region &lt;chr&gt;,\n#   wdi_pop &lt;dbl&gt;, vdem_polyarchy &lt;dbl&gt;, vdem_corr &lt;dbl&gt;, ht_colonial &lt;chr&gt;\n\n\nBut the code above doesn’t work! To refer to missing values in logical conditions, we cannot use == NA. Instead, we need to use the is.na() function:\n\nqog |&gt; \n  filter(is.na(vdem_polyarchy) | is.na(vdem_corr))\n\n# A tibble: 248 × 8\n   cname      ccodealp  year region wdi_pop vdem_polyarchy vdem_corr ht_colonial\n   &lt;chr&gt;      &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      \n 1 Antigua a… ATG       1990 Carib…   63328             NA        NA British    \n 2 Antigua a… ATG       1991 Carib…   63634             NA        NA British    \n 3 Antigua a… ATG       1992 Carib…   64659             NA        NA British    \n 4 Antigua a… ATG       1993 Carib…   65834             NA        NA British    \n 5 Antigua a… ATG       1994 Carib…   67072             NA        NA British    \n 6 Antigua a… ATG       1995 Carib…   68398             NA        NA British    \n 7 Antigua a… ATG       1996 Carib…   69798             NA        NA British    \n 8 Antigua a… ATG       1997 Carib…   71218             NA        NA British    \n 9 Antigua a… ATG       1998 Carib…   72572             NA        NA British    \n10 Antigua a… ATG       1999 Carib…   73821             NA        NA British    \n# ℹ 238 more rows\n\n\nNotice that, in most R functions, missing values are “contagious.” This means that any missing value will contaminate the operation and carry over to the results. For example:\n\nqog |&gt; \n  summarize(mean_vdem_polyarchy = mean(vdem_polyarchy))\n\n# A tibble: 1 × 1\n  mean_vdem_polyarchy\n                &lt;dbl&gt;\n1                  NA\n\n\nSometimes we’d like to perform our operations even in the presence of missing values, simply excluding them. Most basic R functions have an na.rm = argument to do this:\n\nqog |&gt; \n  summarize(mean_vdem_polyarchy = mean(vdem_polyarchy, na.rm = T))\n\n# A tibble: 1 × 1\n  mean_vdem_polyarchy\n                &lt;dbl&gt;\n1               0.657\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCalculate the median value of the corruption variable for each region (i.e., perform a grouped summary). Your code:"
  },
  {
    "objectID": "04_tidy_data2.html#pivoting-data",
    "href": "04_tidy_data2.html#pivoting-data",
    "title": "4  Tidy data analysis II",
    "section": "4.4 Pivoting data",
    "text": "4.4 Pivoting data\nWe will now load another time-series cross-sectional dataset, but in a slightly different format. It’s adapted from the World Bank’s World Development Indicators (WDI) (2023) and records gross domestic product at purchasing power parity (GDP PPP).\n\ngdp &lt;- read_excel(\"data/wdi_gdp_ppp.xlsx\")\n\n\ngdp\n\n# A tibble: 266 × 35\n   country_name        country_code   `1990`   `1991`   `1992`   `1993`   `1994`\n   &lt;chr&gt;               &lt;chr&gt;           &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 Aruba               ABW           2.03e 9  2.19e 9  2.32e 9  2.48e 9  2.69e 9\n 2 Africa Eastern and… AFE           9.41e11  9.42e11  9.23e11  9.19e11  9.35e11\n 3 Afghanistan         AFG          NA       NA       NA       NA       NA      \n 4 Africa Western and… AFW           5.76e11  5.84e11  5.98e11  5.92e11  5.91e11\n 5 Angola              AGO           6.85e10  6.92e10  6.52e10  4.95e10  5.02e10\n 6 Albania             ALB           1.59e10  1.14e10  1.06e10  1.16e10  1.26e10\n 7 Andorra             AND          NA       NA       NA       NA       NA      \n 8 Arab World          ARB           2.19e12  2.25e12  2.35e12  2.41e12  2.48e12\n 9 United Arab Emirat… ARE           2.01e11  2.03e11  2.10e11  2.12e11  2.27e11\n10 Argentina           ARG           4.61e11  5.04e11  5.43e11  5.88e11  6.22e11\n# ℹ 256 more rows\n# ℹ 28 more variables: `1995` &lt;dbl&gt;, `1996` &lt;dbl&gt;, `1997` &lt;dbl&gt;, `1998` &lt;dbl&gt;,\n#   `1999` &lt;dbl&gt;, `2000` &lt;dbl&gt;, `2001` &lt;dbl&gt;, `2002` &lt;dbl&gt;, `2003` &lt;dbl&gt;,\n#   `2004` &lt;dbl&gt;, `2005` &lt;dbl&gt;, `2006` &lt;dbl&gt;, `2007` &lt;dbl&gt;, `2008` &lt;dbl&gt;,\n#   `2009` &lt;dbl&gt;, `2010` &lt;dbl&gt;, `2011` &lt;dbl&gt;, `2012` &lt;dbl&gt;, `2013` &lt;dbl&gt;,\n#   `2014` &lt;dbl&gt;, `2015` &lt;dbl&gt;, `2016` &lt;dbl&gt;, `2017` &lt;dbl&gt;, `2018` &lt;dbl&gt;,\n#   `2019` &lt;dbl&gt;, `2020` &lt;dbl&gt;, `2021` &lt;dbl&gt;, `2022` &lt;dbl&gt;\n\n\nNote how the information is recorded differently. Here columns are not variables, but years. We call datasets like this one wide, in contrast to the long datasets we have seen before. In general, R and the tidyverse work much nicer with long datasets. Luckily, the tidyr package of the tidyverse makes it easy to convert datasets between these two formats.\n\n\n\nSource: Illustration by Allison Horst, adapted by Peter Higgins.\n\n\nWe will use the pivot_longer() function:\n\ngdp_long &lt;- gdp |&gt; \n  pivot_longer(cols = -c(country_name, country_code), # cols to not pivot\n               names_to = \"year\", # how to name the column with names\n               values_to = \"wdi_gdp_ppp\",  # how to name the column with values\n               names_transform = as.integer) # make sure that years are numeric\ngdp_long\n\n# A tibble: 8,778 × 4\n   country_name country_code  year wdi_gdp_ppp\n   &lt;chr&gt;        &lt;chr&gt;        &lt;int&gt;       &lt;dbl&gt;\n 1 Aruba        ABW           1990 2025472682.\n 2 Aruba        ABW           1991 2186758474.\n 3 Aruba        ABW           1992 2315391348.\n 4 Aruba        ABW           1993 2484593045.\n 5 Aruba        ABW           1994 2688426606.\n 6 Aruba        ABW           1995 2756904694.\n 7 Aruba        ABW           1996 2789595753.\n 8 Aruba        ABW           1997 2986175079.\n 9 Aruba        ABW           1998 3045659222.\n10 Aruba        ABW           1999 3083365758.\n# ℹ 8,768 more rows\n\n\nDone! This is a much friendlier format to work with. For example, we can now do summaries:\n\ngdp_long |&gt; \n  summarize(mean_gdp_ppp = mean(wdi_gdp_ppp, na.rm = T), .by = country_name)\n\n# A tibble: 266 × 2\n   country_name                mean_gdp_ppp\n   &lt;chr&gt;                              &lt;dbl&gt;\n 1 Aruba                            3.38e 9\n 2 Africa Eastern and Southern      1.61e12\n 3 Afghanistan                      5.56e10\n 4 Africa Western and Central       1.15e12\n 5 Angola                           1.38e11\n 6 Albania                          2.56e10\n 7 Andorra                        NaN      \n 8 Arab World                       4.22e12\n 9 United Arab Emirates             4.29e11\n10 Argentina                        8.06e11\n# ℹ 256 more rows\n\n\n\n\n\n\n\n\nExercise\n\n\n\nConvert back gdp_long to a wide format using pivot_wider(). Check out the help file using ?pivot_wider. Your code:"
  },
  {
    "objectID": "04_tidy_data2.html#merging-datasets",
    "href": "04_tidy_data2.html#merging-datasets",
    "title": "4  Tidy data analysis II",
    "section": "4.5 Merging datasets",
    "text": "4.5 Merging datasets\nIt is extremely common to want to integrate data from multiple sources. Combining information from two datasets is called merging or joining.\nTo do this, we need ID variables in common between the two data sets. Using our QOG and WDI datasets, these variables will be country code (which in this case is shared between the two datasets) and year.\n\n\n\n\n\n\nTip\n\n\n\nStandardized unit codes (like country codes) are extremely useful when merging data. It’s harder than expected for a computer to realize that “Bolivia (Plurinational State of)” and “Bolivia” refer to the same unit. By default, these units will not be matched.2\n\n\nOkay, now to the merging. Imagine we want to add information about GDP to our QOG main dataset. To do so, we can use the left_join() function, from the tidyverse’s dplyr package:\n\nqog_plus &lt;- left_join(qog, # left data frame, which serves as a \"base\"\n                      gdp_long, # right data frame, from which to draw new columns\n                      by = c(\"ccodealp\" = \"country_code\", # can define name equivalencies!\n                             \"year\"))\n\n\nqog_plus |&gt; \n  # select variables for clarity\n  select(cname, ccodealp, year, wdi_pop, wdi_gdp_ppp)\n\n# A tibble: 1,085 × 5\n   cname               ccodealp  year wdi_pop wdi_gdp_ppp\n   &lt;chr&gt;               &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;\n 1 Antigua and Barbuda ATG       1990   63328  966660878.\n 2 Antigua and Barbuda ATG       1991   63634  987701012.\n 3 Antigua and Barbuda ATG       1992   64659  999143284.\n 4 Antigua and Barbuda ATG       1993   65834 1051896837.\n 5 Antigua and Barbuda ATG       1994   67072 1122128908.\n 6 Antigua and Barbuda ATG       1995   68398 1073208718.\n 7 Antigua and Barbuda ATG       1996   69798 1144088355.\n 8 Antigua and Barbuda ATG       1997   71218 1206688391.\n 9 Antigua and Barbuda ATG       1998   72572 1263778328.\n10 Antigua and Barbuda ATG       1999   73821 1310634399.\n# ℹ 1,075 more rows\n\n\n\n\n\n\n\n\nTip\n\n\n\nMost of the time, you’ll want to do a left_join(), which is great for adding new information to a “base” dataset, without dropping information from the latter. In limited situations, other types of joins can be helpful. To learn more about them, you can read Jenny Bryan’s excelent tutorial on dplyr joins.\n\n\n\n\n\n\n\n\nExercise\n\n\n\nThere is a dataset on country’s CO2 emissions, again from the World Bank (2023), in “data/wdi_co2.csv”. Load the dataset into R and add a new variable with its information, wdi_co2, to our qog_plus data frame. Finally, compute the average values of CO2 emissines per capita, by country. Tip: this exercise requires you to do many steps—plan ahead before you start coding! Your code:\n\n\n\n\n\n\nArel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman. 2018. “Countrycode: An r Package to Convert Country Names and Country Codes.” Journal of Open Source Software 3 (28): 848. https://doi.org/10.21105/joss.00848.\n\n\nBank, World. 2023. “World Bank Open Data.” https://data.worldbank.org/.\n\n\nDahlberg, Stefan, Aksen Sundström, Sören Holmberg, Bo Rothstein, Natalia Alvarado Pachon, Cem Mert Dalli, and Yente Meijers. 2023. “The Quality of Government Basic Dataset, Version Jan23.” University of Gothenburg: The Quality of Government Institute. https://www.gu.se/en/quality-government doi:10.18157/qogbasjan23.\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nRobinson, David. 2020. Fuzzyjoin: Join Tables Together on Inexact Matching. https://github.com/dgrtwo/fuzzyjoin.\n\n\nSmith, Danny. 2020. Survey Research Datasets and R. https://socialresearchcentre.github.io/r_survey_datasets/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "04_tidy_data2.html#footnotes",
    "href": "04_tidy_data2.html#footnotes",
    "title": "4  Tidy data analysis II",
    "section": "",
    "text": "Technically, the read_csv() and read_rds() functions come from readr, one of the tidyverse constituent packages.↩︎\nThere are R packages to deal with these complications. fuzzyjoin matches units by their approximate distance, using some clever algorithms. countrycode allows one to standardize country names and country codes across different conventions.↩︎"
  },
  {
    "objectID": "05_functions.html#basics",
    "href": "05_functions.html#basics",
    "title": "5  Functions and loops",
    "section": "5.1 Basics",
    "text": "5.1 Basics\n\n5.1.1 What is a function?\nInformally, a function is anything that takes input(s) and gives one defined output. There are always three main parts:\n\nThe input (\\(x\\) values, or each value in the domain)\nThe relationship of interest\nThe output (\\(y\\) values, or a unique value in the range)\n\n\n\n\nFigure 5.1: Function machine. Source: Bill Bailey on Wikimedia Commons.\n\n\n\n\n\n\n\n\nNote\n\n\n\n“\\(f(x) = \\space ...\\) is the classic notation for writing a function, but we can also use”\\(y = \\space ...\\)“. This is because \\(y\\) is”a function of” \\(x\\), so \\(y=f(x)\\).\n\n\nLet’s take a look at an example and break down the structure:\n\\[f(x) = 3x + 4\\]\n\n\\(x\\) is the input (some value) that the function takes.\nFor any \\(x\\), we multiply by three and add 4, which is the relationship.\nFinally, \\(f(x)\\) or \\(y\\) is the unique result, or the output.\n\nThe most common name to give a function is, predictably, “\\(f\\)”, but we can have other names such as “\\(g\\)” or “\\(h\\)”. The choice is yours.\n\n\n\n\n\n\nImportant\n\n\n\nWhen reading out loud, we say “[name of function] of x equals [relationship]. For example, \\(f(x) = x^2\\) is referred to as”f of x equals x squared.”\n\n\n\n\n5.1.2 Vertical line test\n\n\n\n\n\n\nExercise\n\n\n\nWhen graphed, vertical lines cannot touch functions at more than one point. Why?\nWhich of the following represent functions?\n\n\n\nFigure 5.2: Vertical line test: examples."
  },
  {
    "objectID": "05_functions.html#functions-in-r",
    "href": "05_functions.html#functions-in-r",
    "title": "5  Functions and loops",
    "section": "5.2 Functions in R",
    "text": "5.2 Functions in R\nOften we need to create our own functions in R. To build them: we use the keyword function alongside the following syntax: function_name &lt;- function(argumentnames){ operation }\n\nfunction_name: the name of the function, that will be stored as an object in the R environment. Make the name concise and memorable!\nfunction(argumentnames): the inputs of the function.\n{ operation }: a set of commands that are run in a predefined order every time we call the function.\n\nFor example, we can create a function that multiplies a number by 2:\n\nmult_by_two &lt;- function(x){x * 2}\n\n\nmult_by_two(x = 5) # we can also omit the argument name (x =)\n\n[1] 10\n\n\nIf the function body works for vectors, our custom function will do too:\n\nmult_by_two(1:10)\n\n [1]  2  4  6  8 10 12 14 16 18 20\n\n\nWe can also automate more complicated tasks such as calculating the area of a circle from its radius:\n\ncalc_circle_area &lt;- function(r){\n    pi * r ^ 2\n}\ncalc_circle_area(r = 3)\n\n[1] 28.27433\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCreate a function that calculates the area of a circle from its diameter. So your_function(d = 6) should yield the same result as the example above. Your code:\n\n\nFunctions can take more than one argument/input. In a silly example, let’s generalize our first function:\n\nmult_by &lt;- function(x, mult){x * mult}\n\n\nmult_by(x = 1:5, mult = 10)\n\n[1] 10 20 30 40 50\n\n\n\nmult_by(1:5, mult = 10)\n\n[1] 10 20 30 40 50\n\n\n\nmult_by(1:5, 10)\n\n[1] 10 20 30 40 50\n\n\nTo graph a function, we’ll use our friend ggplot2 and stat_function():\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nggplot() +\n  stat_function(fun = mult_by_two, \n                xlim = c(-5, 5)) # domain over which we will plot the function\n\n\n\n\nUser-defined functions have endless possibilities! We encourage you to get creative and try to automate new tasks when possible, especially if they are repetitive.\n\n\n\n\n\n\nTip\n\n\n\nFunctions in R can also take non-numeric inputs. For example:\n\nsay_my_name &lt;- function(my_name){paste(\"My name is\", my_name)}\n\n\nsay_my_name(\"Inigo Montoya\")\n\n[1] \"My name is Inigo Montoya\"\n\n\nWhile w"
  },
  {
    "objectID": "05_functions.html#common-types-of-functions",
    "href": "05_functions.html#common-types-of-functions",
    "title": "5  Functions and loops",
    "section": "5.3 Common types of functions",
    "text": "5.3 Common types of functions\n\n5.3.1 Linear functions\n\\[y=mx+b\\]\nLinear functions are those whose graph is a straight line (in two dimensions).\n\n\\(m\\) is the slope, or the rate of change (common interpretation: for every one unit increase in \\(x\\), \\(y\\) increases \\(m\\) units).\n\\(b\\) is the y intercept, or the constant term (the value of \\(y\\) when \\(x=0\\)).\n\nBelow is a graph of the function \\(y = 3x + 4\\):\n\nggplot() +\n  stat_function(fun = function(x){3 * x + 4}, # we don't need to create an object\n                xlim = c(-5, 5)) \n\n\n\n\n\n\n5.3.2 Quadratic functions\n\\[y=ax^2 + bx + c\\]\n\nThese lines have one curve.\n\\(a\\), \\(b\\), and \\(c\\) don’t have well-defined meanings here.\nIf \\(a\\) is negative, the function opens downward; if \\(a\\) is positive,it opens upward.\nNote that \\(x^2\\) always returns positive values.\nBelow is a graph of the function \\(y = x^2\\):\n\n\nggplot() +\n  stat_function(fun = function(x){x ^ 2},\n                xlim = c(-5, 5)) \n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nSocial scientists commonly use linear or quadratic functions as theoretical simplifications of social phenomena. Can you give any examples?\n\n\n\n\n5.3.3 Cubic functions\n\\[y=ax^3 + bx^2 + cx +d\\]\n\nThese lines (generally) have two curves (inflection points).\n\\(a\\), \\(b\\), \\(c\\), and \\(d\\) don’t have well-defined meanings here.\nBelow is a graph of the function \\(y = x^3\\):\n\n\nggplot() +\n  stat_function(fun = function(x){x ^ 3},\n                xlim = c(-5, 5)) \n\n\n\n\n\n\n5.3.4 Polynomial functions\n\\[y=ax^n + bx^{n-1} + ... + c\\]\n\nThese functions have (maximum) \\(n-1\\) changes in direction (turning points).\nThey also have (maximum) \\(n\\) x-intercepts. - They can be made arbitrarily precise.\nThese functions have (maximum) \\(n-1\\) changes in direction (turning points).\nThey also have (maximum) \\(n\\) x-intercepts.\nThey can be made arbitrarily precise.\nBelow is a graph of the function \\(y = \\frac{1}{4}x^4 - 5 x^2 + x\\).\n\n\nggplot() +\n  stat_function(fun = function(x){1/4 * x ^ 4 - 5 * x ^ 2 + x},\n                xlim = c(-5, 5)) \n\n\n\n\n\n\n5.3.5 Exponential functions\n\\[y = ab^{x}\\]\n\nHere our input (\\(x\\)), is the exponent.\nBelow is a graph of the function \\(y = 2^x\\):\n\n\nggplot() +\n  stat_function(fun = function(x){2 ^ x},\n                xlim = c(-5, 5))"
  },
  {
    "objectID": "05_functions.html#logarithms-and-exponents",
    "href": "05_functions.html#logarithms-and-exponents",
    "title": "5  Functions and loops",
    "section": "5.4 Logarithms and exponents",
    "text": "5.4 Logarithms and exponents\n\n5.4.1 Logarithms\n\nLogarithms are basically the opposite (inverse) of exponents.\nThey ask how many times you must raise the base to get \\(x\\).\n\\(log_a(b)=x\\) is asking “a raised to what power x gives b?”\n\\(\\log_3(81) = 4\\) because \\(3^4=81\\)\n\n\n\n\n\n\n\nWarning\n\n\n\nLogarithms can be undefined. The base cannot be 0, 1, or negative.\n\n\n\n\n5.4.2 Relationships\nIf, \\[ log_ax=b\\] then, \\[a^{log_{a}x}=a^b\\] and \\[x=a^b\\]\n\n\n5.4.3 Basic rules\n\\[\\dfrac{\\log_x n}{\\log_x m} = \\log_m n\\]\n\\[\\log_x(ab) = \\log_xa + \\log_xb \\]\n\\[\\log_x\\left(\\frac{a}{b}\\right) = \\log_xa - \\log_xb\\]\n\\[\\log_xa^b = b \\log_x a\\]\n\\[\\log_x 1 = 0\\]\n\\[log_{x}x=1\\]\n\\[m^{\\log_m(a)} = a\\]\n\n\n5.4.4 Natural logarithms\n\nWe most often use natural logarithms for our purposes.\nThis means \\(log_e(x)\\), which is usually written as \\(ln(x)\\).\n\n\n\n\n\n\n\nImportant\n\n\n\n\\(e \\approx 2.7183\\).\n\n\n\n\\(ln(x)\\) and its exponent opposite, \\(e^x\\), have nice properties when we perform calculus.\n\n\n\n5.4.5 Illustration of \\(e\\)\n\nImagine you invest $1 in a bank and receive 100% interest for one year, and the bank pays you back once a year: \\[(1+1)^1= 2\\]\nWhen it pays you twice a year with compound interest:\n\n\\[(1+1/2)^2=2.25\\]\n\nIf it pays you three times a year:\n\n\\[(1+1/3)^3=2.37...\\]\n\nWhat will happen when the bank pays you once a month? Once a day?\n\n\\[(1+\\frac{1}{n})^{n}\\]\n\nHowever, there is limit to what you can get.\n\n\\[\\lim_{n\\to\\infty} (1 + \\dfrac{1}{n})^n = 2.7183... = e\\]\n\nFor any interest rate \\(k\\) and number of times the bank pays you \\(t\\): \\[\\lim_{n\\to\\infty} (1 + \\dfrac{k}{n})^{nt} = e^{kt}\\]\n\\(e\\) is important for defining exponential growth. Since \\(ln(e^x) = x\\), the natural logarithm helps us turn exponential functions into linear ones.\n\n\n\n\n\n\n\nExercise\n\n\n\nSolve the problems below, simplifying as much as you can. \\[log_{10}(1000)\\] \\[log_2(\\dfrac{8}{32})\\] \\[10^{log_{10}(300)}\\] \\[ln(1)\\] \\[ln(e^2)\\] \\[ln(5e)\\]\n\n\n\n\n5.4.6 Logarithms in R\nBy default, R’s log() function computes natural logarithms:\n\nlog(100)\n\n[1] 4.60517\n\n\nWe can change this behavior with the base = argument:\n\nlog(100, base = 10)\n\n[1] 2"
  },
  {
    "objectID": "05_functions.html#composite-functions-functions-of-functions",
    "href": "05_functions.html#composite-functions-functions-of-functions",
    "title": "5  Functions and loops",
    "section": "5.5 Composite functions (functions of functions)",
    "text": "5.5 Composite functions (functions of functions)\n\nFunctions can take other functions as inputs, e.g., \\(f(g(x))\\).\nThis means that the outside function takes the output of the inside function as its input.\nSay we have the exterior function f(x)=\\(x^2\\) and the interior function g(x)=\\(x-3\\).\nThen if we want f(g(x)), we would subtract 3 from any input, and then square the result.\nWe write this \\((x-3)^2\\), not \\(x^2-3\\).\n\n\n\n\n\nArel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman. 2018. “Countrycode: An r Package to Convert Country Names and Country Codes.” Journal of Open Source Software 3 (28): 848. https://doi.org/10.21105/joss.00848.\n\n\nBank, World. 2023. “World Bank Open Data.” https://data.worldbank.org/.\n\n\nDahlberg, Stefan, Aksen Sundström, Sören Holmberg, Bo Rothstein, Natalia Alvarado Pachon, Cem Mert Dalli, and Yente Meijers. 2023. “The Quality of Government Basic Dataset, Version Jan23.” University of Gothenburg: The Quality of Government Institute. https://www.gu.se/en/quality-government doi:10.18157/qogbasjan23.\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nRobinson, David. 2020. Fuzzyjoin: Join Tables Together on Inexact Matching. https://github.com/dgrtwo/fuzzyjoin.\n\n\nSmith, Danny. 2020. Survey Research Datasets and R. https://socialresearchcentre.github.io/r_survey_datasets/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "06_calculus.html#derviatives",
    "href": "06_calculus.html#derviatives",
    "title": "6  Calculus",
    "section": "6.1 Derviatives",
    "text": "6.1 Derviatives\n\n“Derivative” is just a fancy term for slope.\nSlope is the rate of change \\(\\frac{\\delta y}{\\delta x}\\) or \\(\\frac{d y}{d x}\\).\nSpecifically, the derivative is the instantaneous rate of change.\nWe need slope for our statistics, which are all about fitting lines.\nWe also need slope for taking maxima and minima.\nThe equation for a line is \\(y = mx + b\\). What is its slope?\n\n\n6.1.1 Calculating derivatives\n\nSlope is rise over run, which is \\(\\dfrac{f(x+\\Delta x)-f(x)}{\\Delta x}\\)\nTo see why, consider the slope of a line connecting two points: \\[m = \\displaystyle\\frac{f(x_2) - f(x_1)}{x_2-x_1}\\]\nWe can define \\(x_2 = x_1 + \\Delta x\\) (or equivalently \\(\\Delta x = x_2 - x_1\\)) \\[m = \\dfrac{f(x_1+ \\Delta x) - f(x_1)}{\\Delta x}\\]\n\n\n\nAs we’ve seen, for a curve, we need to be infinitely close for our line’s defining points, yielding \\[\\lim_{\\Delta x\\to 0} \\frac{f(x+ \\Delta x)-f(x)}{\\Delta x}\\]\nThis gives us this instantaneous slope (rate of change) of a function at every point on its domain. The above equation is the definition of the derivative.\n\n\n\n6.1.2 Notation\n\n\\(\\frac{d}{dx} f(x)\\) is read “The derivative of \\(f\\) of \\(x\\) with respect to \\(x\\).”\n\nYou can also say “The instantaneous rate of change in \\(f\\) of \\(x\\) with respect to \\(x\\).”\n\nLagrange’s prime notation: \\(f'(x)\\) (read: “\\(f\\) prime \\(x\\)”) is the derivative of \\(f(x)\\).\nIf \\(y=f(x)\\), \\(\\frac{dy}{dx}\\) is “The derivative of \\(y\\) with respect to \\(x\\)”.\n\nThe variable with respect to which we’re differentiating is the one that appears in the denominator.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nDo not try to cancel out the \\(d\\)’s, no matter how tempting it is.\n\n\n\nExamples\n\nWhat is \\(\\dfrac{d(x^2)}{dx}\\)?\n\n\\(x^2\\)\n\\(2 x^{2-1}\\) -\\(2x\\)\n\nWhat is \\(\\frac{d(4x^3)}{dx}\\)?\n\n\\(4x^3\\)\n\\(4*3 x^{3-1}\\)\n\\(12x^2\\)\n\n\n\nPractice\n\nTake the derivative of each of the following: \\[x^3\\] \\[3x^2\\] \\[60x^{11}\\] \\[x\\] \\[\\frac{4}{x^2} \\] \\[9 \\sqrt{x}\\] \\[6 x^{5/2}\\] \\[11,596,232\\]\n\n\nPractice\n\nEvaluate the derivatives at \\(x=2\\) and \\(x=-1\\) \\[x^3\\] \\[3x^2\\] \\[60x^{11}\\] \\[x\\] \\[\\frac{4}{x^2} \\] \\[9 \\sqrt{x}\\] \\[6 x^{5/2}\\] \\[11,596,232\\]\n\n\nPractice\n\nTake the derivative of each of the following: \\[x^3\\] \\[3x^2\\] \\[60x^{11}\\] \\[x\\] \\[\\frac{4}{x^2} \\] \\[9 \\sqrt{x}\\] \\[6 x^{5/2}\\] \\[11,596,232\\]\n\n\n\nEvaluate the derivatives at \\(x=2\\) and \\(x=-1\\) \\[x^3\\] \\[3x^2\\] \\[60x^{11}\\] \\[x\\] \\[\\frac{4}{x^2} \\] \\[9 \\sqrt{x}\\] \\[6 x^{5/2}\\] \\[11,596,232\\]\n\n\n\n\n6.1.3 Special functions\n\nA few functions have particular rules:\n\n\\[\\frac{d (ln(x))}{dx}=\\frac{1}{x}\\]\n\\[\\dfrac{d (log_b(x))}{dx}=\\dfrac{1}{x*ln(b)}\\]\n\\[\\frac{d (e^x)}{dx}=e^x\\]\n\\[\\frac{d (a^x)}{dx}=a^x ln(a)\\]\n\\[\\frac{dy}{dx}c=0\\]\n\\[\\frac{d (x^x)}{dx}=x^x (1+ln(x))\\]\n\n\n6.1.4 Derivatives with addition and substraction\n\nThis is perhaps the rasiest rule to remember: \\[\\frac{d (f(x) \\pm g(x))}{dx}=f'(x) \\pm g'(x)\\]\n\n\nPractice\n\nTake the derivative of each of the following: \\[x^2 + x +5\\] \\[x^4 - 4x^3 + 5x^2 + 8x - 6\\] \\[3x^5 - 6x^2\\] \\[5x^2 + 8 \\sqrt{x} - \\frac{1}{x}\\] \\[ln(x) + 5e^x - 4x^3\\]"
  },
  {
    "objectID": "06_calculus.html#advanced-rules",
    "href": "06_calculus.html#advanced-rules",
    "title": "6  Calculus",
    "section": "6.2 Advanced rules",
    "text": "6.2 Advanced rules\n\n6.2.1 Product rule\n\nThis rule is more complicated: \\[\\frac{d (f(x) \\times g(x))}{dx}=f'(x)g(x) + g'(x)f(x)\\]\nExample: \\[2x \\times 3x\\] \\[ f(x)=2x\\] \\[g(x) = 3x\\] \\[f'(x) = 2\\] \\[g'(x) = 3\\] \\[f'(x)g(x) + g'(x)f(x) = 2 \\times 3x + 3 \\times 2x\\] \\[\\frac{d (2x \\times 3x)}{dx} = 6x + 6x = 12x\\]\n\n\nPractice\n\nTake the derivative of each of these: \\[x^3 * x\\] \\[e^x * x^2\\] \\[ln(x) * x^{-3}\\]\n\n\n\n\n\n\n\nReminder!\n\n\n\n\\[\\frac{d (f(x) * g(x))}{dx}=f'(x)g(x) + g'(x)f(x)\\]\n\n\n\n\n6.2.2 Quotient rule\n\\[\\frac{d \\frac{f(x)}{g(x)}}{dx}=\\frac{f'(x)g(x) - g'(x)f(x)}{[g(x)]^2}\\] - If you’re having trouble with this, just apply the product rule to the following: \\[\\frac{d[f(x)*g^{-1}(x)]}{dx}\\]\n\n\n\n\n\n\nReminder!\n\n\n\n\\[\\frac{d \\frac{f(x)}{g(x)}}{dx}=\\frac{f'(x)g(x) - g'(x)f(x)}{[g(x)]^2}\\]\n\n\n\n\n6.2.3 Chain rule\n\\[\\frac{d [f(g(x))]}{dx}=f'(g(x)) * g'(x)\\]\n\nLet’s take the derivative of a function of a function: \\[\\frac{d[ln(x^2)]}{dx}\\] \\[f(x)=ln(x)\\] \\[g(x)=x^2\\] \\[f'(x)=\\frac{1}{x}\\] \\[g'(x)=2x\\] \\[ \\frac{1}{x^2}*2x = \\frac{2}{x}\\]\n\n\nPractice\n\nTake the derivative of each of the following: \\[ (3x^4-8)^2 \\] \\[e^{x^2}\\]\n\n\n\n\n\n\n\nReminder!\n\n\n\n\\[\\frac{d (f(g(x))}{dx}=f'(g(x)) * g'(x)\\]\n\n\n\n\n6.2.4 Second derivative\n\nSame process as taking single derivative, except input for second derivative is output from first.\nSecond derivative tells us whether the slope of a function is increasing, decreasing, or staying the same at any point \\(x\\) on the function’s domain.\nExample: driving a car.\n\n\\(f(x)\\) = distance traveled at time \\(x\\)\n\\(f'(x)\\) = speed at time \\(x\\)\n\\(f''(x)\\) = acceleration at time \\(x\\)\n\nLet’s graph \\(f(x) = x^2\\), \\(f'(x)\\), and \\(f''(x)\\).\n\n\n\n\n\n\n\n\\[\\frac{d^2(x^4)}{dx^2}=f''(x^4)\\]\n\nFirst, we take the first derivative: \\[f'(x^4)=4x^3\\]\nThen we use that output to take the second derivative: \\[f''(x^4)=f'(4x^3)=12x^2\\]\n\nPractice\nTake the second derivative of the following functions: \\[x^5\\] \\[6x^2\\] \\[4 ln(x)\\] \\[3x\\] \\[4x^{3/2}\\]"
  },
  {
    "objectID": "06_calculus.html#differentiable-and-continuous-functions",
    "href": "06_calculus.html#differentiable-and-continuous-functions",
    "title": "6  Calculus",
    "section": "6.3 Differentiable and Continuous Functions",
    "text": "6.3 Differentiable and Continuous Functions\n\nInformally: A function is continuous at a point if its graph has no holes or breaks at that point\nFormally: A function is continuous at a point \\(a\\) if: \\[\\displaystyle\\lim_{x \\to a} f(x)=f(a)\\]\nContinuity requires 3 conditions to hold:\n\n\\(f(a)\\) is defined (\\(a\\) is in the domain of \\(f\\))\n\\(\\displaystyle\\lim_{x \\to a} f(x)\\) exists\n\\(\\displaystyle\\lim_{x \\to a} f(x) = f(a)\\) (the value of \\(f\\) equals the limit of \\(f\\) at \\(a\\))\n\nDifferentiable:\n\nIf \\(f'(x)\\) exists, \\(f\\) is differentiable at \\(x\\).\nIf \\(f\\) is differentiable at every point of an open interval \\(I\\), \\(f\\) is differentiable on \\(I\\).\nGraph must have a (non-vertical) tangent line at each point, be relatively smooth, and not contain any breaks, bends, or cusps.\n\nIf a function is differentiable at a point, it is also continuous at that point.\nIf a function is continuous at a point, it is not necessarily differentiable at that point.\n\n\n6.3.1 When is f not differentiable?\nWhen does \\(f'(x)\\) not exist?\n\nWhen the function is discontinuous at that point.\n\nJump or break in the graph.\n\nThere are different slopes approaching the point from the left and from the right.\n\nCorner point\n\nWhen the graph of the function has a vertical tangent line at that point.\n\nCusp\nVertical inflection point"
  },
  {
    "objectID": "06_calculus.html#extrema-and-optimization",
    "href": "06_calculus.html#extrema-and-optimization",
    "title": "6  Calculus",
    "section": "6.4 Extrema and optimization",
    "text": "6.4 Extrema and optimization\nOptimization lets us find the minimum or maximum value a function takes.\n\nFormal theory\n\nUtility maximization, continuous choices\n\nOrdinary Least Squares (OLS)\n\nFocuses on minimizing the squared errors between observed data and values predicted by a regression.\n\nMaximum Likelihood Estimation (MLE)\n\nFocuses on maximizing a likelihood function, given observed values.\n\n\n\n6.4.1 Extrema\n\nInformally, a maximum is just the highest value a function takes, and a minimum is the lowest value.\nEasy to identify extrema (maxima or minima) intuitively by looking at a graph of the function.\n\nMaxima are high points (“peaks”)\nMinima are low points (“valleys”)\n\nExtrema can be local or global.\n\n\n\n6.4.2 Identifying extrema\n\nThe derivative of a function gives the rate of change.\nWhen the derivative is zero (or fails to exist), the function has usually reached a (local) maximum or minimum.\nAt a maximum, the function must be increasing before the point and decreasing after it.\nAt a minimum, the function must be decreasing before the point and increasing after it.\nWe’ll start by identifying points where this is the case (“critical points” or “stationary points”).\n\n\n\n\n\n\n\nNote\n\n\n\nA point where \\(f'(x)=0\\) or \\(f'(x)\\) does not exist is called a critical point (or stationary point). Local extrema occur at critical points, but not all critical points are extrema. For instance, sometimes the graph is changing between concave and convex (“inflection points”). Sometimes the function is not differentiable at that point for other reasons.\n\n\n\n\nWe can find the local maxima and/or minima of a function by taking the derivative, setting it equal to zero, and solving for x (or whatever).\n\n\\[f'(x)=0\\]\n\nThis gives us the first-order condition (FOC).\n\n\n\n6.4.3 Minimum or maximum?\nBUT we don’t know if we’ve found a maximum or minimum, or even if we’ve found an extremum or just an inflection point.\n\n\n6.4.4 Second derivatives\n\nThe second derivative gives us the rate of change of the rate of change of the original function. It tells us whether the slope is getting larger or smaller.\n\n\\[f(x) = x^2\\] \\[f'(x) = 2x\\] \\[f''(x) = 2\\]\n\nSecond Derivative Test - Start by identifying \\(f''(x)\\)\n\nSubstitute in the stationary points \\((x^*)\\) identified from the FOC.\n\n\\(f''(x^*) &gt; 0\\) we have a local minimum\n\\(f''(x^*) &lt; 0\\) we have a local maximum\n\\(f''(x^*) = 0\\) we (may) have an inflection point - need to calculate higher-order derivatives (don’t worry about this now)\n\n\nCollectively these give use the Second-Order Condition (SOC).\n\n\n6.4.5 Local vs. Global Extrema\n\nTo find the minimum/maximum on some interval, compare the local min/max to the value of the function at the interval’s endpoints.\nTo find the global minimum/maximum, check the function’s limits as it approaches \\(+ \\infty\\) and \\(- \\infty\\).\nExtreme value theorem: if a real-valued function \\(f\\) is continuous on the closed interval [a,b], then \\(f\\) must attain a (global) maximum and a (global) minimum."
  },
  {
    "objectID": "06_calculus.html#partial-derivatives",
    "href": "06_calculus.html#partial-derivatives",
    "title": "6  Calculus",
    "section": "6.5 Partial derivatives",
    "text": "6.5 Partial derivatives\n\nWe can take the derivative with respect to different variables.\nFor a function \\(fy=(x,z)=xz\\), we might want to know how the function changes with \\(x\\):\n\n\\[ \\displaystyle\\frac{\\partial}{\\partial_x}f(x,y) = \\frac{\\partial_y}{\\partial_x} = \\partial_x f\\]\n\nWe treat all other variables as constants and take derivative with respect to the variable of interest (here \\(x\\)).\n\n\nHow do we take a partial derivative?\nTreat all other variables as constants and take derivative with respect to the variable of interest.\nFrom our earlier example: \\[y = f(x,z) = xz \\] \\[ \\displaystyle\\frac{\\partial_y}{\\partial_x} = ?\\]\n\n\\[y = f(x,z) = xz \\] \\[ \\displaystyle\\frac{\\partial_y}{\\partial_x} = z\\]\nWhy? Because the partial derivative of \\(xz\\) with respect to \\(x\\) treats \\(z\\) as a constant.\nWhat is \\(\\displaystyle\\frac{\\partial_y}{\\partial_z}?\\)\n\n6.5.1 Application\n\n\\(\\frac{\\partial (x^2y+xy^2-x)}{\\partial x}\\)\nWe apply the addition rule to take the derivative of each term with respect to x.\n\\(\\frac{\\partial (x^2y)}{\\partial x}\\)+\\(\\frac{\\partial (xy^2)}{\\partial x}\\)+\\(\\frac{\\partial (-x)}{\\partial x}\\)\n\\(2xy+y^2-1\\)\n\n\n\n\\(\\frac{\\partial (x^2y+xy^2-x)}{\\partial y}\\)\nWe apply the addition rule to take the derivative of each term with respect to y\n\\(\\frac{\\partial (x^2y)}{\\partial y}\\)+\\(\\frac{\\partial (xy^2)}{\\partial y}\\)+\\(\\frac{\\partial (-x)}{\\partial y}\\)\n\\(x^2+2xy\\)\n\n\nPractice\nTake the partial derivative with respect to x and to y of the following functions. What would the notation for each look like?\n\\[3xy-x\\] \\[ln(xy)\\] \\[x^3+y^3+x^4y^4\\] \\[e^{xy}\\]"
  },
  {
    "objectID": "06_calculus.html#integrals",
    "href": "06_calculus.html#integrals",
    "title": "6  Calculus",
    "section": "6.6 Integrals",
    "text": "6.6 Integrals\n\n6.6.1 Area under a curve\n\nOften we want to find the area under a curve.\nSometimes finding the area is easy. What’s the area under the curve between \\(x=-1\\) and \\(x=1\\) for this function? \\[f(x) =\n\\begin{cases}\n\\frac{1}{3} & \\text{for } x \\in [0, 3] \\\\\n0 & \\text{otherwise}\n\\end{cases}\\]\n\n\n\n\n\n\n\n“Hint\n\n\n\nWe can draw this and look at the graph. Remember: \\[area = \\ell*w\\]\n\n\n\nNormally, finding the area under a curve is much harder. But this is basically the question behind integration.\n\n\n\n6.6.2 Integrals as summation\n\nWe are already familiar with summation notation. \\[\\displaystyle\\sum_{i=1}^{n} i\\]\nThis only works when we have discrete values to add.\n\nWhen we need to add continuously, we have to use something else. Specifically, integrals.\n\n\n\n\n6.6.3 Definite integrals\n\nLet’s say we have a function \\[ y = x^2 \\] And we want to find the area under the curve from \\(x=0\\) to \\(x=1\\).\nTo find the area we’re interested in here, we can use the definite integral.\nGenerally speaking, the notation looks like this: \\[\\displaystyle\\int_{x=a}^{b} f(x),dx\\]\nHere \\(a\\) is the lower limit of integration, \\(b\\) is the upper limit of integration, our function \\(f(x)\\) is our integrand, and \\(x\\) is our variable of integration.\n\n\n\nFor our question, we’re looking for the following: \\[\\displaystyle\\int_{x=0}^{1} f(x) dx\\]\nThis will give us a real number denoting the area under the curve of our function (\\(y=x^2\\)) between \\(x=0\\) and \\(x=1\\).\nIf \\(f\\) is continuous on \\([a,b]\\) or bounded on \\([a,b]\\) with a finite number of discontinuities, then \\(f\\) is integrable on \\([a,b]\\).\n\n\n\n6.6.4 Indefinite integrals\n\nThe indefinite integral, also known as the anti-derivative, \\(F(x)\\) is the inverse of the function \\(f'(x)\\). \\[F(x)= \\displaystyle\\int f(x) \\text{ } dx\\]\nThis means if you take the derivative of \\(F(x)\\), you wind up back at \\(f(x)\\). \\[F' = f \\text{ or } \\displaystyle\\frac{dF(x)}{dx} = f(x)\\]\nThis process is called anti-differentiation, or indefinite integration.\n\nWhile the definite integral gives us a real number (the total area under a curve), the indefinite integral gives us a function.\n\nWe need the concept of indefinite integrals to help us solve definite integrals.\n\n\n\n6.6.5 Solving definite integrals\n\nThe easiest way to calculate definite integrals, known as the “fundamental theorem of calculus,” is shown below:\n\n\\[\\displaystyle\\int_{a}^{b} f(x) \\text{ } dx = F(b)-F(a) = F(x)\\bigg|_{a}^{b}\\] - First we determine the antiderivative (indefinite integral) of \\(f(x)\\) (and represent it \\(F(x)\\)), substitute the upper limit first and then the lower limit one by one, and subtract the results in order.\n\n\n6.6.6 Constants\n\n\n\n\n\n\nNote\n\n\n\n\\(C\\) in the following slides is the called the “constant of integration.” We need to add it when we define all antiderivatives (integrals) of a function because the anti-derivative “undoes” the derivative.\nRemember that the derivative of any constant is zero. So if we find an integral \\(F(x)\\) whose derivative is \\(f(x)\\), adding (or subtracting) any constant will give us another integral \\(F(x)+C\\) whose derivative is also \\(f(x)\\).\n\n\n\n\n6.6.7 Rules of integration\n\\[ \\displaystyle\\int_{a}^{a}f(x) \\text{ }dx = 0\\]\n\\[\\displaystyle\\int_{a}^{b} f(x) \\text{ } dx = -\\displaystyle\\int_{b}^{a}f(x)dx\\]\n\\[\\int a \\text{ }dx = ax + C \\text { where $a$ is a constant}\\]\n\\[\\displaystyle\\int af(x)dx = a\\displaystyle\\int f(x) \\text{ }dx \\text{ where $a$ is a constant}\\]\n\n\n6.6.8 More rules\n\\[\\int (f(x) + g(x)) \\text{ } dx = \\int f(x) dx + \\int g(x)dx\\]\n\\[\\int x^n dx = \\frac{x^{n+1}}{n+1} + C \\qquad \\forall n \\neq -1\\]\n\\[\\int x^{-1}dx = \\ln |x| + C\\]\n\n\n6.6.9 Solving the problem\nRemember our function \\(y=x^2\\) and our goal of finding the area under the curve from \\(x=0\\) to \\(x=1\\).\n\nFind the indefinite integral, \\(F(x)\\)\n\n\\(\\displaystyle\\int x^2 \\text{ } dx\\)\n\\(\\displaystyle\\frac{x^3}{3}+C\\)\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWe use the “power rule” of integration, which is the following: \\[\\int x^n dx = \\frac{x^{n+1}}{n+1} + C \\qquad \\forall n \\neq -1\\]\n\n\n\nEvaluate at our lowest and highest points, \\(F(0)\\) and \\(F(1)\\).\n\n\\(F(0) = 0\\)\n\\(F(1) = \\displaystyle\\frac{1}{3}\\)\nTechnically \\(0 + C\\) and \\(\\displaystyle\\frac{1}{3} + C\\), but the C’s will fall out in the next step\n\nCalculate \\(F(1) - F(0)\\) \\[\\displaystyle\\frac{1}{3} - 0 = \\displaystyle\\frac{1}{3}\\]\n\n\nPractice — indefinite integrals\n\\[\\int x^2 \\text{ } dx\\] \\[\\int 3x^2\\text{ } dx\\] \\[\\int x\\text{ } dx\\] \\[\\int 3x^2 + 2x - 7\\text{ }dx\\] \\[\\int \\dfrac{2}{x}\\text{ }dx\\]\n\nPractice — definite integrals\n\\[\\displaystyle\\int_{1}^{7} x^2 \\text{ } dx\\] \\[\\displaystyle\\int_{1}^{10} 3x^2 \\text{ } dx\\] \\[\\int_7^7 x\\text{ } dx\\] \\[\\displaystyle\\int_{1}^{5} 3x^2 + 2x - 7\\text{ }dx\\] \\[\\int_{1}^{e} \\dfrac{2}{x}\\text{ }dx\\]\n\n\n\n\nArel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman. 2018. “Countrycode: An r Package to Convert Country Names and Country Codes.” Journal of Open Source Software 3 (28): 848. https://doi.org/10.21105/joss.00848.\n\n\nBank, World. 2023. “World Bank Open Data.” https://data.worldbank.org/.\n\n\nDahlberg, Stefan, Aksen Sundström, Sören Holmberg, Bo Rothstein, Natalia Alvarado Pachon, Cem Mert Dalli, and Yente Meijers. 2023. “The Quality of Government Basic Dataset, Version Jan23.” University of Gothenburg: The Quality of Government Institute. https://www.gu.se/en/quality-government doi:10.18157/qogbasjan23.\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nRobinson, David. 2020. Fuzzyjoin: Join Tables Together on Inexact Matching. https://github.com/dgrtwo/fuzzyjoin.\n\n\nSmith, Danny. 2020. Survey Research Datasets and R. https://socialresearchcentre.github.io/r_survey_datasets/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "07_probability.html#what-is-probability",
    "href": "07_probability.html#what-is-probability",
    "title": "7  Probability",
    "section": "7.1 What is probability?",
    "text": "7.1 What is probability?\n\nFrequency with which an event occurs.\n\nTypically: \\[Pr(A) = P(A) = \\pi(A) = \\dfrac{\\text{Number of ways an event can occur}}{\\text{Total number of possible outcomes}}\\]\n\nProbability predicts real-world events using theoretical quantities.\n\nFormally, it assigns a likelihood of occurrence to each event in sample space\nWe use the probability space triplet (\\(\\Omega, S, P\\)), which are the sample space, event space, and probability mapping, respectively.\n\nWe can consider probability as a function that maps \\(\\Omega \\to \\mathbb{R}\\).\nWe can conceive it in terms of relative frequency or subjective belief."
  },
  {
    "objectID": "07_probability.html#kolmogorovs-axioms",
    "href": "07_probability.html#kolmogorovs-axioms",
    "title": "7  Probability",
    "section": "7.2 Kolmogorov’s axioms",
    "text": "7.2 Kolmogorov’s axioms\n\n\\(Pr(S_i)\\in\\mathbb{R},\\hspace{2mm} 1 \\geq Pr(S_i)\\geq 0 \\qquad \\forall S_i\\in S\\)\n\nWhere \\(S\\) is the event space, \\(S_i\\) are events.\nProbabilities must be non-negative.\n\n\\(Pr(\\Omega) = 1\\)\n\nWhere \\(\\Omega\\) is the sample space.\nSomething has to happen.\nProbabilities sum/integrate to 1.\n\n\\(Pr\\left(\\bigcup_{i = 1}^\\infty S_i\\right) = \\sum_{i=1}^\\infty Pr(S_i) \\iff Pr(S_i \\cap S_j) = 0\\hspace{2mm} \\forall i\\neq j\\)\n\nThe probability of disjoint (mutually exclusive) sets is equal to the sum of their individual probabilities."
  },
  {
    "objectID": "07_probability.html#some-definitions",
    "href": "07_probability.html#some-definitions",
    "title": "7  Probability",
    "section": "7.3 Some definitions",
    "text": "7.3 Some definitions\n\nRandom variable: a variable whose value is determined by the outcome of a random process.\n\nSometimes also called a stochastic variable.\nMay be discrete or continuous.\n\nDistribution (of a random variable): the set of values the variable might take.\n\nProbability mass function / probability density function defines the probability with which each value occurs.\nAlways sums / integrates to 1.\n\nRealization (of a random variable): a particular value taken by the variable.\n\n\n\nPopulation: the entire set of objects (people, cases, etc.) in which we are interested.\n\nOften denoted \\(N\\).\n\nSample: a subset of the population we can observe, from which we try to make generalizations about the population.\n\nOften denoted \\(n\\).\n\nFrequency distribution: a count of how often a variable takes each of its possible values.\n\nThe number of members of a sample that take each value of a variable.\n\nIndependent random variables: two variables are statistically independent if the value of one does not affect the value of the other.\n\nFormally, \\(Pr(A \\cap B)=Pr(A)Pr(B)\\)"
  },
  {
    "objectID": "07_probability.html#discrete-probability",
    "href": "07_probability.html#discrete-probability",
    "title": "7  Probability",
    "section": "7.4 Discrete probability",
    "text": "7.4 Discrete probability\n\nA sample space in which there are a (finite or infinite) countable number of outcomes\nEach realization of random process has a discrete probability of occurring.\n\n\\(f(X=x_i)=P(X=x_i)\\) is the probability the variable takes the value \\(x_i\\).\n\n\n\n7.4.1 Probability Mass Function (PMF)\nProbability of each occurrence encoded in probability mass function (PMF)\n\n\\(0 \\leq f(x_i) \\leq 1\\)\n\nProbability of any value occurring must be between 0 and 1.\n\n\\(\\displaystyle\\sum_{x}f(x_i) = 1\\)\n\nProbabilities of all values must sum to 1.\n\n\n\n\n7.4.2 Discrete distribution\n\nWhat’s the probability that we’ll roll a 3 on one die roll: \\[Pr(y=3) = \\dfrac{1}{6}\\]\nIf one roll of the die is an “experiment.”\nWe can think of a 3 as a “success.”\n\\(Y \\sim Bernoulli \\left(\\frac{1}{6} \\right)\\)\nFair coins are \\(\\sim Bernoulli(.5)\\), for example.\nMore generally, \\(Bernoulli(\\pi )\\).\n\n\\(\\pi\\) represents the probability of success.\n\n\n\n\nDrawing a specific card from a deck: \\[Pr(y=\\text{ace of spades}) = \\dfrac{1}{52}\\]\nDrawing any card with a specific value from a deck: \\[Pr(y=ace) = \\dfrac{4}{52}\\]\nGetting a specific value on two dice rolls: \\[Pr(y=8) = \\dfrac{5}{36}\\]\nWe can express the probability mass function in tabular format or in a graph."
  },
  {
    "objectID": "07_probability.html#continuous-probability",
    "href": "07_probability.html#continuous-probability",
    "title": "7  Probability",
    "section": "7.5 Continuous probability",
    "text": "7.5 Continuous probability\n\nWhat happens when our outcome is continuous?\nThere are an infinite number of outcomes.\nThis makes the denominator of our fraction difficult to work with.\nThe probability of the whole space must equal 1.\nEven if all events are equally likely, \\(\\dfrac{1}{\\infty} =0\\)\n\n\n7.5.1 Basics\n\nThe domain may not span -\\(\\infty\\) to \\(\\infty\\).\n\nEven space between 0 and 1 is infinite.\n\nThe domain is defined as the area under the probability density function.\nTwo common examples are the uniform and bell curves.\n\n\n\n7.5.2 Probability Density Function (PDF)\n\nSimilar to PMF from before, but for continuous variables.\nGives the probability a value falls within a particular interval\n\n\\(P[a\\le X\\le b] = \\displaystyle\\int_a^b f(x) \\, dx\\)\nTotal area under the curve is 1.\n\\(P(a &lt; X &lt; b)\\) is the area under the curve between \\(a\\) and \\(b\\) (where \\(b &gt; a\\))."
  },
  {
    "objectID": "07_probability.html#cumulative-density-function-cdf",
    "href": "07_probability.html#cumulative-density-function-cdf",
    "title": "7  Probability",
    "section": "7.6 Cumulative Density Function (CDF)",
    "text": "7.6 Cumulative Density Function (CDF)\n\n7.6.1 Discrete\n\nCumulatve density function is probability X will take a value of x or lower.\nPDF is written \\(f(x)\\), and CDF is written \\(F'(x)\\). \\[F_X(x) = Pr(X\\leq x)\\]\nFor discrete CDFs, that means summing up over all values.\nWhat is the probability of rolling a 6 or lower with two dice? \\(F(6)=?\\)\n\n\n\n7.6.2 Continuous\n\nWe can’t sum probabilities for continuous distributions (remember the 0 problem).\nSolution: integration \\[F_Y(y) = \\int_{-\\infty}^{y} f(y) dy\\]\nExamples of uniform distribution."
  },
  {
    "objectID": "07_probability.html#statistics",
    "href": "07_probability.html#statistics",
    "title": "7  Probability",
    "section": "7.7 Statistics",
    "text": "7.7 Statistics\n\n7.7.1 Introduction\n\nWhile probability allows us to make predictions about events using distributions, statistics uses events to make estimates about distributions and variables.\nIt is the process of learning from data.\nA statistic is a summary of data, capturing some theoretically-relevant quantity.\nBroad categories of numerical and categorical.\n\n\n\n7.7.2 Univariate statistics\n\nThese measure a single variable.\nReadily expressed in graphical form.\nCommon examples:\n\nCentral tendency (mean, median, and mode)\nVariance\n\n\n\n\n7.7.3 Examples of univariate statistics\n\nThe mean (\\(\\bar{x}\\)) is calculated by summing the data, then dividing by the number of observations: \\[\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\\]\nThe median is found by ordering the observations from highest to lowest and finding the one in the middle.\nThe mode is the most common number.\n\n\\[x= \\begin{bmatrix} 1 & 2 & 3 & 4 & 5 & 6 & 6 & 7 & 8 & 9 \\end{bmatrix}\\]\n\nWhat are the mean, median, and mode of x?\n\n\n\n7.7.4 Measures of central tendency\n\nMean balances values on either side.\nMedian balances observations on either side.\nMode finds the most typical observation.\nWhich is the best? Like most of what you’ll learn in statistics, it depends.\n\n\n\n7.7.5 Deviations from central tendency\n\nConsider two data sets: \\[\\begin{aligned}\nx= \\begin{bmatrix} 1 & 1.5 & 2 & 2.5 & 5.5 & 8.5 & 9 & 9.5 & 10 \\end{bmatrix}\n\\end{aligned}\\] \\[\\begin{aligned}\ny= \\begin{bmatrix} 4.5 & 4.8 & 5 & 5.3 & 5.5 & 5.7 & 6 & 6.2 & 6.5 \\end{bmatrix}\n\\end{aligned}\\]\nWhat is the mean of each?\nWhat is the median of each?\nAre they similar distributions?\n\n\n\n7.7.6 Variance\n\nWe use variance to measure the spread of a single variable.\nFormally defined as the squared deviation from the mean (\\(\\mu\\)).\nFor discrete random variables, it is written \\(Var(x)=\\sigma^2=\\displaystyle\\frac{1}{n}\\displaystyle\\sum_{i=1}^n(x_i-\\mu)^2\\)\nFor continuous random variables, it is written \\(Var(x)=\\sigma^2=\\displaystyle\\int (x-\\mu)^2 f(x) \\text{ }dx\\)\n\n\n\n7.7.7 Standard deviation\n\nSometimes variance doesn’t make sense, either mathematically or conceptually.\n\nNot always clear how to interpret “squared deviation from the mean.”\n\nInstead, will frequently see standard deviation, which is square root of variance.\nIt is written \\(\\sigma\\)."
  },
  {
    "objectID": "07_probability.html#bivariate-statistics",
    "href": "07_probability.html#bivariate-statistics",
    "title": "7  Probability",
    "section": "7.8 Bivariate statistics",
    "text": "7.8 Bivariate statistics\n\n7.8.1 Covariance\n\nWhile measures of central tendency and variance/standard deviation provide useful summaries of a single variable, they don’t provide insights into relationships between variables.\nFor that, we need bivariate statistics.\nMost common and straightforward is covariance.\n\n\n\nColloquially, can think of covariance as measure of linear deviation from mean.\nWhen values from one variable are above their mean, are values from the other above or below their mean?\nPut another way, if I told you the value of x was high, would you expect values of y to be high or low?\nFormally, it is written as: \\[cov(X,Y)=E(X-E(X))(Y-E(Y))=E(XY)-E(X)E(Y)\\]\nIt is important to note that the magnitude is meaningless; only the direction is interpretable.\n\n\n\n7.8.2 Correlation\n\nCorrelation is a normalized measure of covariance\nIt is calculated as: \\[\\rho_{X,Y}=\\frac{cov(X,Y)}{\\sigma_X \\sigma_Y}\\]\nIt varies between -1 and 1.\nWhat is correlation of two independent variables?"
  },
  {
    "objectID": "07_probability.html#regression",
    "href": "07_probability.html#regression",
    "title": "7  Probability",
    "section": "7.9 Regression",
    "text": "7.9 Regression\n\n7.9.1 Ordinary least squares\n\nOrdinary least squares regression (OLS) is probably the most widely-used model in political science.\nIt is all about drawing a line through data.\nThis allows us to evaluate the relationship (the association) between \\(x\\) on \\(y\\).\nThe dependent variable, \\(y\\), must be continuous, generally speaking.\nThe main question is which line to draw.\n\n\nLine and equation (\\(\\hat{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1} x_{i}\\)) on board\n\n\n7.9.2 Residuals\n\nIn basically any set of data, no line can pass through every point (observation).\nWe will always have make some error in predicting values.\nThe error between the line and some point is referred to as the residual.\nIf we refer to our predicted value as \\(\\hat{y}\\), then we can calculate the residual for each observation with the following equation: \\[e_i = y_i - \\hat{y}_i\\]\n\n\n\n7.9.3 Finding the right line\n\nOLS determines the “best” line by minimizing the sum of squared residuals.\nPlug in all the values for the slope amd intercept and calculate the sum of squared residuals for these infinity combinations.\nThat is a lot of work.\nThe best solution turns out to be calculus.\nWe want to minimize the sum of squared residuals with respect to our \\(\\beta\\)’s.\n\n\n\n\n\nArel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman. 2018. “Countrycode: An r Package to Convert Country Names and Country Codes.” Journal of Open Source Software 3 (28): 848. https://doi.org/10.21105/joss.00848.\n\n\nBank, World. 2023. “World Bank Open Data.” https://data.worldbank.org/.\n\n\nDahlberg, Stefan, Aksen Sundström, Sören Holmberg, Bo Rothstein, Natalia Alvarado Pachon, Cem Mert Dalli, and Yente Meijers. 2023. “The Quality of Government Basic Dataset, Version Jan23.” University of Gothenburg: The Quality of Government Institute. https://www.gu.se/en/quality-government doi:10.18157/qogbasjan23.\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nRobinson, David. 2020. Fuzzyjoin: Join Tables Together on Inexact Matching. https://github.com/dgrtwo/fuzzyjoin.\n\n\nSmith, Danny. 2020. Survey Research Datasets and R. https://socialresearchcentre.github.io/r_survey_datasets/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "08_simulations.html",
    "href": "08_simulations.html",
    "title": "8  Simulations",
    "section": "",
    "text": "Arel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman. 2018. “Countrycode: An r Package to Convert Country Names and Country Codes.” Journal of Open Source Software 3 (28): 848. https://doi.org/10.21105/joss.00848.\n\n\nBank, World. 2023. “World Bank Open Data.” https://data.worldbank.org/.\n\n\nDahlberg, Stefan, Aksen Sundström, Sören Holmberg, Bo Rothstein, Natalia Alvarado Pachon, Cem Mert Dalli, and Yente Meijers. 2023. “The Quality of Government Basic Dataset, Version Jan23.” University of Gothenburg: The Quality of Government Institute. https://www.gu.se/en/quality-government doi:10.18157/qogbasjan23.\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nRobinson, David. 2020. Fuzzyjoin: Join Tables Together on Inexact Matching. https://github.com/dgrtwo/fuzzyjoin.\n\n\nSmith, Danny. 2020. Survey Research Datasets and R. https://socialresearchcentre.github.io/r_survey_datasets/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "09_textanalysis.html#strings",
    "href": "09_textanalysis.html#strings",
    "title": "9  Text analysis",
    "section": "9.1 Strings",
    "text": "9.1 Strings\n\nIn R, a piece of text is represented as a sequence of characters (letters, numbers, and symbols).\nA string is a sequence of characters, which is used for storing text.\n\nFor example, “methods” is a string that includes characters: m, e, t, h, o, d, s.\n\nCreating strings is very straightforward in RStudio. We assign character values to a variable, being sure to enclose the character values (the text) in double or single quotation marks.\n\nWe can create strings of single words, or whole sentences if we so wish.\n\n\n\nstring1 &lt;- \"camp\" \nstring1\n\n[1] \"camp\"\n\nstring2 &lt;- \"I love methods camps.\"\nstring2\n\n[1] \"I love methods camps.\"\n\n\n\nWe can also create a vector of strings.\n\n\nstring3 &lt;- c(\"I\", \"love\", \"methods\", \"camp\", \".\")\nstring3\n\n[1] \"I\"       \"love\"    \"methods\" \"camp\"    \".\""
  },
  {
    "objectID": "09_textanalysis.html#string-manipulation",
    "href": "09_textanalysis.html#string-manipulation",
    "title": "9  Text analysis",
    "section": "9.2 String manipulation",
    "text": "9.2 String manipulation\n\nOften, strings, and more broadly text, contain information that we want to extract for the purpose of our research.\n\nFor example, perhaps we wanted to count the number of times a certain country was mentioned during the U.S. President’s annual State of the Union Address.\n\nFor tasks such as these, we can use regular expressions (also known as ‘regex’), which search for one or more specified pattern of characters.\n\nThese patterns can be exact matches, or more general.\n\n\n\ntest &lt;- \"test\"\n\n\nRegular expressions can be used to:\n\nExtract information from text.\nParse text.\nClean/replace strings.\n\n\n\n\n\n\n\n\nNote\n\n\n\nFortunately, the syntax for regular expressions is relatively stable across all programming languages (e.g., Java, Python, R)."
  },
  {
    "objectID": "09_textanalysis.html#stringr",
    "href": "09_textanalysis.html#stringr",
    "title": "9  Text analysis",
    "section": "9.3 Stringr",
    "text": "9.3 Stringr\n\nlibrary(stringr)\n\n\nstringr comes with the tidyverse and provides functions for both (a) basic string manipulations and (b) regular expression operations. Some basic functions are listed below:\n\n\n\n\nFunction\nDescription\n\n\n\n\nstr_c()\nstring concatenation\n\n\nstr_length()\nnumber of characters\n\n\nstr_sub()\nextracts substrings\n\n\nstr_dup()\nduplicates characters\n\n\nstr_trim()\nremoves leading and trailing whitespace\n\n\nstr_pad()\npads a string\n\n\nstr_wrap()\nwraps a string paragraph\n\n\nstr_trim()\ntrims a string\n\n\n\n\n9.3.1 Basic string manipulation\n\nLet’s try some examples of basic string manipulation using stringr:\n\n\nmy_string &lt;- \"I know people who have seen the Barbie movie 2, 3, even 4 times!\"\nmy_string\n\n[1] \"I know people who have seen the Barbie movie 2, 3, even 4 times!\"\n\n\n\nOne common thing we want to do with strings is lowercase them:\n\n\nlower_string &lt;- tolower(my_string)\nlower_string\n\n[1] \"i know people who have seen the barbie movie 2, 3, even 4 times!\"\n\n\n\nWe can also combine (concatenate) strings using the str_c command:\n\n\nmy_string2 &lt;- \"I wonder if they have seen Oppenheimer, too.\"\ncat_string &lt;- str_c(my_string, my_string2, sep = \" \")\ncat_string\n\n[1] \"I know people who have seen the Barbie movie 2, 3, even 4 times! I wonder if they have seen Oppenheimer, too.\"\n\n\n\nWe can also split up strings on a particular character sequence.\n\n! denotes where split occurs and deletes the “!” The double bracket instructs to grab the first part of the split string.\n\n\n\nmy_string_vector &lt;- str_split(cat_string, \"!\")[[1]] \nmy_string_vector\n\n[1] \"I know people who have seen the Barbie movie 2, 3, even 4 times\"\n[2] \" I wonder if they have seen Oppenheimer, too.\"                  \n\n\n\nWe can also find which strings in a vector contain a particular character or sequence of characters.\n\nThe grep (Globally search for Regular Expression and Print) command will return any instance that (partially) matches the provided pattern.\nClosely related to the grep() function is the grepl() function, which returns a logical for whether a string contains a character or sequence of characters.\n\n\n\ngrep(\"Barbie\",\n     cat_string,\n     value = FALSE,\n     ignore.case = TRUE)\n\n[1] 1\n\n# To search for some special characters (e.g., \"!\"), you need to \"escape\" it\ngrep(\"\\\\!\", cat_string, value = TRUE)\n\n[1] \"I know people who have seen the Barbie movie 2, 3, even 4 times! I wonder if they have seen Oppenheimer, too.\"\n\ngrepl(\"\\\\!\", cat_string)\n\n[1] TRUE\n\n\n\nThe str_replace_all function can be used to replace all instances of a given string, with an alternative string.\n\n\nstr_replace_all(cat_string, \"e\",\"_\")\n\n[1] \"I know p_opl_ who hav_ s__n th_ Barbi_ movi_ 2, 3, _v_n 4 tim_s! I wond_r if th_y hav_ s__n Opp_nh_im_r, too.\"\n\n\n\nWe can also pull out all sub-strings matching a given string argument.\n\nThis becomes especially useful when we generalize the patterns of interest.\n\n\n\nstr_extract_all(cat_string, \"have\")\n\n[[1]]\n[1] \"have\" \"have\"\n\nstr_extract_all(cat_string,\"[0-9]+\")[[1]] \n\n[1] \"2\" \"3\" \"4\"\n\n#   The square brackets define a set of possibilities.\n#   The \"0-9\" says the possibilities are any digit from 0 to 9.\n#   The \"+\" means \"one or more of the just-named thing\"\n\nstr_extract_all(cat_string,\"\\\\d+\")[[1]] #   Instead of 0-9, we can just say \"\\\\d\" for digits\n\n[1] \"2\" \"3\" \"4\"\n\nstr_extract_all(cat_string,\"[a-zA-Z]+\")[[1]] # letters\n\n [1] \"I\"           \"know\"        \"people\"      \"who\"         \"have\"       \n [6] \"seen\"        \"the\"         \"Barbie\"      \"movie\"       \"even\"       \n[11] \"times\"       \"I\"           \"wonder\"      \"if\"          \"they\"       \n[16] \"have\"        \"seen\"        \"Oppenheimer\" \"too\"        \n\nstr_extract_all(cat_string,\"\\\\w+\")[[1]] # \"word\" characters\n\n [1] \"I\"           \"know\"        \"people\"      \"who\"         \"have\"       \n [6] \"seen\"        \"the\"         \"Barbie\"      \"movie\"       \"2\"          \n[11] \"3\"           \"even\"        \"4\"           \"times\"       \"I\"          \n[16] \"wonder\"      \"if\"          \"they\"        \"have\"        \"seen\"       \n[21] \"Oppenheimer\" \"too\""
  },
  {
    "objectID": "09_textanalysis.html#simple-text-analysis",
    "href": "09_textanalysis.html#simple-text-analysis",
    "title": "9  Text analysis",
    "section": "9.4 Simple text analysis",
    "text": "9.4 Simple text analysis\n\nWe can use the tidytext package to conduct some basic text analysis using tidy data principles.\nAs Wickham 2014 reminds us, tidy data has a specific structure:\n\nEach variable is a column.\nEach observation is a row.\nEach type of observational unit is a table.\n\nWe can thus define the format as a table with one-token-per-row.\n\nA token is a unit of text (e.g., word) that we use for analysis. Tokenization is the process of turning text into tokens.\n\nAs Silge and Robinson (2017) remind us, it is important to contrast this structure with the alternative ways that text is often structured and stored in text analysis:\n\nString: Text can be stored as strings, i.e., character vectors. Text data is often first read into memory in this form.\nCorpus: These objects usually contain raw strings annotated with metadata and details.\nDocument-term matrix: This sparse matrix describe a collection (i.e., a corpus) of documents with one row for each document and one column for each term. The value in the matrix is typically word count or tf-idf (term frequency-inverse document frequency).\n\nLet’s try an example. To create a tidy text dataset, we need to first put some text into a data frame.\n\nWe print out each line as a “tibble,” which has a convenient print method that does not convert strings to factors or use row names.\n\n\n\nlibrary(dplyr)\n\nBarbie &lt;- c(\"I'm a Barbie girl in the Barbie world\",\n            \"Life in plastic, it's fantastic\",\n            \"You can brush my hair, undress me everywhere\",\n            \"Imagination, life is your creation\")\nBarbie\n\n[1] \"I'm a Barbie girl in the Barbie world\"       \n[2] \"Life in plastic, it's fantastic\"             \n[3] \"You can brush my hair, undress me everywhere\"\n[4] \"Imagination, life is your creation\"          \n\nBarbie_df &lt;- tibble(line = 1:4, text = Barbie)\nBarbie_df\n\n# A tibble: 4 × 2\n   line text                                        \n  &lt;int&gt; &lt;chr&gt;                                       \n1     1 I'm a Barbie girl in the Barbie world       \n2     2 Life in plastic, it's fantastic             \n3     3 You can brush my hair, undress me everywhere\n4     4 Imagination, life is your creation          \n\n\n\nWe then break the text into individual tokens (tokenization) using tidytext’s unnest_tokens() function.\n\nThe two basic arguments for the unnest_tokens() function are column names. We have the output column, word, created by unnesting the text, and we have the input column, text, where the text being unnested comes from.\n\n\n\ninstall.packages(\"tidytext\")\n\n\nlibrary(tidytext)\n\nBarbie_df %&gt;%\n  unnest_tokens(word, text)\n\n# A tibble: 26 × 2\n    line word  \n   &lt;int&gt; &lt;chr&gt; \n 1     1 i'm   \n 2     1 a     \n 3     1 barbie\n 4     1 girl  \n 5     1 in    \n 6     1 the   \n 7     1 barbie\n 8     1 world \n 9     2 life  \n10     2 in    \n# ℹ 16 more rows\n\n\n\n9.4.1 Counts\n\nOnce we have our tidy structure, we can then perform very simple tasks such as finding the most common words in our text as a whole. Let’s instead work with a short passage from a famous interview with J. Robert Oppenheimer.\n\nWe can use the count() function from the dplyr package with ease here.\n\n\n\nOppenheimer &lt;- c(\"We knew the world would not be the same.\",\n                 \"A few people laughed, a few people cried, most people were silent.\",\n                 \"I remembered the line from the Hindu scripture, the Bhagavad-Gita.\",\n                 \"Vishnu is trying to persuade the Prince that he should do his duty and to impress him \n                 takes on his multi-armed form and says, “Now, I am become Death, the destroyer of \n                 worlds.”\", \n                 \"I suppose we all thought that one way or another.\")\n\nOpp_df &lt;- tibble(line = 1:5, text = Oppenheimer)\n\nOpp_tok &lt;- unnest_tokens(Opp_df, word, text)\n\nOpp_tok %&gt;%\n  count(word, sort = TRUE)\n\n# A tibble: 59 × 2\n   word       n\n   &lt;chr&gt;  &lt;int&gt;\n 1 the        7\n 2 i          3\n 3 people     3\n 4 a          2\n 5 and        2\n 6 few        2\n 7 his        2\n 8 that       2\n 9 to         2\n10 we         2\n# ℹ 49 more rows\n\n\n\nOur word counts are stored in a tidy data frame, which allows us to pipe these data directly to the ggplot2 package and create a simple visualization of the most common words in the short excerpt.\n\n\nlibrary(ggplot2)\nOpp_tok %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  filter(n &gt; 1) %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n  ggplot(aes(n, word)) +\n  geom_col() +\n  labs(y = NULL)\n\n\n\n\n\n\n9.4.2 tf-idf\n\nAnother way to quantify what a document is about is to calculate a term’s inverse document frequency (idf), which decreases the weight for commonly used words and increases the weight for words that are not used as frequently in a corpus.\nIf we multiply together the term frequency (tf) with the idf, we can calculate the tf-idf, the frequency of a term adjusted for how infrequently it is used.\n\nThe tf-idf statistic measures how important a word is to document that is part of a corpus.\n\nWe are going to take a look at the published novels of Jane Austen, an example from Silge and Robinson (2017).\n\nLet’s start by calculating the term frequency.\n\n\n\nlibrary(janeaustenr)\n\nbook_words &lt;- austen_books() %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  count(book, word, sort = TRUE)\n\ntotal_words &lt;- book_words %&gt;% \n  group_by(book) %&gt;% \n  summarize(total = sum(n))\n\nbook_words &lt;- left_join(book_words, total_words)\n\nbook_words\n\n# A tibble: 40,379 × 4\n   book              word      n  total\n   &lt;fct&gt;             &lt;chr&gt; &lt;int&gt;  &lt;int&gt;\n 1 Mansfield Park    the    6206 160460\n 2 Mansfield Park    to     5475 160460\n 3 Mansfield Park    and    5438 160460\n 4 Emma              to     5239 160996\n 5 Emma              the    5201 160996\n 6 Emma              and    4896 160996\n 7 Mansfield Park    of     4778 160460\n 8 Pride & Prejudice the    4331 122204\n 9 Emma              of     4291 160996\n10 Pride & Prejudice to     4162 122204\n# ℹ 40,369 more rows\n\n\n\nWe can then take these data and visualize them for each of the books in the dataset.\n\n\nggplot(book_words, aes(n/total, fill = book)) +\n  geom_histogram(show.legend = FALSE) +\n  xlim(NA, 0.0009) +\n  facet_wrap(~book, ncol = 2, scales = \"free_y\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 896 rows containing non-finite values (`stat_bin()`).\n\n\nWarning: Removed 6 rows containing missing values (`geom_bar()`).\n\n\n\n\n\n\nThe bind_tf_idf() function in the tidytext package then takes a dataset as input with one row per token (term) per document, calculating the tf-idf statistics. Let’s look at terms with high scores.\n\nBelow we see all proper nouns, mostly names of characters. None of them occur across all of Jane Austen’s novels, which is why they are important, defining terms for each of the texts.\n\n\n\nbook_tf_idf &lt;- book_words %&gt;%\n  bind_tf_idf(word, book, n)\n\nbook_tf_idf %&gt;%\n  select(-total) %&gt;%\n  arrange(desc(tf_idf))\n\n# A tibble: 40,379 × 6\n   book                word          n      tf   idf  tf_idf\n   &lt;fct&gt;               &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 Sense & Sensibility elinor      623 0.00519  1.79 0.00931\n 2 Sense & Sensibility marianne    492 0.00410  1.79 0.00735\n 3 Mansfield Park      crawford    493 0.00307  1.79 0.00551\n 4 Pride & Prejudice   darcy       373 0.00305  1.79 0.00547\n 5 Persuasion          elliot      254 0.00304  1.79 0.00544\n 6 Emma                emma        786 0.00488  1.10 0.00536\n 7 Northanger Abbey    tilney      196 0.00252  1.79 0.00452\n 8 Emma                weston      389 0.00242  1.79 0.00433\n 9 Pride & Prejudice   bennet      294 0.00241  1.79 0.00431\n10 Persuasion          wentworth   191 0.00228  1.79 0.00409\n# ℹ 40,369 more rows\n\n\n\nLet’s end with a visualization for the high tf-idf words in each of Jane Austen’s novels.\n\nThese results highlight that what distinguishes one novel from another within the collection of her works (the corpus) are the proper nouns, mainly the names of people and places. These are the terms that are “important” for defining the character of each document.\n\n\n\nlibrary(forcats)\n\nbook_tf_idf %&gt;%\n  group_by(book) %&gt;%\n  slice_max(tf_idf, n = 15) %&gt;%\n  ungroup() %&gt;%\n  ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = book)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~book, ncol = 2, scales = \"free\") +\n  labs(x = \"tf-idf\", y = NULL)\n\n\n\n\n\n\n\n\nArel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman. 2018. “Countrycode: An r Package to Convert Country Names and Country Codes.” Journal of Open Source Software 3 (28): 848. https://doi.org/10.21105/joss.00848.\n\n\nBank, World. 2023. “World Bank Open Data.” https://data.worldbank.org/.\n\n\nDahlberg, Stefan, Aksen Sundström, Sören Holmberg, Bo Rothstein, Natalia Alvarado Pachon, Cem Mert Dalli, and Yente Meijers. 2023. “The Quality of Government Basic Dataset, Version Jan23.” University of Gothenburg: The Quality of Government Institute. https://www.gu.se/en/quality-government doi:10.18157/qogbasjan23.\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nRobinson, David. 2020. Fuzzyjoin: Join Tables Together on Inexact Matching. https://github.com/dgrtwo/fuzzyjoin.\n\n\nSmith, Danny. 2020. Survey Research Datasets and R. https://socialresearchcentre.github.io/r_survey_datasets/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "10_wrapup.html#project-management",
    "href": "10_wrapup.html#project-management",
    "title": "10  Wrap up",
    "section": "10.1 Project management",
    "text": "10.1 Project management\n\n10.1.1 RStudio projects\n\nRStudio projects are an excellent way to keep all the files associated with a project (data, R scripts, results, figures, etc.) in one place on your computer.\nThis is one of the best ways to improve your workflow in RStudio, allowing you to:\n\nCreate a project for each paper or data analysis project.\nStore data files in one place.\nSave, edit, and run scripts.\nKeep outputs such as plots and cleaned data.\n\nTo create a new project file, click File &gt; New Project, then:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCall your project some version of “methodscamptest” and choose carefully where you wish to store the project on your machine.\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you don’t store your project (and your other files, too!) somewhere reasonable, it will be hard to find it in the future! We recommend creating a clear organizational scheme for yourself early on.\n\n\n\n10.1.1.1 Using RStudio projects\nWhen using an RStudio project, you should see its name in the top-right corner of RStudio, next to a light blue icon. You can check with R the folder in which your project operates:\n\ngetwd()\n\n\nNow, as an example, let’s run the following commands in the script editor and save the files into the project directory.\n\n\nlibrary(tidyverse)\n\nmy_plot &lt;- ggplot(mtcars, aes(wt, mpg)) + \n  geom_point()\n\nggsave(plot = my_plot,\n       filename = \"plot_mtcars.pdf\")\n\nwrite_csv(mtcars, \"mtcars.csv\")\n\n\nQuit RStudio and check out the folder associated with the project.\nYou should see the PDF file for the plot, the .csv file for the data, and the .Rproj file for the project itself.\nDouble-click the .Rproj file to reopen the project and pick up where you left off! Everything you need should be ready to go."
  },
  {
    "objectID": "10_wrapup.html#other-resources",
    "href": "10_wrapup.html#other-resources",
    "title": "10  Wrap up",
    "section": "10.2 Other resources",
    "text": "10.2 Other resources\n\n10.2.1 Overleaf\n\n\n\n\nOverleaf is a collaborative cloud-based LaTeX editor designed for writing, editing, and publishing documents.\n\nLaTeX is a software used for typesetting technical documents. It is used widely in our discipline for the preparation for manuscripts to journals and other publishing venues.\n\nUT Austin actually provides free access to Overleaf Professional to all graduate students using your UT email.\nOverleaf Professional upgrades include:\n\nReal-time collaboration\nReal-time track changes and visible collaborator cursor(s)\nReal-time PDF preview of your document while editing and writing\nFull history view of your documents\nTwo-way sync with Dropbox and GitHub\nReference manager sync and advanced reference search.\nUT Austin resource portal, including UT Austin templates, FAQs, and resource links\n\n\n\n\n\n\n\n\nImportant\n\n\n\nLaTeX is actually the markup language that powers this website! If you are curious about general syntax and commands, you can access our repository at any time to get a closer look.\n\n\n\n\n10.2.2 Zotero\n\n\n\n\nZotero is an open-source reference manager used to store, manage, and cite bibliographic references, such as books and articles.\nWhen it is time to write, you can insert your sources directly into your paper as in-text citations via a word processor plugin, which generates a bibliography in your style of choice.\n\nThis can save a lot of time, especially when you have to change citation styles for submission to another journal.\n\nYou can download the software for free here.\n\nYou can also find a guide on how to install it here.\n\n\n\n\n\n\n\n\nNote\n\n\n\nZotero is one of many other reference managers out there. Alternatives include Mendeley and EndNote, among others. You should choose whatever option best suits your needs.\n\n\n\n10.2.2.1 Benefits of Zotero\n\nIf you have not yet chosen a reference manager or are considering switching, below are some advantages of Zotero:\n\nWorks as a standalone desktop software with plugins for Chrome, Safari, and Firefox\nFull compatibility with Google docs\nFree plugin for Word and LibreOffice included\nIncludes most popular citation styles with more styles available on the Zotero Style Repository\nDrag and drop PDF files into the library, extracting metadata such as authors, year, etc.\nAllows advanced searches of all content in your library using full-text PDF indexing\nUse cloud storage (optional) and sync libraries across devices\nCreate unlimited private or public groups and collaborate by sharing files and citations\n300MB of free cloud storage and 2GB of storage for $20 USD/year (equal to $1.67 per month)\n\nHere is a comprehensive guide to unlocking all of Zotero’s potential."
  },
  {
    "objectID": "10_wrapup.html#methods-at-ut",
    "href": "10_wrapup.html#methods-at-ut",
    "title": "10  Wrap up",
    "section": "10.3 Methods at UT",
    "text": "10.3 Methods at UT\n\n10.3.1 Required methods courses\n\nScope and Methods of Political Science\n\nStatistics I (Statistics/linear regression)\n\nStatistics II (Linear regression and more)\nStatistics III (Maximum likelihood estimation)\n\nOnly required if your major field is methods\n\n\n\n\n10.3.2 Other methods courses\n\nStatistics/econometrics:\n\nBayesian Statistics\nCausal Inference\nMath Methods for Political Analysis\nTime Series and Panel Data\nPanel and Multilevel Analysis\n\n\n\n\n10.3.3 More courses\n\nFormal Theory\n\nIntro to Formal Political Analysis\nFormal Political Analysis II\nFormal Theories of International Relations\n\nEverything else\n\nConceptualization and Measurement\nExperimental Methods in Political Science\nQualitative Methods\nNetwork Analysis\nSeminar in Field Experiments\n\n\n\n\n10.3.4 Other departments at UT\nYou can also take courses through the Economics, Mathematics, or Statistics (Statistics and Data Science) departments.\n\nM.S. in Statistics\n\nSoftware and Topic Short Courses - R, Python, Stata, etc.\n\nMore info here.\n\n\n\n10.3.5 Other resources\nSummer programs at UT:\n\nShort courses in statistics\n\nDepartment sometimes offers scholarships to cover part of the cost.\n\n\nSummer programs outside UT:\n\nICPSR (Inter-university Consortium for Political and Social Research)\n\nAnn Arbor, Michigan\n\nEITM (Empirical Implications of Theoretical Models)\n\nHouston and other locations (Michigan, Duke, Berkeley, Emory)\n\nIQMR (Institute for Qualitative and Multi-Method Research)\n\nSyracuse, NY\n\n\n\n\n\n\nArel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman. 2018. “Countrycode: An r Package to Convert Country Names and Country Codes.” Journal of Open Source Software 3 (28): 848. https://doi.org/10.21105/joss.00848.\n\n\nBank, World. 2023. “World Bank Open Data.” https://data.worldbank.org/.\n\n\nDahlberg, Stefan, Aksen Sundström, Sören Holmberg, Bo Rothstein, Natalia Alvarado Pachon, Cem Mert Dalli, and Yente Meijers. 2023. “The Quality of Government Basic Dataset, Version Jan23.” University of Gothenburg: The Quality of Government Institute. https://www.gu.se/en/quality-government doi:10.18157/qogbasjan23.\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nRobinson, David. 2020. Fuzzyjoin: Join Tables Together on Inexact Matching. https://github.com/dgrtwo/fuzzyjoin.\n\n\nSmith, Danny. 2020. Survey Research Datasets and R. https://socialresearchcentre.github.io/r_survey_datasets/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Arel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman. 2018.\n“Countrycode: An r Package to Convert Country Names and Country\nCodes.” Journal of Open Source Software 3 (28): 848. https://doi.org/10.21105/joss.00848.\n\n\nBank, World. 2023. “World Bank Open Data.” https://data.worldbank.org/.\n\n\nDahlberg, Stefan, Aksen Sundström, Sören Holmberg, Bo Rothstein, Natalia\nAlvarado Pachon, Cem Mert Dalli, and Yente Meijers. 2023. “The\nQuality of Government Basic Dataset, Version Jan23.” University\nof Gothenburg: The Quality of Government Institute. https://www.gu.se/en/quality-government\ndoi:10.18157/qogbasjan23.\n\n\nFiveThirtyEight. 2021. “Tracking Congress\nIn The Age Of\nTrump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nRobinson, David. 2020. Fuzzyjoin: Join Tables Together on Inexact\nMatching. https://github.com/dgrtwo/fuzzyjoin.\n\n\nSmith, Danny. 2020. Survey Research Datasets and\nR. https://socialresearchcentre.github.io/r_survey_datasets/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service.\n2019. “Department of Agriculture Agricultural Research\nService.” https://fdc.nal.usda.gov/."
  }
]