[
  {
    "objectID": "index.html#class-schedule",
    "href": "index.html#class-schedule",
    "title": "Methods Camp",
    "section": "Class schedule",
    "text": "Class schedule\n\n\n\nDate\nTime\nLocation\n\n\n\n\nThurs, Aug. 10\n9:00 AM - 4:00 PM\nRLP 1.302E\n\n\nFri, Aug. 11\n9:00 AM - 4:00 PM\nRLP 1.302E\n\n\nSat, Aug. 12\nNo class\n-\n\n\nSun, Aug. 13\nNo class\n-\n\n\nMon, Aug. 14\n9:00 AM - 4:00 PM\nRLP 1.302E\n\n\nTues, Aug. 15\n9:00 AM - 4:00 PM\nRLP 1.302E\n\n\nWeds, Aug. 16\n9:00 AM - 4:00 PM\nRLP 1.302E\n\n\n\nOn class days, we will have a lunch break from 12:00-1:00 PM. We’ll also take short breaks periodically during the morning and afternoon sessions as needed."
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "Methods Camp",
    "section": "Description",
    "text": "Description\nWelcome to Introduction to Methods for Political Science, aka “Methods Camp”! In the past our incoming students have told us their math skills are rusty and they would like to be better prepared for UT’s methods courses. Methods Camp is designed to give everyone a chance to brush up on some skills in preparation for the Stats I and Formal Theory I courses. The other goal of Methods Camp is to allow you to get to know your cohort. We hope that struggling with matrix algebra and the dreaded chain rule will still prove to be a good bonding exercise.\nAs you can see from the above schedule, we’ll be meeting on Thursday, August 10th and Friday, August 11th as well as from Monday, August 14th through Wednesday, August 16th. Classes at UT begin the start of the following week on Monday, August 22nd. Below is a tentaive schedule outlining what will be covered in the class, although we may rearrange things a bit if we find we’re going too slowly or too quickly through any of the material."
  },
  {
    "objectID": "index.html#course-outline",
    "href": "index.html#course-outline",
    "title": "Methods Camp",
    "section": "Course outline",
    "text": "Course outline\n1 Thursday morning: R and RStudio\n\nIntroductions\nRStudio (materials are on the website as zipped RStudio projects)\nObjects (vectors, matrices, data frames)\nBasic functions (mean(), length(), etc.)\n\n2 Thursday afternoon: tidyverse basics I\n\nPackages: installation and loading (including the tidyverse)\nData wrangling with dplyr (basic verbs, including the new .by = syntax)\nData visualization basics with ggplot2\nData loading (.csv, .rds, .dta, .xlsx)\nQuarto fundamentals\n\n3 Friday morning: Matrices\n\nMatrices\nSystems of linear equations\nMatrix operations (multiplication, transpose, inverse, determinant).\nSolving systems of linear equations in matrix form (and why that’s cool)\nIntroduction to OLS\n\n4 Friday afternoon: tidyverse basics II\n\nData merging and pivoting (*_join(), pivot_*())\nValue recoding (if_else(), case_when())\nMissing values\nData visualization extensions: facets, text annotations\n\n5 Monday morning: Functions and loops\n\nFunctions\nFor-loops and lapply()\nFinding R help (help files, effective Googling, ChatGPT)\n\n6 Monday afternoon: Calculus\n\nLimits (not sure how to teach this in an R-centric way yet, but there must be a way)\nDerivatives (symbolic, numerical, automatic)\nIntegrals\n\n7 Tuesday morning: Probability\n\nConcepts: probability, random variables, etc.\nPMF, PDF, CDF, etc.\nDistributions (binomial, normal; different functions in R and how to use them)\nExpectation and variance\n\n8 Tuesday afternoon: Simulations\n\nSimulations (ideas, seed setting, etc.)\nSampling\nBootstrapping\n\n9 Wednesday morning: Text analysis\n\nString manipulation with stringr\nSimple text analysis (counts, tf-idf, etc.) with tidytext and visualization\n\n10 Wednesday afternoon: Wrap-up\n\nProject management fundamentals (RStudio projects, keeping raw data, etc.)\nSelf-study resources and materials\nOther software (Overleaf, Zotero, etc.)\nMethods at UT"
  },
  {
    "objectID": "index.html#contact-info",
    "href": "index.html#contact-info",
    "title": "Methods Camp",
    "section": "Contact info",
    "text": "Contact info\nIf you have any questions during or outside of methods camp, you can contact us via email:\n\nAndrés Cruz: andres.cruz at utexas dot edu\nMatt Martin: mjmartin at utexas dot edu\n\nIf you are interested in learning more about our research, you can also check out our respective websites:\n\nAndrés Cruz via GitHub Pages\nMatt Martin via GitHub Pages\n\nOr, follow us on Twitter (or should we say X…):\n\nAndrés Cruz: https://twitter.com/arcruz0\nMatt Martin: https://twitter.com/MattJ_Martin\n\n\n\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "00_setup.html#installing-r-and-rstudio",
    "href": "00_setup.html#installing-r-and-rstudio",
    "title": "Setup",
    "section": "Installing R and RStudio",
    "text": "Installing R and RStudio\nR is a programming language optimized for statistics and data analysis. Most people use R from RStudio, a graphical user interface (GUI) that includes a file pane, a graphics pane, and other goodies. Both R and RStudio are open source, i.e., free as in beer and free as in freedom!\nYour first steps should be to install R and RStudio, in that order (if you have installed these programs before, make sure that your versions are up-to-date—if they are not, follow the instructions below):\n\nDownload and install R from the official website, CRAN. Click on “Download R for &lt;Windows/Mac&gt;” and follow the instructions. If you have a Mac, make sure to select the version appropriate for your system (Apple Silicon for newer M1/M2 Macs and Intel for older Macs).\nDownload and install RStudio from the official website. Scroll down and select the installer for your operating system.\n\nAfter these two steps, you can open RStudio in your system, as you would with any program. You should see something like this:\n\n\n\nFigure 1: How RStudio looks after a clean installation.\n\n\nThat’s it for the installation! We also strongly recommend that you change a couple of RStudio’s default settings.1 You can change settings by clicking on Tools &gt; Global Options in the menubar. Here are our recommendations:\n\nGeneral &gt; Uncheck \"Restore .RData into workspace at startup\"\nGeneral &gt; Save workspace to .RData on Exit &gt; Select \"Never\"\nCode &gt; Check \"Use native pipe operator\"\nTools &gt; Global Options &gt; Appearance to change to a dark theme, if you want! Pros: better for night sessions, hacker vibes…"
  },
  {
    "objectID": "00_setup.html#setting-up-for-methods-camp",
    "href": "00_setup.html#setting-up-for-methods-camp",
    "title": "Setup",
    "section": "Setting up for Methods Camp",
    "text": "Setting up for Methods Camp\nAll materials for Methods Camp are both on this website and an RStudio project. An RStudio project is simply a folder where one keeps scripts, datasets, and other files needed for a data analysis project.\nYou can download our RStudio project here, as a .zip compressed file. On MacOS, the file will be uncompressed automatically. On Windows, you should do Right click &gt; Extract all.\n\n\n\n\n\n\nWarning\n\n\n\nMake sure to properly unzip the materials. Double-clicking the .zip file on most Windows systems will not unzip the folder—you must do Right click &gt; Extract all.\n\n\nYou should now have a folder called methodscamp/ on your computer. Navigate to the methodscamp.Rproj file within it and open it. RStudio should open the project right away. You should see methodscamp on the top-right of RStudio—this indicates that you are working in our RStudio project.\n\n\n\nFigure 2: How the bottom-right corner of RStudio looks after opening our project.\n\n\nThat’s all for setup! We can now start coding. After opening our RStudio project, we’ll begin by opening the 01_r_intro.qmd file from the “Files” panel, in the bottom-right portion of RStudio. This is a Quarto document,2 which contains both code and explanations (you can also read in the next chapter of this website).\n\n\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "00_setup.html#footnotes",
    "href": "00_setup.html#footnotes",
    "title": "Setup",
    "section": "",
    "text": "The idea behind these settings (or at least the first two) is to force R to start from scratch with each new session. No lingering objects from previous coding sessions avoids misunderstandings and helps with reproducibility!↩︎\nPerhaps you have used R Markdown before. Quarto is the next iteration of R Markdown, and is both more flexible and more powerful!↩︎"
  },
  {
    "objectID": "01_r_intro.html#objects",
    "href": "01_r_intro.html#objects",
    "title": "1  Intro to R",
    "section": "1.1 Objects",
    "text": "1.1 Objects\nA huge part of R is working with objects. Let’s see how they work:\n\nmy_object &lt;- 10 # opt/alt + minus sign will make the arrow \n\n\nmy_object # to print the value of an object, just call its name\n\n[1] 10\n\n\nWe can now use this object in our operations:\n\n2 ^ my_object\n\n[1] 1024\n\n\nOr even create another object out of it:\n\nmy_object2 &lt;- my_object * 2\n\n\nmy_object2\n\n[1] 20\n\n\nYou can delete objects with the rm() function (for “remove”):\n\nrm(my_object2)"
  },
  {
    "objectID": "01_r_intro.html#vectors-and-functions",
    "href": "01_r_intro.html#vectors-and-functions",
    "title": "1  Intro to R",
    "section": "1.2 Vectors and functions",
    "text": "1.2 Vectors and functions\nObjects can be of different types. One of the most useful ones is the vector, which holds a series of values. To create one manually, we can use the c() function (for “combine”):\n\nmy_vector &lt;- c(6, -11, my_object, 0, 20)\n\n\nmy_vector\n\n[1]   6 -11  10   0  20\n\n\nOne can also define vectors by sequences:\n\n3:10\n\n[1]  3  4  5  6  7  8  9 10\n\n\nWe can use square brackets to retrieve parts of vectors:\n\nmy_vector[4] # fourth element\n\n[1] 0\n\n\n\nmy_vector[1:2] # first two elements\n\n[1]   6 -11\n\n\nLet’s check out some basic functions we can use with numbers and numeric vectors:\n\nsqrt(my_object) # squared root\n\n[1] 3.162278\n\n\n\nlog(my_object) # logarithm (natural by default)\n\n[1] 2.302585\n\n\n\nabs(-5) # absolute value\n\n[1] 5\n\n\n\nmean(my_vector)\n\n[1] 5\n\n\n\nmedian(my_vector)\n\n[1] 6\n\n\n\nsd(my_vector) # standard deviation\n\n[1] 11.53256\n\n\n\nsum(my_vector)\n\n[1] 25\n\n\n\nmin(my_vector) # minimum value\n\n[1] -11\n\n\n\nmax(my_vector) # maximum value\n\n[1] 20\n\n\n\nlength(my_vector) # length (number of elements)\n\n[1] 5\n\n\nNotice that if we wanted to save any of these results for later, we would need to assign them:\n\nmy_mean &lt;- mean(my_vector)\n\n\nmy_mean\n\n[1] 5\n\n\nThese functions are quite simple: they take one object and do one operation. A lot of functions are a bit more complex—they take multiple objects or take options. For example, see the sort() function, which by default sorts a vector increasingly:\n\nsort(my_vector)\n\n[1] -11   0   6  10  20\n\n\nIf we instead want to sort our vector decreasingly, we can use the decreasing = TRUE argument (T also works as an abbreviation for TRUE).\n\nsort(my_vector, decreasing = TRUE)\n\n[1]  20  10   6   0 -11\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you use the argument values in order, you can avoid writing the argument names (see below). This is sometimes useful, but can also lead to confusing code—use it with caution.\n\nsort(my_vector, T)\n\n[1]  20  10   6   0 -11\n\n\n\n\nA useful function to create vectors in sequence is seq(). Notice its arguments:\n\nseq(from = 30, to = 100, by = 5)\n\n [1]  30  35  40  45  50  55  60  65  70  75  80  85  90  95 100\n\n\nTo check the arguments of a function, you can examine its help file: look the function up on the “Help” panel on RStudio or use a command like the following: ?sort.\n\n\n\n\n\n\nExercise\n\n\n\nExamine the help file of the log() function. How can we compute the the base-10 logarithm of my_object? Your code:\n\n\nOther than numeric vectors, character vectors are also useful:\n\nmy_character_vector &lt;- c(\"Apple\", \"Orange\", \"Watermelon\", \"Banana\")\n\n\nmy_character_vector[3]\n\n[1] \"Watermelon\"\n\n\n\nnchar(my_character_vector) # count number of characters\n\n[1]  5  6 10  6"
  },
  {
    "objectID": "01_r_intro.html#data-frames-and-lists",
    "href": "01_r_intro.html#data-frames-and-lists",
    "title": "1  Intro to R",
    "section": "1.3 Data frames and lists",
    "text": "1.3 Data frames and lists\nAnother useful object type is the data frame. Data frames can store multiple vectors in a tabular format. We can manually create one with the data.frame() function:\n\nmy_data_frame &lt;- data.frame(fruit = my_character_vector,\n                            calories_per_100g = c(52, 47, 30, 89),\n                            water_per_100g = c(85.6, 86.8, 91.4, 74.9))\n\n\nmy_data_frame\n\n       fruit calories_per_100g water_per_100g\n1      Apple                52           85.6\n2     Orange                47           86.8\n3 Watermelon                30           91.4\n4     Banana                89           74.9\n\n\nNow we have a little 4x3 data frame of fruits with their calorie counts and water composition. We gathered the nutritional information from the USDA (2019).\nWe can use the data_frame$column construct to access the vectors within the data frame:\n\nmean(my_data_frame$calories_per_100g)\n\n[1] 54.5\n\n\n\n\n\n\n\n\nExercise\n\n\n\nObtain the maximum value of water content per 100g in the data. Your code:\n\n\nSome useful commands to learn attributes of our data frame:\n\ndim(my_data_frame)\n\n[1] 4 3\n\n\n\nnrow(my_data_frame)\n\n[1] 4\n\n\n\nnames(my_data_frame) # column names\n\n[1] \"fruit\"             \"calories_per_100g\" \"water_per_100g\"   \n\n\nWe will learn much more about data frames in our next module on data analysis.\nAfter talking about vectors and data frames, the last object type that we will cover is the list. Lists are super flexible objects that can contain just about anything:\n\nmy_list &lt;- list(my_object, my_vector, my_data_frame)\n\n\nmy_list\n\n[[1]]\n[1] 10\n\n[[2]]\n[1]   6 -11  10   0  20\n\n[[3]]\n       fruit calories_per_100g water_per_100g\n1      Apple                52           85.6\n2     Orange                47           86.8\n3 Watermelon                30           91.4\n4     Banana                89           74.9\n\n\nTo retrieve the elements of a list, we need to use double square brackets:\n\nmy_list[[1]]\n\n[1] 10\n\n\nLists are sometimes useful due to their flexibility, but are much less common in routine data analysis compared to vectors or data frames."
  },
  {
    "objectID": "01_r_intro.html#packages",
    "href": "01_r_intro.html#packages",
    "title": "1  Intro to R",
    "section": "1.4 Packages",
    "text": "1.4 Packages\nThe R community has developed thousands of packages, which are specialized collections of functions, datasets, and other resources. To install one, you should use the install.packages() command. Below we will install the tidyverse package, a suite for data analysis that we will use in the next modules. You just need to install packages once, and then they will be available system-wide.\n\ninstall.packages(\"tidyverse\") # this can take a couple of minutes\n\nIf you want to use an installed package in your script, you must load it with the library() function. Some packages, as shown below, will print descriptive messages once loaded.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\n\nWarning\n\n\n\nRemember that install.packages(\"package\") needs to be executed just once, while library(package) needs to be in each script in which you plan to use the package. In general, never include install.packages(\"package\") as part of your scripts or Quarto documents!\n\n\n\n\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "02_tidy_data1.html#loading-data",
    "href": "02_tidy_data1.html#loading-data",
    "title": "2  Tidy data analysis I",
    "section": "2.1 Loading data",
    "text": "2.1 Loading data\nThroughout this module we will work with a dataset of senators during the Trump presidency, which was adapted from FiveThirtyEight (2021).\nWe have stored the dataset in .csv format under the data/ subfolder. Loading it into R is simple (notice that we need to assign it to an object):\n\ntrump_scores &lt;- read_csv(\"data/trump_scores_538.csv\")\n\nRows: 122 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): bioguide, last_name, state, party\ndbl (4): num_votes, agree, agree_pred, margin_trump\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ntrump_scores\n\n# A tibble: 122 × 8\n   bioguide last_name  state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 A000360  Alexander  TN    R           118 0.890      0.856       26.0  \n 2 B000575  Blunt      MO    R           128 0.906      0.787       18.6  \n 3 B000944  Brown      OH    D           128 0.258      0.642        8.13 \n 4 B001135  Burr       NC    R           121 0.893      0.560        3.66 \n 5 B001230  Baldwin    WI    D           128 0.227      0.510        0.764\n 6 B001236  Boozman    AR    R           129 0.915      0.851       26.9  \n 7 B001243  Blackburn  TN    R           131 0.885      0.889       26.0  \n 8 B001261  Barrasso   WY    R           129 0.891      0.895       46.3  \n 9 B001267  Bennet     CO    D           121 0.273      0.417       -4.91 \n10 B001277  Blumenthal CT    D           128 0.203      0.294      -13.6  \n# ℹ 112 more rows\n\n\nLet’s review the dataset’s columns:\n\nbioguide: A unique ID for each politician, from the Congress Bioguide.\nlast_name\nstate\nparty\nnum_votes: Number of votes for which data was available.\nagree: Proportion (0-1) of votes in which the senator voted in agreement with Trump.\nagree_pred: Predicted proportion of vote agreement, calculated using Trump’s margin (see next variable).\nmargin_trump: Margin of victory (percentage points) of Trump in the senator’s state.\n\nWe can inspect our data by using the interface above. An alternative is to run the command View(trump_scores) or click on the object in RStudio’s environment panel (in the top-right section).\nDo you have any questions about the data?\nBy the way, the tidyverse works amazingly with tidy data. If you can get your data to this format (and we will see ways to do this), your life will be much easier:\n\n\n\n\n\n\n\n\n\n\n\nSource: Illustrations from the Openscapes blog Tidy Data for reproducibility, efficiency, and collaboration by Julia Lowndes and Allison Horst."
  },
  {
    "objectID": "02_tidy_data1.html#wrangling-data-with-dplyr",
    "href": "02_tidy_data1.html#wrangling-data-with-dplyr",
    "title": "2  Tidy data analysis I",
    "section": "2.2 Wrangling data with dplyr",
    "text": "2.2 Wrangling data with dplyr\nWe often need to modify data to conduct our analyses, e.g., creating columns, filtering rows, etc. In the tidyverse, these operations are conducted with multiple verbs, which we will review now.\n\n2.2.1 Selecting columns\nWe can select specific columns in our dataset with the select() function. All dplyr wrangling verbs take a data frame as their first argument—in this case, the columns we want to select are the other arguments.\n\nselect(trump_scores, last_name, party)\n\n# A tibble: 122 × 2\n   last_name  party\n   &lt;chr&gt;      &lt;chr&gt;\n 1 Alexander  R    \n 2 Blunt      R    \n 3 Brown      D    \n 4 Burr       R    \n 5 Baldwin    D    \n 6 Boozman    R    \n 7 Blackburn  R    \n 8 Barrasso   R    \n 9 Bennet     D    \n10 Blumenthal D    \n# ℹ 112 more rows\n\n\nThis is a good moment to talk about “pipes.” Notice how the code below produces the same output as the one above, but with a slightly different syntax. Pipes (|&gt;) “kick” the object on the left of the pipe to the first argument of the function on the right. One can read pipes as “then,” so the code below can be read as “take trump_scores, then select the columns last_name and party.” Pipes are very useful to chain multiple operations, as we will see in a moment.\n\ntrump_scores |&gt; \n  select(last_name, party)\n\n# A tibble: 122 × 2\n   last_name  party\n   &lt;chr&gt;      &lt;chr&gt;\n 1 Alexander  R    \n 2 Blunt      R    \n 3 Brown      D    \n 4 Burr       R    \n 5 Baldwin    D    \n 6 Boozman    R    \n 7 Blackburn  R    \n 8 Barrasso   R    \n 9 Bennet     D    \n10 Blumenthal D    \n# ℹ 112 more rows\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can insert a pipe with the Cmd/Ctrl + Shift + M shortcut. If you have not changed the default RStudio settings, an “old” pipe (%&gt;%) might appear. While most of the functionality is the same, the |&gt; “new” pipes are more readable. You can change this RStudio option in Tools &gt; Global Options &gt; Code &gt; Use native pipe operator. Make sure to check the other suggested settings in our Setup module!\n\n\nGoing back to selecting columns, you can select ranges:\n\ntrump_scores |&gt; \n  select(bioguide:party)\n\n# A tibble: 122 × 4\n   bioguide last_name  state party\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;\n 1 A000360  Alexander  TN    R    \n 2 B000575  Blunt      MO    R    \n 3 B000944  Brown      OH    D    \n 4 B001135  Burr       NC    R    \n 5 B001230  Baldwin    WI    D    \n 6 B001236  Boozman    AR    R    \n 7 B001243  Blackburn  TN    R    \n 8 B001261  Barrasso   WY    R    \n 9 B001267  Bennet     CO    D    \n10 B001277  Blumenthal CT    D    \n# ℹ 112 more rows\n\n\nAnd use a few helper functions, like matches():\n\ntrump_scores |&gt; \n  select(last_name, matches(\"agree\"))\n\n# A tibble: 122 × 3\n   last_name  agree agree_pred\n   &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 Alexander  0.890      0.856\n 2 Blunt      0.906      0.787\n 3 Brown      0.258      0.642\n 4 Burr       0.893      0.560\n 5 Baldwin    0.227      0.510\n 6 Boozman    0.915      0.851\n 7 Blackburn  0.885      0.889\n 8 Barrasso   0.891      0.895\n 9 Bennet     0.273      0.417\n10 Blumenthal 0.203      0.294\n# ℹ 112 more rows\n\n\nOr everything(), which we usually use to reorder columns:\n\ntrump_scores |&gt; \n  select(last_name, everything())\n\n# A tibble: 122 × 8\n   last_name  bioguide state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 Alexander  A000360  TN    R           118 0.890      0.856       26.0  \n 2 Blunt      B000575  MO    R           128 0.906      0.787       18.6  \n 3 Brown      B000944  OH    D           128 0.258      0.642        8.13 \n 4 Burr       B001135  NC    R           121 0.893      0.560        3.66 \n 5 Baldwin    B001230  WI    D           128 0.227      0.510        0.764\n 6 Boozman    B001236  AR    R           129 0.915      0.851       26.9  \n 7 Blackburn  B001243  TN    R           131 0.885      0.889       26.0  \n 8 Barrasso   B001261  WY    R           129 0.891      0.895       46.3  \n 9 Bennet     B001267  CO    D           121 0.273      0.417       -4.91 \n10 Blumenthal B001277  CT    D           128 0.203      0.294      -13.6  \n# ℹ 112 more rows\n\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that all these commands have not edited our existent objects—they have just printed the requested outputs to the screen. In order to modify objects, you need to use the assignment operator (&lt;-). For example:\n\ntrump_scores_reduced &lt;- trump_scores |&gt; \n  select(last_name, matches(\"agree\"))\n\n\ntrump_scores_reduced\n\n# A tibble: 122 × 3\n   last_name  agree agree_pred\n   &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 Alexander  0.890      0.856\n 2 Blunt      0.906      0.787\n 3 Brown      0.258      0.642\n 4 Burr       0.893      0.560\n 5 Baldwin    0.227      0.510\n 6 Boozman    0.915      0.851\n 7 Blackburn  0.885      0.889\n 8 Barrasso   0.891      0.895\n 9 Bennet     0.273      0.417\n10 Blumenthal 0.203      0.294\n# ℹ 112 more rows\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nSelect the variables last_name, party, num_votes, and agree from the data frame. Your code:\n\n\n\n\n2.2.2 Renaming columns\nWe can use the rename() function to rename columns, with the syntax new_name = old_name. For example:\n\ntrump_scores |&gt; \n  rename(prop_agree = agree, prop_agree_pred = agree_pred)\n\n# A tibble: 122 × 8\n   bioguide last_name  state party num_votes prop_agree prop_agree_pred\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;\n 1 A000360  Alexander  TN    R           118      0.890           0.856\n 2 B000575  Blunt      MO    R           128      0.906           0.787\n 3 B000944  Brown      OH    D           128      0.258           0.642\n 4 B001135  Burr       NC    R           121      0.893           0.560\n 5 B001230  Baldwin    WI    D           128      0.227           0.510\n 6 B001236  Boozman    AR    R           129      0.915           0.851\n 7 B001243  Blackburn  TN    R           131      0.885           0.889\n 8 B001261  Barrasso   WY    R           129      0.891           0.895\n 9 B001267  Bennet     CO    D           121      0.273           0.417\n10 B001277  Blumenthal CT    D           128      0.203           0.294\n# ℹ 112 more rows\n# ℹ 1 more variable: margin_trump &lt;dbl&gt;\n\n\nThis is a good occasion to show how pipes allow us to chain operations. How do we read the following code out loud? (Remember that pipes are read as “then”).\n\ntrump_scores |&gt; \n  select(last_name, matches(\"agree\")) |&gt; \n  rename(prop_agree = agree, prop_agree_pred = agree_pred)\n\n# A tibble: 122 × 3\n   last_name  prop_agree prop_agree_pred\n   &lt;chr&gt;           &lt;dbl&gt;           &lt;dbl&gt;\n 1 Alexander       0.890           0.856\n 2 Blunt           0.906           0.787\n 3 Brown           0.258           0.642\n 4 Burr            0.893           0.560\n 5 Baldwin         0.227           0.510\n 6 Boozman         0.915           0.851\n 7 Blackburn       0.885           0.889\n 8 Barrasso        0.891           0.895\n 9 Bennet          0.273           0.417\n10 Blumenthal      0.203           0.294\n# ℹ 112 more rows\n\n\n\n\n2.2.3 Creating columns\nIt is common to want to create columns, based on existing ones. We can use mutate() to do so. For example, we could want our main variables of interest in terms of percentages instead of proportions:\n\ntrump_scores |&gt; \n  select(last_name, agree, agree_pred) |&gt; # select just for clarity\n  mutate(pct_agree = 100 * agree,\n         pct_agree_pred = 100 * agree_pred)\n\n# A tibble: 122 × 5\n   last_name  agree agree_pred pct_agree pct_agree_pred\n   &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;\n 1 Alexander  0.890      0.856      89.0           85.6\n 2 Blunt      0.906      0.787      90.6           78.7\n 3 Brown      0.258      0.642      25.8           64.2\n 4 Burr       0.893      0.560      89.3           56.0\n 5 Baldwin    0.227      0.510      22.7           51.0\n 6 Boozman    0.915      0.851      91.5           85.1\n 7 Blackburn  0.885      0.889      88.5           88.9\n 8 Barrasso   0.891      0.895      89.1           89.5\n 9 Bennet     0.273      0.417      27.3           41.7\n10 Blumenthal 0.203      0.294      20.3           29.4\n# ℹ 112 more rows\n\n\nWe can also use multiple columns for creating a new one. For example, let’s retrieve the total number of votes in which the senator agreed with Trump:\n\ntrump_scores |&gt; \n  select(last_name, num_votes, agree) |&gt; # select just for clarity\n  mutate(num_votes_agree = num_votes * agree)\n\n# A tibble: 122 × 4\n   last_name  num_votes agree num_votes_agree\n   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;           &lt;dbl&gt;\n 1 Alexander        118 0.890           105  \n 2 Blunt            128 0.906           116  \n 3 Brown            128 0.258            33  \n 4 Burr             121 0.893           108  \n 5 Baldwin          128 0.227            29  \n 6 Boozman          129 0.915           118  \n 7 Blackburn        131 0.885           116  \n 8 Barrasso         129 0.891           115  \n 9 Bennet           121 0.273            33.0\n10 Blumenthal       128 0.203            26  \n# ℹ 112 more rows\n\n\n\n\n2.2.4 Filtering rows\nAnother common operation is to filter rows based on logical conditions. We can do so with the filter() function. For example, we can filter to only get Democrats:\n\ntrump_scores |&gt; \n  filter(party == \"D\")\n\n# A tibble: 55 × 8\n   bioguide last_name  state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 B000944  Brown      OH    D           128 0.258      0.642        8.13 \n 2 B001230  Baldwin    WI    D           128 0.227      0.510        0.764\n 3 B001267  Bennet     CO    D           121 0.273      0.417       -4.91 \n 4 B001277  Blumenthal CT    D           128 0.203      0.294      -13.6  \n 5 B001288  Booker     NJ    D           119 0.160      0.290      -14.1  \n 6 C000127  Cantwell   WA    D           128 0.242      0.276      -15.5  \n 7 C000141  Cardin     MD    D           128 0.25       0.209      -26.4  \n 8 C000174  Carper     DE    D           129 0.295      0.318      -11.4  \n 9 C001070  Casey      PA    D           129 0.287      0.508        0.724\n10 C001088  Coons      DE    D           128 0.289      0.319      -11.4  \n# ℹ 45 more rows\n\n\nNotice that == here is a logical operator, read as “is equal to.” So our full chain of operations says the following: take trump_scores, then filter it to get rows where party is equal to “D”.\nThere are other logical operators:\n\n\n\nLogical operator\nMeaning\n\n\n\n\n==\n“is equal to”\n\n\n!=\n“is not equal to”\n\n\n&gt;\n“is greater than”\n\n\n&lt;\n“is less than”\n\n\n&gt;=\n“is greater than or equal to”\n\n\n&lt;=\n“is less than or equal to”\n\n\n%in%\n“is contained in”\n\n\n&\n“and” (intersection)\n\n\n|\n“or” (union)\n\n\n\nLet’s see a couple of other examples.\n\ntrump_scores |&gt; \n  filter(agree &gt; 0.5)\n\n# A tibble: 69 × 8\n   bioguide last_name state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 A000360  Alexander TN    R           118 0.890      0.856        26.0 \n 2 B000575  Blunt     MO    R           128 0.906      0.787        18.6 \n 3 B001135  Burr      NC    R           121 0.893      0.560         3.66\n 4 B001236  Boozman   AR    R           129 0.915      0.851        26.9 \n 5 B001243  Blackburn TN    R           131 0.885      0.889        26.0 \n 6 B001261  Barrasso  WY    R           129 0.891      0.895        46.3 \n 7 B001310  Braun     IN    R            44 0.909      0.713        19.2 \n 8 C000567  Cochran   MS    R            68 0.971      0.830        17.8 \n 9 C000880  Crapo     ID    R           125 0.904      0.870        31.8 \n10 C001035  Collins   ME    R           129 0.651      0.441        -2.96\n# ℹ 59 more rows\n\n\n\ntrump_scores |&gt; \n  filter(state %in% c(\"CA\", \"TX\"))\n\n# A tibble: 4 × 8\n  bioguide last_name state party num_votes agree agree_pred margin_trump\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n1 C001056  Cornyn    TX    R           129 0.922      0.659         9.00\n2 C001098  Cruz      TX    R           126 0.921      0.663         9.00\n3 F000062  Feinstein CA    D           128 0.242      0.201       -30.1 \n4 H001075  Harris    CA    D           116 0.164      0.209       -30.1 \n\n\n\ntrump_scores |&gt; \n  filter(state == \"WV\" & party == \"D\")\n\n# A tibble: 1 × 8\n  bioguide last_name state party num_votes agree agree_pred margin_trump\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n1 M001183  Manchin   WV    D           129 0.504      0.893         42.2\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nAdd a new column to the data frame, called diff_agree, which subtracts agree and agree_pred. How would you create abs_diff_agree, defined as the absolute value of diff_agree? Your code:\nFilter the data frame to only get senators for which we have information on fewer than (or equal to) five votes. Your code:\nFilter the data frame to only get Democrats who agreed with Trump in at least 30% of votes. Your code:\n\n\n\n\n\n2.2.5 Ordering rows\nThe arrange() function allows us to order rows according to values. For example, let’s order based on the agree variable:\n\ntrump_scores |&gt; \n  arrange(agree)\n\n# A tibble: 122 × 8\n   bioguide last_name    state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 H000273  Hickenlooper CO    D             2 0         0.0302        -4.91\n 2 H000601  Hagerty      TN    R             2 0         0.115         26.0 \n 3 L000570  Luján        NM    D           186 0.124     0.243         -8.21\n 4 G000555  Gillibrand   NY    D           121 0.124     0.242        -22.5 \n 5 M001176  Merkley      OR    D           129 0.155     0.323        -11.0 \n 6 W000817  Warren       MA    D           116 0.155     0.216        -27.2 \n 7 B001288  Booker       NJ    D           119 0.160     0.290        -14.1 \n 8 S000033  Sanders      VT    D           112 0.161     0.221        -26.4 \n 9 H001075  Harris       CA    D           116 0.164     0.209        -30.1 \n10 M000133  Markey       MA    D           127 0.165     0.213        -27.2 \n# ℹ 112 more rows\n\n\nMaybe we only want senators with more than a few data points. Remember that we can chain operations:\n\ntrump_scores |&gt; \n  filter(num_votes &gt;= 10) |&gt; \n  arrange(agree)\n\n# A tibble: 115 × 8\n   bioguide last_name  state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 L000570  Luján      NM    D           186 0.124      0.243        -8.21\n 2 G000555  Gillibrand NY    D           121 0.124      0.242       -22.5 \n 3 M001176  Merkley    OR    D           129 0.155      0.323       -11.0 \n 4 W000817  Warren     MA    D           116 0.155      0.216       -27.2 \n 5 B001288  Booker     NJ    D           119 0.160      0.290       -14.1 \n 6 S000033  Sanders    VT    D           112 0.161      0.221       -26.4 \n 7 H001075  Harris     CA    D           116 0.164      0.209       -30.1 \n 8 M000133  Markey     MA    D           127 0.165      0.213       -27.2 \n 9 W000779  Wyden      OR    D           129 0.186      0.323       -11.0 \n10 B001277  Blumenthal CT    D           128 0.203      0.294       -13.6 \n# ℹ 105 more rows\n\n\nBy default, arrange() uses increasing order (like sort()). To use decreasing order, add a minus sign:\n\ntrump_scores |&gt; \n  filter(num_votes &gt;= 10) |&gt; \n  arrange(-agree)\n\n# A tibble: 115 × 8\n   bioguide last_name state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 M001198  Marshall  KS    R           183 0.973      0.933        20.6 \n 2 C000567  Cochran   MS    R            68 0.971      0.830        17.8 \n 3 H000338  Hatch     UT    R            84 0.964      0.825        18.1 \n 4 M001197  McSally   AZ    R           136 0.949      0.562         3.55\n 5 P000612  Perdue    GA    R           119 0.941      0.606         5.16\n 6 C001096  Cramer    ND    R           135 0.941      0.908        35.7 \n 7 R000307  Roberts   KS    R           127 0.937      0.818        20.6 \n 8 C001056  Cornyn    TX    R           129 0.922      0.659         9.00\n 9 H001061  Hoeven    ND    R           129 0.922      0.883        35.7 \n10 C001047  Capito    WV    R           127 0.921      0.896        42.2 \n# ℹ 105 more rows\n\n\nYou can also order rows by more than one variable. What this does is to order by the first variable, and resolve any ties by ordering by the second variable (and so forth if you have more than two ordering variables). For example, let’s first order our data frame by party, and then within party order by agreement with Trump:\n\ntrump_scores |&gt; \n  filter(num_votes &gt;= 10) |&gt; \n  arrange(party, agree)\n\n# A tibble: 115 × 8\n   bioguide last_name  state party num_votes agree agree_pred margin_trump\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 L000570  Luján      NM    D           186 0.124      0.243        -8.21\n 2 G000555  Gillibrand NY    D           121 0.124      0.242       -22.5 \n 3 M001176  Merkley    OR    D           129 0.155      0.323       -11.0 \n 4 W000817  Warren     MA    D           116 0.155      0.216       -27.2 \n 5 B001288  Booker     NJ    D           119 0.160      0.290       -14.1 \n 6 S000033  Sanders    VT    D           112 0.161      0.221       -26.4 \n 7 H001075  Harris     CA    D           116 0.164      0.209       -30.1 \n 8 M000133  Markey     MA    D           127 0.165      0.213       -27.2 \n 9 W000779  Wyden      OR    D           129 0.186      0.323       -11.0 \n10 B001277  Blumenthal CT    D           128 0.203      0.294       -13.6 \n# ℹ 105 more rows\n\n\n\n\n\n\n\n\nExercise\n\n\n\nArrange the data by diff_pred, the difference between agreement and predicted agreement with Trump. (You should have code on how to create this variable from the last exercise). Your code:\n\n\n\n\n2.2.6 Summarizing data\ndplyr makes summarizing data a breeze using the summarize() function:\n\ntrump_scores |&gt; \n  summarize(mean_agree = mean(agree),\n            mean_agree_pred = mean(agree_pred))\n\n# A tibble: 1 × 2\n  mean_agree mean_agree_pred\n       &lt;dbl&gt;           &lt;dbl&gt;\n1      0.592           0.572\n\n\nTo make summaries, we can use any function that takes a vector and returns one value. Another example:\n\ntrump_scores |&gt; \n  filter(num_votes &gt;= 5) |&gt; # to filter out senators with few data points\n  summarize(max_agree = max(agree),\n            min_agree = min(agree))\n\n# A tibble: 1 × 2\n  max_agree min_agree\n      &lt;dbl&gt;     &lt;dbl&gt;\n1         1     0.124\n\n\nGrouped summaries allow us to disaggregate summaries according to other variables (usually categorical):\n\ntrump_scores |&gt; \n  filter(num_votes &gt;= 5) |&gt; # to filter out senators with few data points\n  summarize(mean_agree = mean(agree),\n            max_agree = max(agree),\n            min_agree = min(agree),\n            .by = party) # to group by party\n\n# A tibble: 2 × 4\n  party mean_agree max_agree min_agree\n  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 R          0.876     1         0.651\n2 D          0.272     0.548     0.124\n\n\n\n\n\n\n\n\nExercise\n\n\n\nObtain the maximum absolute difference in agreement with Trump (the abs_diff_agree variable from before) for each party.\n\n\n\n\n2.2.7 Overview\n\n\n\nFunction\nPurpose\n\n\n\n\nselect()\nSelect columns\n\n\nrename()\nRename columns\n\n\nmutate()\nCreating columns\n\n\nfilter()\nFiltering rows\n\n\narrange()\nOrdering rows\n\n\nsummarize()\nSummarizing data\n\n\nsummarize(…, .by = )\nSummarizing data (by groups)"
  },
  {
    "objectID": "02_tidy_data1.html#visualizing-data-with-ggplot2",
    "href": "02_tidy_data1.html#visualizing-data-with-ggplot2",
    "title": "2  Tidy data analysis I",
    "section": "2.3 Visualizing data with ggplot2",
    "text": "2.3 Visualizing data with ggplot2\nggplot2 is the package in charge of data visualization in the tidyverse. It is extremely flexible and allows us to draw bar plots, box plots, histograms, scatter plots, and many other types of plots (see examples at R Charts).\nThroughout this module we will use a subset of our data frame, which only includes senators with more than a few data points:\n\ntrump_scores_ss &lt;- trump_scores |&gt; \n  filter(num_votes &gt;= 10)\n\nThe ggplot2 syntax provides a unifying interface (the “grammar of graphics” or “gg”) for drawing all different types of plots. One draws plots by adding different “layers,” and the core code always includes the following:\n\nA ggplot() command with a data = argument specifying a data frame and a mapping = aes() argument specifying “aesthetic mappings,” i.e., how we want to use the columns in the data frame in the plot (for example, in the x-axis, as color, etc.).\n“geoms,” such as geom_bar() or geom_point(), specifying what to draw on the plot.\n\nSo all ggplot2 commands will have at least three elements: data, aesthetic mappings, and geoms.\n\n2.3.1 Univariate plots: categorical\nLet’s see an example of a bar plot with a categorical variable:\n\nggplot(data = trump_scores_ss, mapping = aes(x = party)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nAs with any other function, we can drop the argument names if we specify the argument values in order. This is common in ggplot2 code:\n\nggplot(trump_scores_ss, aes(x = party)) +\n  geom_bar()\n\n\n\n\n\n\nNotice how geom_bar() automatically computes the number of observations in each category for us. Sometimes we want to use numbers in our data frame as part of a bar plot. Here we can use the geom_col() geom specifying both x and y aesthetic mappings, in which is sometimes called a “column plot:”\n\nggplot(trump_scores_ss |&gt; filter(state == \"ME\"),\n       aes(x = last_name, y = agree)) +\n  geom_col()\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nDraw a column plot with the agreement with Trump of Bernie Sanders and Ted Cruz. What happens if you use last_name as the y aesthetic mapping and agree in the x aesthetic mapping? Your code:\n\n\n\n\n2.3.2 Univariate plots: numerical\nWe can draw a histogram with geom_histogram():\n\nggplot(trump_scores_ss, aes(x = agree)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNotice the warning message above. It’s telling us that, by default, geom_histogram() will draw 30 bins. Sometimes we want to modify this behavior. The following code has some common options for geom_histogram() and their explanations:\n\nggplot(trump_scores_ss, aes(x = agree)) +\n  geom_histogram(binwidth = 0.05,   # draw bins every 0.05 jumps in x\n                 boundary = 0,      # don't shift bins to integers\n                 closed   = \"left\") # close bins on the left\n\n\n\n\nSometimes we want to manually alter a scale. This is accomplished with the scale_*() family of ggplot2 functions. Here we use the scale_x_continuous() function to make the x-axis go from 0 to 1:\n\nggplot(trump_scores_ss, aes(x = agree)) +\n  geom_histogram(binwidth = 0.05, boundary = 0, closed   = \"left\") +   \n  scale_x_continuous(limits = c(0, 1))\n\n\n\n\nAdding the fill aesthetic mapping to a histogram will divide it according to a categorical variable. This is actually a bivariate plot!\n\nggplot(trump_scores_ss, aes(x = agree, fill = party)) +\n  geom_histogram(binwidth = 0.05, boundary = 0, closed   = \"left\") +   \n  scale_x_continuous(limits = c(0, 1)) +\n  # change default colors:\n  scale_fill_manual(values = c(\"D\" = \"blue\", \"R\" = \"red\"))\n\n\n\n\n\n\n2.3.3 Bivariate plots\nAnother common bivariate plot for categorical and numerical variables is the grouped box plot:\n\nggplot(trump_scores_ss, aes(x = agree, y = party)) +\n  geom_boxplot() +\n  scale_x_continuous(limits = c(0, 1)) # same change as before\n\n\n\n\nFor bivariate plots of numerical variables, scatter plots are made with geom_point():\n\nggplot(trump_scores_ss, aes(x = margin_trump, y = agree)) +\n  geom_point()\n\n\n\n\nWe can add the color aesthetic mapping to add a third variable:\n\nggplot(trump_scores_ss, aes(x = margin_trump, y = agree, color = party)) +\n  geom_point() +\n  scale_color_manual(values = c(\"D\" = \"blue\", \"R\" = \"red\"))\n\n\n\n\nLet’s finish our plot with the labs() function, which allows us to add labels to our aesthetic mappings, as well as titles and notes:\n\nggplot(trump_scores, aes(x = margin_trump, y = agree, color = party)) +\n  geom_point() +\n  scale_color_manual(values = c(\"D\" = \"blue\", \"R\" = \"red\")) +\n  labs(x = \"Trump margin in the senator's state (p.p.)\",\n       y = \"Votes in agreement with Trump (prop.)\",\n       color = \"Party\",\n       title = \"Relationship between Trump margins and senators' votes\",\n       caption = \"Data source: FiveThirtyEight (2021)\")\n\n\n\n\nWe will review a few more customization options, including text labels and facets, in a subsequent module.\n\n\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "03_matrices.html#introduction",
    "href": "03_matrices.html#introduction",
    "title": "3  Matrices",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\n\n3.1.1 Scalars\nOne number (for example, 12) is referred to as a scalar.\n\\[\na = 12\n\\]\n\n\n3.1.2 Vectors\nWe can put several scalars together to make a vector. Here is an example:\n\\[\n\\overrightarrow b =\n\\begin{bmatrix}\n  12 \\\\\n  14 \\\\\n  15\n\\end{bmatrix}\n\\]\nSince this is a column of numbers, we cleverly refer to it as a column vector.\nHere is another example of a vector, this time represented as a row vector:\n\\[\n\\overrightarrow c = \\begin{bmatrix}\n  12 & 14 & 15\n\\end{bmatrix}\n\\]\nColumn vectors are possibly more common and useful, but we sometimes write things down using row vectors to\nVectors are fairly easy to construct in R. As we saw before, we can use the c() function to combine elements:\n\nc(5, 25, -2, 1)\n\n[1]  5 25 -2  1\n\n\n\n\n\n\n\n\nWarning\n\n\n\nRemember that the code above does not create any objects. To do so, you’d need to use the assignment operator (&lt;-):\n\nvector_example &lt;- c(5, 25, -2, 1)\nvector_example\n\n[1]  5 25 -2  1\n\n\n\n\nOr we can also create vectors from sequences with the : operator or the seq() function:\n\n10:20\n\n [1] 10 11 12 13 14 15 16 17 18 19 20\n\n\n\nseq(from = 3, to = 27, by = 3)\n\n[1]  3  6  9 12 15 18 21 24 27"
  },
  {
    "objectID": "03_matrices.html#operators",
    "href": "03_matrices.html#operators",
    "title": "3  Matrices",
    "section": "3.2 Operators",
    "text": "3.2 Operators\n\n3.2.1 Summation\nThe summation operator \\(\\sum\\) (i.e., the uppercase Sigma letter) lets us perform an operation on a sequence of numbers, which is often but not always a vector.\n\\[\\overrightarrow d = \\begin{bmatrix}\n12 & 7 & -2 & 3 & -1\n\\end{bmatrix}\\]\nWe can then calculate the sum of the first three elements of the vector, which is expressed as follows: \\[\\sum_{i=1}^3 d_i\\]\nThen we do the following math: \\[12+7+(-2)=17\\]\nIt is also common to use \\(n\\) in the superscript to indicate that we want to sum all elements:\n\\[\n\\sum_{i=1}^n d_i = 12 + 7 + (-2) + 3 + (-1) = 19\n\\] We can perform these operations using the sum() function in R:\n\nvector_d &lt;- c(12, 7, -2, 3, -1)\n\n\nsum(vector_d[1:3])\n\n[1] 17\n\n\n\nsum(vector_d)\n\n[1] 19\n\n\n\n\n3.2.2 Product\nThe product operator \\(\\prod\\) (i.e., the uppercase Pi letter) can also perform operations over a sequence of elements in a vector. Recall our previous vector:\n\\[\\overrightarrow d = \\begin{bmatrix}\n12 & 7 & -2 & 3 & 1\n\\end{bmatrix}\\]\nWe might want to calculate the product of all its elements, which is expressed as follows: \\[\\prod_{i=1}^n d_i = 12 \\cdot 7 \\cdot (-2) \\cdot 3 \\cdot (-1) = 504\\]\nIn R, we can compute products using the prod() function:\n\nprod(vector_d)\n\n[1] 504\n\n\n\n\n\n\n\n\nExercise\n\n\n\nGet the product of the first three elements of vector \\(d\\). Write the notation by hand and use R to obtain the number."
  },
  {
    "objectID": "03_matrices.html#matrices",
    "href": "03_matrices.html#matrices",
    "title": "3  Matrices",
    "section": "3.3 Matrices",
    "text": "3.3 Matrices\n\n3.3.1 Basics\nWe can append vectors together to form a matrix:\n\\[A = \\begin{bmatrix}\n12 & 14 & 15 \\\\\n115 & 22 & 127 \\\\\n193 & 29 & 219\n\\end{bmatrix}\\]\nThe number of rows and columns of a matrix constitute the dimensions of the matrix. The first number is the number of rows (“r”) and the second number is the number of columns (“c”) in the matrix.\n\n\n\n\n\n\nImportant\n\n\n\nFind a way to remember “r x c” permanently. The order of the dimensions never changes.\n\n\nMatrix \\(A\\) above, for example, is a \\(3x3\\) matrix. Sometimes we’d refer to it as \\(A_{3x3}\\).\n\n\n\n\n\n\nTip\n\n\n\nIt is common to use capital letters (sometimes bold-faced) to represent matrices. In contrast, vectors are usually represented with either bold lowercase letters or lowercase letters with an arrow on top (e.g., \\(\\overrightarrow v\\)).\n\n\n\nConstructing matrices in R\nThere are different ways to create matrices in R. One of the simplest is via rbind() or cbind(), which paste vectors together (either by rows or by columns):\n\n# Create some vectors\nvector1 &lt;- 1:4\nvector2 &lt;- 5:8\nvector3 &lt;- 9:12\nvector4 &lt;- 13:16\n\n\n# Using rbind(), each vector will be a row \nrbind_mat &lt;- rbind(vector1, vector2, vector3, vector4)\nrbind_mat\n\n        [,1] [,2] [,3] [,4]\nvector1    1    2    3    4\nvector2    5    6    7    8\nvector3    9   10   11   12\nvector4   13   14   15   16\n\n\n\n# Using cbind(), each vector will be a column\ncbind_mat &lt;- cbind(vector1, vector2, vector3, vector4)\ncbind_mat\n\n     vector1 vector2 vector3 vector4\n[1,]       1       5       9      13\n[2,]       2       6      10      14\n[3,]       3       7      11      15\n[4,]       4       8      12      16\n\n\nAn alternative is to use to properly named matrix() function. The basic syntax is matrix(data, nrow, ncol, byrow):\n\ndata is the input vector which becomes the data elements of the matrix.\nnrow is the number of rows to be created.\nncol is the number of columns to be created.\nbyrow is a logical clue. If TRUE then the input vector elements are arranged by row. By default (FALSE), elements are arranged by column.\n\nLet’s see some examples:\n\n# Elements are arranged sequentially by row.\nM &lt;- matrix(c(1:12), nrow = 4, byrow = T)\nM\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n[4,]   10   11   12\n\n\n\n# Elements are arranged sequentially by column (byrow = F by default).\nN &lt;- matrix(c(1:12), nrow = 4)\nN\n\n     [,1] [,2] [,3]\n[1,]    1    5    9\n[2,]    2    6   10\n[3,]    3    7   11\n[4,]    4    8   12\n\n\n\n\n\n3.3.2 Structure\nHow do we refer to specific elements of the matrix? For example, matrix \\(A\\) is an \\(m\\times n\\) matrix where \\(m=n=3\\). This is sometimes called a square matrix.\nMore generally, matrix \\(B\\) is an \\(m\\times n\\) matrix where the elements look like this: \\[B=\n\\begin{bmatrix}\nb_{11} & b_{12} & b_{13} & \\ldots & b_{1n} \\\\\nb_{21} & b_{22} & b_{23} & \\ldots & b_{2n} \\\\\n\\vdots & \\vdots & \\vdots & \\ldots & \\vdots \\\\\nb_{m1} & b_{m2} & b_{m3} & \\ldots & b_{mn}\n\\end{bmatrix}\\]\nThus \\(b_{23}\\) refers to the second unit down and third across. More generally, we refer to row indices as \\(i\\) and to column indices as \\(j\\).\nIn R, we can access a matrix’s elements using square brackets:\n\n# In matrix N, access the element at 1st row and 3rd column.\nN[1,3]\n\n[1] 9\n\n\n\n# In matrix N, access the element at 4th row and 2nd column.\nN[4,2]\n\n[1] 8\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhen trying to identify a specific element, the first subscript is the element’s row and the second subscript is the element’s column (always in that order)."
  },
  {
    "objectID": "03_matrices.html#matrix-operations",
    "href": "03_matrices.html#matrix-operations",
    "title": "3  Matrices",
    "section": "3.4 Matrix operations",
    "text": "3.4 Matrix operations\n\n3.4.1 Addition and subtraction\n\nAddition and subtraction are straightforward operations.\nMatrices must have exactly the same dimensions for both of these operations.\nWe add or subtract each element with the corresponding element from the other matrix.\nThis is expressed as follows:\n\n\\[A \\pm B=C\\]\n\\[c_{ij}=a_{ij} \\pm b_{ij} \\text{ }\\forall i,j\\]\n\\[\\begin{bmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\n\\pm\n\\begin{bmatrix}\nb_{11} & b_{12} & b_{13}\\\\\nb_{21} & b_{22} & b_{23}\\\\\nb_{31} & b_{32} & b_{33}\n\\end{bmatrix}\\] \\[=\\] \\[\\begin{bmatrix}\na_{11}\\pm b_{11} & a_{12}\\pm b_{12} & a_{13}\\pm b_{13}\\\\\na_{21}\\pm b_{21} & a_{22}\\pm b_{22} & a_{23}\\pm b_{23}\\\\\na_{31}\\pm b_{31} & a_{32}\\pm b_{32} & a_{33}\\pm b_{33}\n\\end{bmatrix}\\]\n\nAddition and subtraction in R\nWe start by creating two 2x3 matrices:\n\n# Create two 2x3 matrices.\nmatrix1 &lt;- matrix(c(3, 9, -1, 4, 2, 6), nrow = 2)\nmatrix1\n\n     [,1] [,2] [,3]\n[1,]    3   -1    2\n[2,]    9    4    6\n\n\n\nmatrix2 &lt;- matrix(c(5, 2, 0, 9, 3, 4), nrow = 2)\nmatrix2\n\n     [,1] [,2] [,3]\n[1,]    5    0    3\n[2,]    2    9    4\n\n\nWe can simply use the + and - operators for addition and substraction:\n\nmatrix1 + matrix2\n\n     [,1] [,2] [,3]\n[1,]    8   -1    5\n[2,]   11   13   10\n\n\n\nmatrix1 - matrix2\n\n     [,1] [,2] [,3]\n[1,]   -2   -1   -1\n[2,]    7   -5    2\n\n\n\n\n\n\n\n\nExercise\n\n\n\n(Use code for one of these and do the other one by hand!)\n1) Calculate \\(A + B\\)\n\\[A= \\begin{bmatrix}\n1 & 0 \\\\\n-2 & -1\n\\end{bmatrix}\\]\n\\[B = \\begin{bmatrix}\n5 & 1 \\\\\n2 & -1\n\\end{bmatrix}\\]\n\n2) Calculate \\(A - B\\)\n\\[A= \\begin{bmatrix}\n6 & -2 & 8 & 12 \\\\\n4 & 42 & 8 & -6\n\\end{bmatrix}\\]\n\\[B = \\begin{bmatrix}\n18 & 42 & 3 & 7 \\\\\n0 & -42 & 15 & 4\n\\end{bmatrix}\\]\n\n\n\n\n\n3.4.2 Scalar multiplication\nScalar multiplication is very intuitive. As we know, a scalar is a single number. We multiply each value in the matrix by the scalar to perform this operation.\nFormally, this is expressed as follows: \\[A =\n\\begin{bmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\\] \\[cA =\n\\begin{bmatrix}\nca_{11} & ca_{12} & ca_{13}\\\\\nca_{21} & ca_{22} & ca_{23}\\\\\nca_{31} & ca_{32} & ca_{33}\n\\end{bmatrix}\\]\nIn R, all we need to do is take an established matrix and multiply it by some scalar:\n\n# matrix1 from our previous example\nmatrix1\n\n     [,1] [,2] [,3]\n[1,]    3   -1    2\n[2,]    9    4    6\n\n\n\nmatrix1 * 3\n\n     [,1] [,2] [,3]\n[1,]    9   -3    6\n[2,]   27   12   18\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCalculate \\(2\\times A\\) and \\(-3 \\times B\\). Again, do one by hand and the other one using R.\n\\[A= \\begin{bmatrix}\n    1 & 4 & 8 \\\\\n    0 & -1 & 3\n    \\end{bmatrix}\\] \\[ B = \\begin{bmatrix}\n    -15 & 1 & 5 \\\\\n    2 & -42 & 0 \\\\\n    7 & 1 & 6\n    \\end{bmatrix}\\]\n\n\n\n\n3.4.3 Matrix multiplication\n\nMultiplying matrices is slightly trickier than multiplying scalars.\nTwo matrices must be conformable for them to be multiplied together. This means that the number of columns in the first matrix equals the number of rows in the second.\nWhen multiplying \\(A \\times B\\), if \\(A\\) is \\(m \\times n\\), \\(B\\) must have \\(n\\) rows.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe conformability requirement never changes. Before multiplying anything, check to make sure the matrices are indeed conformable.\n\n\n\nThe resulting matrix will have the same number of rows as the first matrix and the number of columns in the second. For example, if \\(A\\) is \\(i \\times k\\) and \\(B\\) is \\(k \\times j\\), then \\(A \\times B\\) will be \\(i \\times j\\).\n\n\nWhich of the following can we multiply? What will be the dimensions of the resulting matrix? \\[\\begin{aligned}\nB=\n\\begin{bmatrix}\n2 \\\\\n3\\\\\n4\\\\\n1\n\\end{bmatrix}\nM =\n\\begin{bmatrix}\n1 & 0 & 2\\\\\n1 & 2 & 4\\\\\n2 & 3 & 2\n\\end{bmatrix}\nL =\n\\begin{bmatrix}\n6 & 5 & -1\\\\\n1 & 4 & 3\n\\end{bmatrix}\n\\end{aligned}\\]\nWhy can’t we multiply in the opposite order?\n\n\n\n\n\n\nWarning\n\n\n\nWhen multiplying matrices, order matters. Even if multiplication is possible in both directions, in general \\(AB \\neq BA\\).\n\n\n\nMultiplication steps\n\nMultiply each row by each column, summing up each pair of multiplied terms.\n\n\n\n\n\n\n\nTip\n\n\n\nThis is sometimes to referred to as the “dot product,” where we multiply matching members, then sum up.\n\n\n\nThe element in position \\(ij\\) is the sum of the products of elements in the \\(i\\)th row of the first matrix (\\(A\\)) and the corresponding elements in the \\(j\\)th column of the second matrix (\\(B\\)). \\[c_{ij}=\\sum_{k=1}^n a_{ik}b_{kj}\\]\n\n\n\nExample\nSuppose a company manufactures two kinds of furniture: chairs and sofas.\n\nA chair costs $100 for wood, $270 for cloth, and $130 for feathers.\nEach sofa costs $150 for wood, $420 for cloth, and $195 for feathers.\n\n\n\n\n\nChair\nSofa\n\n\n\n\nWood\n100\n150\n\n\nCloth\n270\n420\n\n\nFeathers\n130\n195\n\n\n\nThe same information about unit cost (\\(C\\)) can be presented as a matrix.\n\\[C = \\begin{bmatrix}\n100 & 150\\\\\n270 & 420\\\\\n130 & 195\n\\end{bmatrix}\\]\nNote that each of the three rows of this 3 x 2 matrix represents a material (wood, cloth, or feathers), and each of the two columns represents a product (chair or coach). The elements are the unit cost (in USD).\n\nNow, suppose that the company will produce 45 chairs and 30 sofas this month. This production quantity can be represented in the following table, and also as a 2 x 1 matrix (\\(Q\\)):\n\n\n\nProduct\nQuantity\n\n\n\n\nChair\n45\n\n\nSofa\n30\n\n\n\n\\[Q = \\begin{bmatrix}\n45 \\\\\n30\n\\end{bmatrix}\\]\nWhat will be the company’s total cost? The “total expenditure” is equal to the “unit cost” times the “production quantity” (the number of units).\nThe total expenditure (\\(E\\)) for each material this month is calculated by multiplying these two matrices.\n\\[\\begin{aligned} E = CQ =\n\\begin{bmatrix}\n100 & 150\\\\\n270 & 420\\\\\n130 & 195\n\\end{bmatrix}\n\\begin{bmatrix}\n45 \\\\\n30\n\\end{bmatrix} =\n\\begin{bmatrix}\n(100)(45) + (150)(30) \\\\\n(270)(45) + (420)(30) \\\\\n(130)(45) + (195)(30)\n\\end{bmatrix} =\n\\begin{bmatrix}\n9,000 \\\\\n24,750 \\\\\n11,700\n\\end{bmatrix}\n\\end{aligned}\\]\nMultiplying the 3x2 Cost matrix (\\(C\\)) times the 2x1 Quantity matrix (\\(Q\\)) yields the 3x1 Expenditure matrix (\\(E\\)).\nAs a result of this matrix multiplication, we determine that this month the company will incur expenditures of:\n\n$9,000 for wood\n$24,750 for cloth\n$11,700 for feathers.\n\n\n\nMatrix multiplication in R\nBefore attempting matrix multiplication, we must make sure the matrices are conformable (as we do for our manual calculations).\nThen we can multiply our matrices together using the %*% operator.\n\nC &lt;- matrix(c(100, 270, 130, 150, 420, 195), nrow = 3)\nC\n\n     [,1] [,2]\n[1,]  100  150\n[2,]  270  420\n[3,]  130  195\n\n\n\nQ &lt;- matrix(c(45, 30), nrow = 2)\nQ\n\n     [,1]\n[1,]   45\n[2,]   30\n\n\n\nC %*% Q\n\n      [,1]\n[1,]  9000\n[2,] 24750\n[3,] 11700\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you have a missing value or NA in one of the matrices you are trying to multiply (something we will discuss in further detail in the next module), you will have NAs in your resulting matrix.\n\n\n\n\n\n\n3.4.4 Properties of operations\n\nAddition and subtraction:\n\nAssociative: \\((A \\pm B) \\pm C = A \\pm (B \\pm C)\\)\nCommunicative: \\(A \\pm B = B \\pm A\\)\n\nMultiplication:\n\n\\(AB \\neq BA\\)\n\\(A(BC) = (AB)C\\)\n\\(A(B+C) = AB + AC\\)\n\\((A+B)C = AC + BC\\)"
  },
  {
    "objectID": "03_matrices.html#special-matrices",
    "href": "03_matrices.html#special-matrices",
    "title": "3  Matrices",
    "section": "3.5 Special matrices",
    "text": "3.5 Special matrices\nSquare matrix\n\nIn a square matrix, the number of rows equals the number of columns (\\(m=n\\)):\nThe diagonal of a matrix is a set of numbers consisting of the elements on the line from the upper-left-hand to the lower-right-hand corner of the matrix. Diagonals are particularly useful in square matrices.\nThe trace of a matrix, denoted as \\(tr(A)\\), is the sum of the diagonal elements of the matrix.\n\nDiagonal matrix:\n\nIn a diagonal matrix, all of the elements of the matrix that are not on the diagonal are equal to zero.\n\nScalar matrix:\n\nA scalar matrix is a diagonal matrix where the diagonal elements are all equal to each other. In other words, we’re really only concerned with one scalar (or element) held in the diagonal.\n\nIdentity matrix:\n\nThe identity matrix is a scalar matrix with all of the diagonal elements equal to one.\nRemember that, as with all diagonal matrices, the off-diagonal elements are equal to zero.\nThe capital letter \\(I\\) is reserved for the identity matrix. For convenience, a 3x3 identity matrix can be denoted as \\(I_3\\)."
  },
  {
    "objectID": "03_matrices.html#transpose",
    "href": "03_matrices.html#transpose",
    "title": "3  Matrices",
    "section": "3.6 Transpose",
    "text": "3.6 Transpose\nThe transpose is the original matrix with the rows and the columns interchanged.\nThe notation is either \\(J'\\) (“J prime”) or \\(J^T\\) (“J transpose”).\n\\[J =\n\\begin{bmatrix}\n4 & 5\\\\\n3 & 0\\\\\n7 & -2\n\\end{bmatrix}\\]\n\\[J' = J^T =\n\\begin{bmatrix}\n4 & 3 & 7 \\\\\n5 & 0 & -2\n\\end{bmatrix}\\]\nIn R, we use t() to get the transpose.\n\nJ &lt;- matrix(c(4, 3, 7, 5, 0, -2), ncol = 2)\nJ\n\n     [,1] [,2]\n[1,]    4    5\n[2,]    3    0\n[3,]    7   -2\n\n\n\nt(J)\n\n     [,1] [,2] [,3]\n[1,]    4    3    7\n[2,]    5    0   -2"
  },
  {
    "objectID": "03_matrices.html#inverse",
    "href": "03_matrices.html#inverse",
    "title": "3  Matrices",
    "section": "3.7 Inverse",
    "text": "3.7 Inverse\n\nJust like a number has a reciprocal, a matrix has an inverse.\nWhen we multiply a matrix by its inverse we get the identity matrix (which is like “1” for matrices).\n\n\\[A × A^{-1} = I\\]\n\nThe inverse of A is \\(A^{-1}\\) only when:\n\n\\[AA^{-1} = A^{-1}A = I\\]\n\nSometimes there is no inverse at all.\n\n\n\n\n\n\n\nNote\n\n\n\nFor now, don’t worry about calculating the inverse of a matrix manually. This is the type of task we use R for.\n\n\n\nIn R, we use the solve() function to calculate the inverse of a matrix:\n\n\nA &lt;- matrix(c(3, 2, 5, 2, 3, 2, 5, 2, 4), ncol = 3)\nA\n\n     [,1] [,2] [,3]\n[1,]    3    2    5\n[2,]    2    3    2\n[3,]    5    2    4\n\n\n\nsolve(A)\n\n            [,1]        [,2]       [,3]\n[1,] -0.29629630 -0.07407407  0.4074074\n[2,] -0.07407407  0.48148148 -0.1481481\n[3,]  0.40740741 -0.14814815 -0.1851852"
  },
  {
    "objectID": "03_matrices.html#linear-systems-and-matrices",
    "href": "03_matrices.html#linear-systems-and-matrices",
    "title": "3  Matrices",
    "section": "3.8 Linear systems and matrices",
    "text": "3.8 Linear systems and matrices\n\nA system of equations can be represented by an augmented matrix.\nSystem of equations: \\[{\\color{red}{3}}x + {\\color{green}{6}}y = {\\color{blue}{12}}\\] \\[{\\color{red}{5}}x + {\\color{green}{10}}y = {\\color{blue}{25}}\\]\nIn an augmented matrix, each row represents one equation in the system and each column represents a variable or the constant terms. \\[\\begin{bmatrix}\n{\\color{red}{3}} & {\\color{green}{6}} & {\\color{blue}{12}}\\\\\n{\\color{red}{5}} & {\\color{green}{10}} & {\\color{blue}{25}}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "03_matrices.html#ols-and-matrices",
    "href": "03_matrices.html#ols-and-matrices",
    "title": "3  Matrices",
    "section": "3.9 OLS and matrices",
    "text": "3.9 OLS and matrices\n\nWe can use the logic above to calculate estimates for our ordinary least squares (OLS) models.\nOLS is a linear regression technique used to find the best-fitting line for a set of data points (observations) by minimizing the residuals (the differences between the observed and predicted values).\nWe minimize the sum of the squared errors.\n\n\n3.9.1 Dependent variable\n\nSuppose, for example, we have a sample consisting of \\(n\\) observations.\nThe dependent variable is denoted as an \\(n \\times1\\) column vector.\n\n\\[Y = \\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\ny_3 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix}\\]\n\n\n3.9.2 Independent variables\n\nSuppose there are \\(k\\) independent variables and a constant term, meaning \\(k+1\\) columns and \\(n\\) rows.\nWe can represent these variables as an \\(n \\times (k+1)\\) matrix, expressed as follows:\n\n\\[X= \\begin{bmatrix}\n1 & x_{11} & \\dots & x_{1k} \\\\\n1 & x_{21} & \\dots & x_{2k} \\\\\n\\vdots & \\vdots & \\dots & \\vdots \\\\\n1 & x_{n1} & \\dots & x_{nk}\n\\end{bmatrix}\\]\n\n\\(x_{ij}\\) is the \\(i\\)-th observation of the \\(j\\)-th independent variable.\n\n\n\n3.9.3 Linear regression model\n\nLet’s say we have 173 observations (n = 173) and 2 IVs (k = 3).\nThis can be expressed as the following linear equation: \\[y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\epsilon\\]\nIn matrix form, we have: \\[\\begin{aligned} \\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} = \\begin{bmatrix}\n1 & x_{11} & x_{21} \\\\\n1 & x_{21} & x_{22} \\\\\n\\vdots & \\vdots & \\vdots \\\\\n1 & x_{1173} & x_{2173}\n\\end{bmatrix} \\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\beta_2\n\\end{bmatrix} + \\begin{bmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\vdots \\\\\n\\epsilon_{173}\n\\end{bmatrix}\\end{aligned} \\]\nAll 173 equations can be represented by: \\[y=X\\beta+\\epsilon\\]\n\n\n\n3.9.4 Estimates\n\nWithout getting too much into the mechanics, we can calculate our coefficient estimates with matrix algebra using the following equation:\n\n\\[\\hat{\\beta} = (X'X)^{-1}X'Y\\]\n\nRead aloud, we say “X prime X inverse, X prime Y”.\nThe little hat on our beta (\\(\\hat{\\beta}\\)) signifies that these are estimates, that is our OLS estimators.\nRemember, the OLS method is to choose \\(\\hat{\\beta}\\) such that the sum of squared residuals (“SSR”) is minimized.\n\n\n3.9.4.1 Example in R\n\nWe will load the mtcars data set (our favorite) for this example, which contains data about many different car models.\n\n\ncars_df &lt;- mtcars\n\n\nNow, we want to estimate the association between hp (horsepower) and wt (weight), our independent variables, and mpg (miles per gallon), our dependent variable.\nFirst, we transform our dependent variable into a matrix, using the as.matrix function and specifying the column of the mtcars data set to create a column vector of our observed values for the DV.\n\n\nY &lt;- as.matrix(cars_df[,1])\nY\n\n      [,1]\n [1,] 21.0\n [2,] 21.0\n [3,] 22.8\n [4,] 21.4\n [5,] 18.7\n [6,] 18.1\n [7,] 14.3\n [8,] 24.4\n [9,] 22.8\n[10,] 19.2\n[11,] 17.8\n[12,] 16.4\n[13,] 17.3\n[14,] 15.2\n[15,] 10.4\n[16,] 10.4\n[17,] 14.7\n[18,] 32.4\n[19,] 30.4\n[20,] 33.9\n[21,] 21.5\n[22,] 15.5\n[23,] 15.2\n[24,] 13.3\n[25,] 19.2\n[26,] 27.3\n[27,] 26.0\n[28,] 30.4\n[29,] 15.8\n[30,] 19.7\n[31,] 15.0\n[32,] 21.4\n\n\n\nNext, we do the same thing for our independent variables of interest, and our constant.\n\n\n# create two separate matrices for IVs\nX1 &lt;- as.matrix(cars_df[,4])\nX2 &lt;- as.matrix(cars_df[,6])\n\n# create constant column\n\n# bind them altogether into one matrix\nconstant &lt;-  rep(1,nrow(X1))\nX &lt;- cbind(constant,X1,X2)\nX\n\n      constant          \n [1,]        1 110 2.620\n [2,]        1 110 2.875\n [3,]        1  93 2.320\n [4,]        1 110 3.215\n [5,]        1 175 3.440\n [6,]        1 105 3.460\n [7,]        1 245 3.570\n [8,]        1  62 3.190\n [9,]        1  95 3.150\n[10,]        1 123 3.440\n[11,]        1 123 3.440\n[12,]        1 180 4.070\n[13,]        1 180 3.730\n[14,]        1 180 3.780\n[15,]        1 205 5.250\n[16,]        1 215 5.424\n[17,]        1 230 5.345\n[18,]        1  66 2.200\n[19,]        1  52 1.615\n[20,]        1  65 1.835\n[21,]        1  97 2.465\n[22,]        1 150 3.520\n[23,]        1 150 3.435\n[24,]        1 245 3.840\n[25,]        1 175 3.845\n[26,]        1  66 1.935\n[27,]        1  91 2.140\n[28,]        1 113 1.513\n[29,]        1 264 3.170\n[30,]        1 175 2.770\n[31,]        1 335 3.570\n[32,]        1 109 2.780\n\n\n\nNext, we calculate \\(X'X\\), \\(X'Y\\), and \\((X'X)^{-1}\\).\n\n\nDon’t forget to use %*% for matrix multiplication!\n\n\n# X prime X\nXpX &lt;- t(X)%*%X\n\n# X prime X inverse\nXpXinv &lt;- solve(XpX)\n\n# X prime Y\nXpY &lt;- t(X)%*%Y\n\n# beta coefficient estimates\nbhat &lt;- XpXinv %*% XpY\nbhat\n\n                [,1]\nconstant 37.22727012\n         -0.03177295\n         -3.87783074\n\n\n\n\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "04_tidy_data2.html",
    "href": "04_tidy_data2.html",
    "title": "4  Tidy data analysis II",
    "section": "",
    "text": "FiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "05_functions.html#basics",
    "href": "05_functions.html#basics",
    "title": "5  Functions and loops",
    "section": "5.1 Basics",
    "text": "5.1 Basics\n\n5.1.1 What is a function?\n\nAnything that takes input(s) and gives one defined output.\nThey assign a unique value in its range (\\(y\\) values) for each value in its domain ( \\(x\\) values).\nIn math, this usually looks something like \\(f(x) = 3x + 4\\).\n\n\\(x\\) is the argument that the function takes.\nFor any \\(x\\), multiply \\(x\\) by 3 and then add 4\nAlternative but equivalent notation: \\(y = 3x + 4\\)\n\\(y\\) is “a function of” \\(x\\), so \\(y\\) = \\(f(x)\\)\n\nWe describe functions with both equations and graphs.\n\n\n\n5.1.2 Function machine\n\n\n\nFigure 5.1: Function machine\n\n\n\n\n5.1.3 Visualization\nWhen graphed, we can’t draw vertical line through a function. Why not?"
  },
  {
    "objectID": "05_functions.html#types-of-functions",
    "href": "05_functions.html#types-of-functions",
    "title": "5  Functions and loops",
    "section": "5.2 Types of functions",
    "text": "5.2 Types of functions\n\n5.2.1 Linear functions\n\nWe can easily make a function that describes a line.\n\n\\[y=mx+b\\] - \\(m\\) is the slope (for every one unit increase in \\(x\\), \\(y\\) increases \\(m\\) units).\n\n\\(b\\) is the y-intercept: the value of \\(y\\) when \\(x=0\\).\nMore generally, \\(y=a+bx\\) - \\(a\\) is the intercept and \\(b\\) is the slope.\n\n\n\n5.2.2 Quadratic\n\nThese lines have one curve. \\[y=ax^2 + bx + c\\]\n\\(a\\), \\(b\\), and \\(c\\) don’t have well-defined meanings here.\nIf \\(a\\) is negative, the function opens downward; if \\(a\\) is positive,it opens upward.\nNote that \\(x^2\\) always returns positive values.\n\n\n\n\n\n\n\n\n\n5.2.3 Cubic\n\nThese lines (generally) have two curves (inflection points).\n\\(y=ax^3 + bx^2 + cx +d\\)\n\\(a\\), \\(b\\), \\(c\\), and \\(d\\) don’t have well-defined meanings here.\n\n\n\n\n\n\n\n\n\n5.2.4 Polynomial\n\\[y=ax^n + bx^{n-1} + ... + c\\] - These functions have (maximum) \\(n-1\\) changes in direction (turning points). - They also have (maximum) \\(n\\) x-intercepts. - They can be made arbitrarily precise.\n\n\n5.2.5 Exponential\n\\[y = ab^{x}\\] or \\[f(x)=ab^x\\]\n\nHere our independent variable, or input (\\(x\\)), is the exponent.\n\n\n\n5.2.6 Trigonometric functions\n\nThese functions include sine, cosine, and tangent.\nThey are interesting (to some), but not usually useful for social science."
  },
  {
    "objectID": "05_functions.html#logarithms-and-exponents",
    "href": "05_functions.html#logarithms-and-exponents",
    "title": "5  Functions and loops",
    "section": "5.3 Logarithms and exponents",
    "text": "5.3 Logarithms and exponents\n\n5.3.1 Logarithms\n\nLogarithms are basically the opposite (inverse) of exponents.\nThey ask how many times you must raise the base to get \\(x\\).\n\\(log_a(b)=x\\) is asking “a raised to what power x gives b?\n\\(\\log_3(81) = 4\\) because \\(3^4=81\\)\nLogarithms can be undefined.\nThe base cannot be 0, 1, or negative.\n\n\n\n5.3.2 Relationships\nIf, \\[ log_ax=b\\] then, \\[a^{log_{a}x}=a^b\\] and \\[x=a^b\\]\n\n\n5.3.3 Basic rules\n\\[\\dfrac{\\log_x n}{\\log_x m} = \\log_m n\\]\n\\[\\log_x(ab) = \\log_xa + \\log_xb \\]\n\\[\\log_x\\left(\\frac{a}{b}\\right) = \\log_xa - \\log_xb\\]\n\\[\\log_xa^b = b \\log_x a\\]\n\\[\\log_x 1 = 0\\]\n\\[log_{x}x=1\\]\n\\[m^{\\log_m(a)} = a\\]\n\n\n5.3.4 Natural logarithms\n\nWe most often use natural logarithms.\nThis means log\\(_e(x)\\), often written ln\\((x)\\).\n\\(e \\approx 2.7183\\).\nln(x) and its exponent opposite, \\(e^x\\), have nice properties when we hit calculus.\n\n\n\n5.3.5 Definition of e\n\nImagine you invest $1 in a bank and receive 100% interest for one year, and the bank pays you back once a year: \\[(1+1)^1= 2\\]\nWhen it pays you twice a year with compound interest:\n\n\\[(1+1/2)^2=2.25\\]\n\nIf it pays you three times a year:\n\n\\[(1+1/3)^3=2.37...\\]\n\nWhat will happen when the bank pays you once a month? Once a day?\n\n\n\\[(1+\\frac{1}{n})^{n}\\]\n\nHowever, there is limit to what you can get\n\n\\[\\lim_{n\\to\\infty} (1 + \\dfrac{1}{n})^n = 2.7183... = e\\]\n\nFor any interest rate \\(k\\) and number of times the bank pays you \\(t\\): \\[\\lim_{n\\to\\infty} (1 + \\dfrac{k}{n})^{nt} = e^{kt}\\]\n\\(e\\) is important for defining exponential growth. Since \\(ln(e^x) = x\\), the natural logarithm helps us turn exponential functions into linear ones.\n\n\nPractice\nSolve the problems below, simplifying as much as you can. \\[log_{10}(1000)\\] \\[log_2(\\dfrac{8}{32})\\] \\[10^{log_{10}(300)}\\] \\[ln(1)\\] \\[ln(e^2)\\] \\[ln(5e)\\]"
  },
  {
    "objectID": "05_functions.html#functions-of-functions",
    "href": "05_functions.html#functions-of-functions",
    "title": "5  Functions and loops",
    "section": "5.4 Functions of functions",
    "text": "5.4 Functions of functions\n\n5.4.1 Basics\n\nFunctions can take other functions as arguments.\nThis means that outside function takes output of inside function as its input.\nThis is typically written as \\(f(g(x))\\).\nSay we have the exterior function f(x)=\\(x^2\\) and the interior function g(x)=\\(x-3\\).\nThen if we want f(g(x)), we would subtract 3 from any input, and then square the result.\nWe write this \\((x-3)^2\\), NOT \\(x^2-3\\).\n\n\n\n5.4.2 PMF, PDF, and CDF\n\nPMF - probability mass function\n\nThis gives the probability that a discrete random variable is exactly equal to some value.\n\nPDF - probability density function\n\nThis gives the probability that a continuous random variable falls within a particular range of values.\n\nCDF - cumulative distribution function\n\nThis gives the probability that a random variable X takes a value less than or equal to \\(x\\).\n\n\n\n\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "06_calculus.html#derviatives",
    "href": "06_calculus.html#derviatives",
    "title": "6  Calculus",
    "section": "6.1 Derviatives",
    "text": "6.1 Derviatives\n\n“Derivative” is just a fancy term for slope.\nSlope is the rate of change \\(\\frac{\\delta y}{\\delta x}\\) or \\(\\frac{d y}{d x}\\).\nSpecifically, the derivative is the instantaneous rate of change.\nWe need slope for our statistics, which are all about fitting lines.\nWe also need slope for taking maxima and minima.\nThe equation for a line is \\(y = mx + b\\). What is its slope?\n\n\n6.1.1 Calculating derivatives\n\nSlope is rise over run, which is \\(\\dfrac{f(x+\\Delta x)-f(x)}{\\Delta x}\\)\nTo see why, consider the slope of a line connecting two points: \\[m = \\displaystyle\\frac{f(x_2) - f(x_1)}{x_2-x_1}\\]\nWe can define \\(x_2 = x_1 + \\Delta x\\) (or equivalently \\(\\Delta x = x_2 - x_1\\)) \\[m = \\dfrac{f(x_1+ \\Delta x) - f(x_1)}{\\Delta x}\\]\n\n\n\nAs we’ve seen, for a curve, we need to be infinitely close for our line’s defining points, yielding \\[\\lim_{\\Delta x\\to 0} \\frac{f(x+ \\Delta x)-f(x)}{\\Delta x}\\]\nThis gives us this instantaneous slope (rate of change) of a function at every point on its domain. The above equation is the definition of the derivative.\n\n\n\n6.1.2 Notation\n\n\\(\\frac{d}{dx} f(x)\\) is read “The derivative of \\(f\\) of \\(x\\) with respect to \\(x\\).”\n\nYou can also say “The instantaneous rate of change in \\(f\\) of \\(x\\) with respect to \\(x\\).”\n\nLagrange’s prime notation: \\(f'(x)\\) (read: “\\(f\\) prime \\(x\\)”) is the derivative of \\(f(x)\\).\nIf \\(y=f(x)\\), \\(\\frac{dy}{dx}\\) is “The derivative of \\(y\\) with respect to \\(x\\)”.\n\nThe variable with respect to which we’re differentiating is the one that appears in the denominator.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nDo not try to cancel out the \\(d\\)’s, no matter how tempting it is.\n\n\n\nExamples\n\nWhat is \\(\\dfrac{d(x^2)}{dx}\\)?\n\n\\(x^2\\)\n\\(2 x^{2-1}\\) -\\(2x\\)\n\nWhat is \\(\\frac{d(4x^3)}{dx}\\)?\n\n\\(4x^3\\)\n\\(4*3 x^{3-1}\\)\n\\(12x^2\\)\n\n\n\nPractice\n\nTake the derivative of each of the following: \\[x^3\\] \\[3x^2\\] \\[60x^{11}\\] \\[x\\] \\[\\frac{4}{x^2} \\] \\[9 \\sqrt{x}\\] \\[6 x^{5/2}\\] \\[11,596,232\\]\n\n\nPractice\n\nEvaluate the derivatives at \\(x=2\\) and \\(x=-1\\) \\[x^3\\] \\[3x^2\\] \\[60x^{11}\\] \\[x\\] \\[\\frac{4}{x^2} \\] \\[9 \\sqrt{x}\\] \\[6 x^{5/2}\\] \\[11,596,232\\]\n\n\nPractice\n\nTake the derivative of each of the following: \\[x^3\\] \\[3x^2\\] \\[60x^{11}\\] \\[x\\] \\[\\frac{4}{x^2} \\] \\[9 \\sqrt{x}\\] \\[6 x^{5/2}\\] \\[11,596,232\\]\n\n\n\nEvaluate the derivatives at \\(x=2\\) and \\(x=-1\\) \\[x^3\\] \\[3x^2\\] \\[60x^{11}\\] \\[x\\] \\[\\frac{4}{x^2} \\] \\[9 \\sqrt{x}\\] \\[6 x^{5/2}\\] \\[11,596,232\\]\n\n\n\n\n6.1.3 Special functions\n\nA few functions have particular rules:\n\n\\[\\frac{d (ln(x))}{dx}=\\frac{1}{x}\\]\n\\[\\dfrac{d (log_b(x))}{dx}=\\dfrac{1}{x*ln(b)}\\]\n\\[\\frac{d (e^x)}{dx}=e^x\\]\n\\[\\frac{d (a^x)}{dx}=a^x ln(a)\\]\n\\[\\frac{dy}{dx}c=0\\]\n\\[\\frac{d (x^x)}{dx}=x^x (1+ln(x))\\]\n\n\n6.1.4 Derivatives with addition and substraction\n\nThis is perhaps the rasiest rule to remember: \\[\\frac{d (f(x) \\pm g(x))}{dx}=f'(x) \\pm g'(x)\\]\n\n\nPractice\n\nTake the derivative of each of the following: \\[x^2 + x +5\\] \\[x^4 - 4x^3 + 5x^2 + 8x - 6\\] \\[3x^5 - 6x^2\\] \\[5x^2 + 8 \\sqrt{x} - \\frac{1}{x}\\] \\[ln(x) + 5e^x - 4x^3\\]"
  },
  {
    "objectID": "06_calculus.html#advanced-rules",
    "href": "06_calculus.html#advanced-rules",
    "title": "6  Calculus",
    "section": "6.2 Advanced rules",
    "text": "6.2 Advanced rules\n\n6.2.1 Product rule\n\nThis rule is more complicated: \\[\\frac{d (f(x) \\times g(x))}{dx}=f'(x)g(x) + g'(x)f(x)\\]\nExample: \\[2x \\times 3x\\] \\[ f(x)=2x\\] \\[g(x) = 3x\\] \\[f'(x) = 2\\] \\[g'(x) = 3\\] \\[f'(x)g(x) + g'(x)f(x) = 2 \\times 3x + 3 \\times 2x\\] \\[\\frac{d (2x \\times 3x)}{dx} = 6x + 6x = 12x\\]\n\n\nPractice\n\nTake the derivative of each of these: \\[x^3 * x\\] \\[e^x * x^2\\] \\[ln(x) * x^{-3}\\]\n\n\n\n\n\n\n\nReminder!\n\n\n\n\\[\\frac{d (f(x) * g(x))}{dx}=f'(x)g(x) + g'(x)f(x)\\]\n\n\n\n\n6.2.2 Quotient rule\n\\[\\frac{d \\frac{f(x)}{g(x)}}{dx}=\\frac{f'(x)g(x) - g'(x)f(x)}{[g(x)]^2}\\] - If you’re having trouble with this, just apply the product rule to the following: \\[\\frac{d[f(x)*g^{-1}(x)]}{dx}\\]\n\n\n\n\n\n\nReminder!\n\n\n\n\\[\\frac{d \\frac{f(x)}{g(x)}}{dx}=\\frac{f'(x)g(x) - g'(x)f(x)}{[g(x)]^2}\\]\n\n\n\n\n6.2.3 Chain rule\n\\[\\frac{d [f(g(x))]}{dx}=f'(g(x)) * g'(x)\\]\n\nLet’s take the derivative of a function of a function: \\[\\frac{d[ln(x^2)]}{dx}\\] \\[f(x)=ln(x)\\] \\[g(x)=x^2\\] \\[f'(x)=\\frac{1}{x}\\] \\[g'(x)=2x\\] \\[ \\frac{1}{x^2}*2x = \\frac{2}{x}\\]\n\n\nPractice\n\nTake the derivative of each of the following: \\[ (3x^4-8)^2 \\] \\[e^{x^2}\\]\n\n\n\n\n\n\n\nReminder!\n\n\n\n\\[\\frac{d (f(g(x))}{dx}=f'(g(x)) * g'(x)\\]\n\n\n\n\n6.2.4 Second derivative\n\nSame process as taking single derivative, except input for second derivative is output from first.\nSecond derivative tells us whether the slope of a function is increasing, decreasing, or staying the same at any point \\(x\\) on the function’s domain.\nExample: driving a car.\n\n\\(f(x)\\) = distance traveled at time \\(x\\)\n\\(f'(x)\\) = speed at time \\(x\\)\n\\(f''(x)\\) = acceleration at time \\(x\\)\n\nLet’s graph \\(f(x) = x^2\\), \\(f'(x)\\), and \\(f''(x)\\).\n\n\n\n\n\n\n\n\\[\\frac{d^2(x^4)}{dx^2}=f''(x^4)\\]\n\nFirst, we take the first derivative: \\[f'(x^4)=4x^3\\]\nThen we use that output to take the second derivative: \\[f''(x^4)=f'(4x^3)=12x^2\\]\n\nPractice\nTake the second derivative of the following functions: \\[x^5\\] \\[6x^2\\] \\[4 ln(x)\\] \\[3x\\] \\[4x^{3/2}\\]"
  },
  {
    "objectID": "06_calculus.html#differentiable-and-continuous-functions",
    "href": "06_calculus.html#differentiable-and-continuous-functions",
    "title": "6  Calculus",
    "section": "6.3 Differentiable and Continuous Functions",
    "text": "6.3 Differentiable and Continuous Functions\n\nInformally: A function is continuous at a point if its graph has no holes or breaks at that point\nFormally: A function is continuous at a point \\(a\\) if: \\[\\displaystyle\\lim_{x \\to a} f(x)=f(a)\\]\nContinuity requires 3 conditions to hold:\n\n\\(f(a)\\) is defined (\\(a\\) is in the domain of \\(f\\))\n\\(\\displaystyle\\lim_{x \\to a} f(x)\\) exists\n\\(\\displaystyle\\lim_{x \\to a} f(x) = f(a)\\) (the value of \\(f\\) equals the limit of \\(f\\) at \\(a\\))\n\nDifferentiable:\n\nIf \\(f'(x)\\) exists, \\(f\\) is differentiable at \\(x\\).\nIf \\(f\\) is differentiable at every point of an open interval \\(I\\), \\(f\\) is differentiable on \\(I\\).\nGraph must have a (non-vertical) tangent line at each point, be relatively smooth, and not contain any breaks, bends, or cusps.\n\nIf a function is differentiable at a point, it is also continuous at that point.\nIf a function is continuous at a point, it is not necessarily differentiable at that point.\n\n\n6.3.1 When is f not differentiable?\nWhen does \\(f'(x)\\) not exist?\n\nWhen the function is discontinuous at that point.\n\nJump or break in the graph.\n\nThere are different slopes approaching the point from the left and from the right.\n\nCorner point\n\nWhen the graph of the function has a vertical tangent line at that point.\n\nCusp\nVertical inflection point"
  },
  {
    "objectID": "06_calculus.html#extrema-and-optimization",
    "href": "06_calculus.html#extrema-and-optimization",
    "title": "6  Calculus",
    "section": "6.4 Extrema and optimization",
    "text": "6.4 Extrema and optimization\nOptimization lets us find the minimum or maximum value a function takes.\n\nFormal theory\n\nUtility maximization, continuous choices\n\nOrdinary Least Squares (OLS)\n\nFocuses on minimizing the squared errors between observed data and values predicted by a regression.\n\nMaximum Likelihood Estimation (MLE)\n\nFocuses on maximizing a likelihood function, given observed values.\n\n\n\n6.4.1 Extrema\n\nInformally, a maximum is just the highest value a function takes, and a minimum is the lowest value.\nEasy to identify extrema (maxima or minima) intuitively by looking at a graph of the function.\n\nMaxima are high points (“peaks”)\nMinima are low points (“valleys”)\n\nExtrema can be local or global.\n\n\n\n6.4.2 Identifying extrema\n\nThe derivative of a function gives the rate of change.\nWhen the derivative is zero (or fails to exist), the function has usually reached a (local) maximum or minimum.\nAt a maximum, the function must be increasing before the point and decreasing after it.\nAt a minimum, the function must be decreasing before the point and increasing after it.\nWe’ll start by identifying points where this is the case (“critical points” or “stationary points”).\n\n\n\n\n\n\n\nNote\n\n\n\nA point where \\(f'(x)=0\\) or \\(f'(x)\\) does not exist is called a critical point (or stationary point). Local extrema occur at critical points, but not all critical points are extrema. For instance, sometimes the graph is changing between concave and convex (“inflection points”). Sometimes the function is not differentiable at that point for other reasons.\n\n\n\n\nWe can find the local maxima and/or minima of a function by taking the derivative, setting it equal to zero, and solving for x (or whatever).\n\n\\[f'(x)=0\\]\n\nThis gives us the first-order condition (FOC).\n\n\n\n6.4.3 Minimum or maximum?\nBUT we don’t know if we’ve found a maximum or minimum, or even if we’ve found an extremum or just an inflection point.\n\n\n6.4.4 Second derivatives\n\nThe second derivative gives us the rate of change of the rate of change of the original function. It tells us whether the slope is getting larger or smaller.\n\n\\[f(x) = x^2\\] \\[f'(x) = 2x\\] \\[f''(x) = 2\\]\n\nSecond Derivative Test - Start by identifying \\(f''(x)\\)\n\nSubstitute in the stationary points \\((x^*)\\) identified from the FOC.\n\n\\(f''(x^*) &gt; 0\\) we have a local minimum\n\\(f''(x^*) &lt; 0\\) we have a local maximum\n\\(f''(x^*) = 0\\) we (may) have an inflection point - need to calculate higher-order derivatives (don’t worry about this now)\n\n\nCollectively these give use the Second-Order Condition (SOC).\n\n\n6.4.5 Local vs. Global Extrema\n\nTo find the minimum/maximum on some interval, compare the local min/max to the value of the function at the interval’s endpoints.\nTo find the global minimum/maximum, check the function’s limits as it approaches \\(+ \\infty\\) and \\(- \\infty\\).\nExtreme value theorem: if a real-valued function \\(f\\) is continuous on the closed interval [a,b], then \\(f\\) must attain a (global) maximum and a (global) minimum."
  },
  {
    "objectID": "06_calculus.html#partial-derivatives",
    "href": "06_calculus.html#partial-derivatives",
    "title": "6  Calculus",
    "section": "6.5 Partial derivatives",
    "text": "6.5 Partial derivatives\n\nWe can take the derivative with respect to different variables.\nFor a function \\(fy=(x,z)=xz\\), we might want to know how the function changes with \\(x\\):\n\n\\[ \\displaystyle\\frac{\\partial}{\\partial_x}f(x,y) = \\frac{\\partial_y}{\\partial_x} = \\partial_x f\\]\n\nWe treat all other variables as constants and take derivative with respect to the variable of interest (here \\(x\\)).\n\n\nHow do we take a partial derivative?\nTreat all other variables as constants and take derivative with respect to the variable of interest.\nFrom our earlier example: \\[y = f(x,z) = xz \\] \\[ \\displaystyle\\frac{\\partial_y}{\\partial_x} = ?\\]\n\n\\[y = f(x,z) = xz \\] \\[ \\displaystyle\\frac{\\partial_y}{\\partial_x} = z\\]\nWhy? Because the partial derivative of \\(xz\\) with respect to \\(x\\) treats \\(z\\) as a constant.\nWhat is \\(\\displaystyle\\frac{\\partial_y}{\\partial_z}?\\)\n\n6.5.1 Application\n\n\\(\\frac{\\partial (x^2y+xy^2-x)}{\\partial x}\\)\nWe apply the addition rule to take the derivative of each term with respect to x.\n\\(\\frac{\\partial (x^2y)}{\\partial x}\\)+\\(\\frac{\\partial (xy^2)}{\\partial x}\\)+\\(\\frac{\\partial (-x)}{\\partial x}\\)\n\\(2xy+y^2-1\\)\n\n\n\n\\(\\frac{\\partial (x^2y+xy^2-x)}{\\partial y}\\)\nWe apply the addition rule to take the derivative of each term with respect to y\n\\(\\frac{\\partial (x^2y)}{\\partial y}\\)+\\(\\frac{\\partial (xy^2)}{\\partial y}\\)+\\(\\frac{\\partial (-x)}{\\partial y}\\)\n\\(x^2+2xy\\)\n\n\nPractice\nTake the partial derivative with respect to x and to y of the following functions. What would the notation for each look like?\n\\[3xy-x\\] \\[ln(xy)\\] \\[x^3+y^3+x^4y^4\\] \\[e^{xy}\\]"
  },
  {
    "objectID": "06_calculus.html#integrals",
    "href": "06_calculus.html#integrals",
    "title": "6  Calculus",
    "section": "6.6 Integrals",
    "text": "6.6 Integrals\n\n6.6.1 Area under a curve\n\nOften we want to find the area under a curve.\nSometimes finding the area is easy. What’s the area under the curve between \\(x=-1\\) and \\(x=1\\) for this function? \\[f(x) =\n\\begin{cases}\n\\frac{1}{3} & \\text{for } x \\in [0, 3] \\\\\n0 & \\text{otherwise}\n\\end{cases}\\]\n\n\n\n\n\n\n\n“Hint\n\n\n\nWe can draw this and look at the graph. Remember: \\[area = \\ell*w\\]\n\n\n\nNormally, finding the area under a curve is much harder. But this is basically the question behind integration.\n\n\n\n6.6.2 Integrals as summation\n\nWe are already familiar with summation notation. \\[\\displaystyle\\sum_{i=1}^{n} i\\]\nThis only works when we have discrete values to add.\n\nWhen we need to add continuously, we have to use something else. Specifically, integrals.\n\n\n\n\n6.6.3 Definite integrals\n\nLet’s say we have a function \\[ y = x^2 \\] And we want to find the area under the curve from \\(x=0\\) to \\(x=1\\).\nTo find the area we’re interested in here, we can use the definite integral.\nGenerally speaking, the notation looks like this: \\[\\displaystyle\\int_{x=a}^{b} f(x),dx\\]\nHere \\(a\\) is the lower limit of integration, \\(b\\) is the upper limit of integration, our function \\(f(x)\\) is our integrand, and \\(x\\) is our variable of integration.\n\n\n\nFor our question, we’re looking for the following: \\[\\displaystyle\\int_{x=0}^{1} f(x) dx\\]\nThis will give us a real number denoting the area under the curve of our function (\\(y=x^2\\)) between \\(x=0\\) and \\(x=1\\).\nIf \\(f\\) is continuous on \\([a,b]\\) or bounded on \\([a,b]\\) with a finite number of discontinuities, then \\(f\\) is integrable on \\([a,b]\\).\n\n\n\n6.6.4 Indefinite integrals\n\nThe indefinite integral, also known as the anti-derivative, \\(F(x)\\) is the inverse of the function \\(f'(x)\\). \\[F(x)= \\displaystyle\\int f(x) \\text{ } dx\\]\nThis means if you take the derivative of \\(F(x)\\), you wind up back at \\(f(x)\\). \\[F' = f \\text{ or } \\displaystyle\\frac{dF(x)}{dx} = f(x)\\]\nThis process is called anti-differentiation, or indefinite integration.\n\nWhile the definite integral gives us a real number (the total area under a curve), the indefinite integral gives us a function.\n\nWe need the concept of indefinite integrals to help us solve definite integrals.\n\n\n\n6.6.5 Solving definite integrals\n\nThe easiest way to calculate definite integrals, known as the “fundamental theorem of calculus,” is shown below:\n\n\\[\\displaystyle\\int_{a}^{b} f(x) \\text{ } dx = F(b)-F(a) = F(x)\\bigg|_{a}^{b}\\] - First we determine the antiderivative (indefinite integral) of \\(f(x)\\) (and represent it \\(F(x)\\)), substitute the upper limit first and then the lower limit one by one, and subtract the results in order.\n\n\n6.6.6 Constants\n\n\n\n\n\n\nNote\n\n\n\n\\(C\\) in the following slides is the called the “constant of integration.” We need to add it when we define all antiderivatives (integrals) of a function because the anti-derivative “undoes” the derivative.\nRemember that the derivative of any constant is zero. So if we find an integral \\(F(x)\\) whose derivative is \\(f(x)\\), adding (or subtracting) any constant will give us another integral \\(F(x)+C\\) whose derivative is also \\(f(x)\\).\n\n\n\n\n6.6.7 Rules of integration\n\\[ \\displaystyle\\int_{a}^{a}f(x) \\text{ }dx = 0\\]\n\\[\\displaystyle\\int_{a}^{b} f(x) \\text{ } dx = -\\displaystyle\\int_{b}^{a}f(x)dx\\]\n\\[\\int a \\text{ }dx = ax + C \\text { where $a$ is a constant}\\]\n\\[\\displaystyle\\int af(x)dx = a\\displaystyle\\int f(x) \\text{ }dx \\text{ where $a$ is a constant}\\]\n\n\n6.6.8 More rules\n\\[\\int (f(x) + g(x)) \\text{ } dx = \\int f(x) dx + \\int g(x)dx\\]\n\\[\\int x^n dx = \\frac{x^{n+1}}{n+1} + C \\qquad \\forall n \\neq -1\\]\n\\[\\int x^{-1}dx = \\ln |x| + C\\]\n\n\n6.6.9 Solving the problem\nRemember our function \\(y=x^2\\) and our goal of finding the area under the curve from \\(x=0\\) to \\(x=1\\).\n\nFind the indefinite integral, \\(F(x)\\)\n\n\\(\\displaystyle\\int x^2 \\text{ } dx\\)\n\\(\\displaystyle\\frac{x^3}{3}+C\\)\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWe use the “power rule” of integration, which is the following: \\[\\int x^n dx = \\frac{x^{n+1}}{n+1} + C \\qquad \\forall n \\neq -1\\]\n\n\n\nEvaluate at our lowest and highest points, \\(F(0)\\) and \\(F(1)\\).\n\n\\(F(0) = 0\\)\n\\(F(1) = \\displaystyle\\frac{1}{3}\\)\nTechnically \\(0 + C\\) and \\(\\displaystyle\\frac{1}{3} + C\\), but the C’s will fall out in the next step\n\nCalculate \\(F(1) - F(0)\\) \\[\\displaystyle\\frac{1}{3} - 0 = \\displaystyle\\frac{1}{3}\\]\n\n\nPractice — indefinite integrals\n\\[\\int x^2 \\text{ } dx\\] \\[\\int 3x^2\\text{ } dx\\] \\[\\int x\\text{ } dx\\] \\[\\int 3x^2 + 2x - 7\\text{ }dx\\] \\[\\int \\dfrac{2}{x}\\text{ }dx\\]\n\nPractice — definite integrals\n\\[\\displaystyle\\int_{1}^{7} x^2 \\text{ } dx\\] \\[\\displaystyle\\int_{1}^{10} 3x^2 \\text{ } dx\\] \\[\\int_7^7 x\\text{ } dx\\] \\[\\displaystyle\\int_{1}^{5} 3x^2 + 2x - 7\\text{ }dx\\] \\[\\int_{1}^{e} \\dfrac{2}{x}\\text{ }dx\\]\n\n\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "07_probability.html#what-is-probability",
    "href": "07_probability.html#what-is-probability",
    "title": "7  Probability",
    "section": "7.1 What is probability?",
    "text": "7.1 What is probability?\n\nFrequency with which an event occurs.\n\nTypically: \\[Pr(A) = P(A) = \\pi(A) = \\dfrac{\\text{Number of ways an event can occur}}{\\text{Total number of possible outcomes}}\\]\n\nProbability predicts real-world events using theoretical quantities.\n\nFormally, it assigns a likelihood of occurrence to each event in sample space\nWe use the probability space triplet (\\(\\Omega, S, P\\)), which are the sample space, event space, and probability mapping, respectively.\n\nWe can consider probability as a function that maps \\(\\Omega \\to \\mathbb{R}\\).\nWe can conceive it in terms of relative frequency or subjective belief."
  },
  {
    "objectID": "07_probability.html#kolmogorovs-axioms",
    "href": "07_probability.html#kolmogorovs-axioms",
    "title": "7  Probability",
    "section": "7.2 Kolmogorov’s axioms",
    "text": "7.2 Kolmogorov’s axioms\n\n\\(Pr(S_i)\\in\\mathbb{R},\\hspace{2mm} 1 \\geq Pr(S_i)\\geq 0 \\qquad \\forall S_i\\in S\\)\n\nWhere \\(S\\) is the event space, \\(S_i\\) are events.\nProbabilities must be non-negative.\n\n\\(Pr(\\Omega) = 1\\)\n\nWhere \\(\\Omega\\) is the sample space.\nSomething has to happen.\nProbabilities sum/integrate to 1.\n\n\\(Pr\\left(\\bigcup_{i = 1}^\\infty S_i\\right) = \\sum_{i=1}^\\infty Pr(S_i) \\iff Pr(S_i \\cap S_j) = 0\\hspace{2mm} \\forall i\\neq j\\)\n\nThe probability of disjoint (mutually exclusive) sets is equal to the sum of their individual probabilities."
  },
  {
    "objectID": "07_probability.html#some-definitions",
    "href": "07_probability.html#some-definitions",
    "title": "7  Probability",
    "section": "7.3 Some definitions",
    "text": "7.3 Some definitions\n\nRandom variable: a variable whose value is determined by the outcome of a random process.\n\nSometimes also called a stochastic variable.\nMay be discrete or continuous.\n\nDistribution (of a random variable): the set of values the variable might take.\n\nProbability mass function / probability density function defines the probability with which each value occurs.\nAlways sums / integrates to 1.\n\nRealization (of a random variable): a particular value taken by the variable.\n\n\n\nPopulation: the entire set of objects (people, cases, etc.) in which we are interested.\n\nOften denoted \\(N\\).\n\nSample: a subset of the population we can observe, from which we try to make generalizations about the population.\n\nOften denoted \\(n\\).\n\nFrequency distribution: a count of how often a variable takes each of its possible values.\n\nThe number of members of a sample that take each value of a variable.\n\nIndependent random variables: two variables are statistically independent if the value of one does not affect the value of the other.\n\nFormally, \\(Pr(A \\cap B)=Pr(A)Pr(B)\\)"
  },
  {
    "objectID": "07_probability.html#discrete-probability",
    "href": "07_probability.html#discrete-probability",
    "title": "7  Probability",
    "section": "7.4 Discrete probability",
    "text": "7.4 Discrete probability\n\nA sample space in which there are a (finite or infinite) countable number of outcomes\nEach realization of random process has a discrete probability of occurring.\n\n\\(f(X=x_i)=P(X=x_i)\\) is the probability the variable takes the value \\(x_i\\).\n\n\n\n7.4.1 Probability Mass Function (PMF)\nProbability of each occurrence encoded in probability mass function (PMF)\n\n\\(0 \\leq f(x_i) \\leq 1\\)\n\nProbability of any value occurring must be between 0 and 1.\n\n\\(\\displaystyle\\sum_{x}f(x_i) = 1\\)\n\nProbabilities of all values must sum to 1.\n\n\n\n\n7.4.2 Discrete distribution\n\nWhat’s the probability that we’ll roll a 3 on one die roll: \\[Pr(y=3) = \\dfrac{1}{6}\\]\nIf one roll of the die is an “experiment.”\nWe can think of a 3 as a “success.”\n\\(Y \\sim Bernoulli \\left(\\frac{1}{6} \\right)\\)\nFair coins are \\(\\sim Bernoulli(.5)\\), for example.\nMore generally, \\(Bernoulli(\\pi )\\).\n\n\\(\\pi\\) represents the probability of success.\n\n\n\n\nDrawing a specific card from a deck: \\[Pr(y=\\text{ace of spades}) = \\dfrac{1}{52}\\]\nDrawing any card with a specific value from a deck: \\[Pr(y=ace) = \\dfrac{4}{52}\\]\nGetting a specific value on two dice rolls: \\[Pr(y=8) = \\dfrac{5}{36}\\]\nWe can express the probability mass function in tabular format or in a graph."
  },
  {
    "objectID": "07_probability.html#continuous-probability",
    "href": "07_probability.html#continuous-probability",
    "title": "7  Probability",
    "section": "7.5 Continuous probability",
    "text": "7.5 Continuous probability\n\nWhat happens when our outcome is continuous?\nThere are an infinite number of outcomes.\nThis makes the denominator of our fraction difficult to work with.\nThe probability of the whole space must equal 1.\nEven if all events are equally likely, \\(\\dfrac{1}{\\infty} =0\\)\n\n\n7.5.1 Basics\n\nThe domain may not span -\\(\\infty\\) to \\(\\infty\\).\n\nEven space between 0 and 1 is infinite.\n\nThe domain is defined as the area under the probability density function.\nTwo common examples are the uniform and bell curves.\n\n\n\n7.5.2 Probability Density Function (PDF)\n\nSimilar to PMF from before, but for continuous variables.\nGives the probability a value falls within a particular interval\n\n\\(P[a\\le X\\le b] = \\displaystyle\\int_a^b f(x) \\, dx\\)\nTotal area under the curve is 1.\n\\(P(a &lt; X &lt; b)\\) is the area under the curve between \\(a\\) and \\(b\\) (where \\(b &gt; a\\))."
  },
  {
    "objectID": "07_probability.html#cumulative-density-function-cdf",
    "href": "07_probability.html#cumulative-density-function-cdf",
    "title": "7  Probability",
    "section": "7.6 Cumulative Density Function (CDF)",
    "text": "7.6 Cumulative Density Function (CDF)\n\n7.6.1 Discrete\n\nCumulatve density function is probability X will take a value of x or lower.\nPDF is written \\(f(x)\\), and CDF is written \\(F'(x)\\). \\[F_X(x) = Pr(X\\leq x)\\]\nFor discrete CDFs, that means summing up over all values.\nWhat is the probability of rolling a 6 or lower with two dice? \\(F(6)=?\\)\n\n\n\n7.6.2 Continuous\n\nWe can’t sum probabilities for continuous distributions (remember the 0 problem).\nSolution: integration \\[F_Y(y) = \\int_{-\\infty}^{y} f(y) dy\\]\nExamples of uniform distribution."
  },
  {
    "objectID": "07_probability.html#statistics",
    "href": "07_probability.html#statistics",
    "title": "7  Probability",
    "section": "7.7 Statistics",
    "text": "7.7 Statistics\n\n7.7.1 Introduction\n\nWhile probability allows us to make predictions about events using distributions, statistics uses events to make estimates about distributions and variables.\nIt is the process of learning from data.\nA statistic is a summary of data, capturing some theoretically-relevant quantity.\nBroad categories of numerical and categorical.\n\n\n\n7.7.2 Univariate statistics\n\nThese measure a single variable.\nReadily expressed in graphical form.\nCommon examples:\n\nCentral tendency (mean, median, and mode)\nVariance\n\n\n\n\n7.7.3 Examples of univariate statistics\n\nThe mean (\\(\\bar{x}\\)) is calculated by summing the data, then dividing by the number of observations: \\[\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\\]\nThe median is found by ordering the observations from highest to lowest and finding the one in the middle.\nThe mode is the most common number.\n\n\\[x= \\begin{bmatrix} 1 & 2 & 3 & 4 & 5 & 6 & 6 & 7 & 8 & 9 \\end{bmatrix}\\]\n\nWhat are the mean, median, and mode of x?\n\n\n\n7.7.4 Measures of central tendency\n\nMean balances values on either side.\nMedian balances observations on either side.\nMode finds the most typical observation.\nWhich is the best? Like most of what you’ll learn in statistics, it depends.\n\n\n\n7.7.5 Deviations from central tendency\n\nConsider two data sets: \\[\\begin{aligned}\nx= \\begin{bmatrix} 1 & 1.5 & 2 & 2.5 & 5.5 & 8.5 & 9 & 9.5 & 10 \\end{bmatrix}\n\\end{aligned}\\] \\[\\begin{aligned}\ny= \\begin{bmatrix} 4.5 & 4.8 & 5 & 5.3 & 5.5 & 5.7 & 6 & 6.2 & 6.5 \\end{bmatrix}\n\\end{aligned}\\]\nWhat is the mean of each?\nWhat is the median of each?\nAre they similar distributions?\n\n\n\n7.7.6 Variance\n\nWe use variance to measure the spread of a single variable.\nFormally defined as the squared deviation from the mean (\\(\\mu\\)).\nFor discrete random variables, it is written \\(Var(x)=\\sigma^2=\\displaystyle\\frac{1}{n}\\displaystyle\\sum_{i=1}^n(x_i-\\mu)^2\\)\nFor continuous random variables, it is written \\(Var(x)=\\sigma^2=\\displaystyle\\int (x-\\mu)^2 f(x) \\text{ }dx\\)\n\n\n\n7.7.7 Standard deviation\n\nSometimes variance doesn’t make sense, either mathematically or conceptually.\n\nNot always clear how to interpret “squared deviation from the mean.”\n\nInstead, will frequently see standard deviation, which is square root of variance.\nIt is written \\(\\sigma\\)."
  },
  {
    "objectID": "07_probability.html#bivariate-statistics",
    "href": "07_probability.html#bivariate-statistics",
    "title": "7  Probability",
    "section": "7.8 Bivariate statistics",
    "text": "7.8 Bivariate statistics\n\n7.8.1 Covariance\n\nWhile measures of central tendency and variance/standard deviation provide useful summaries of a single variable, they don’t provide insights into relationships between variables.\nFor that, we need bivariate statistics.\nMost common and straightforward is covariance.\n\n\n\nColloquially, can think of covariance as measure of linear deviation from mean.\nWhen values from one variable are above their mean, are values from the other above or below their mean?\nPut another way, if I told you the value of x was high, would you expect values of y to be high or low?\nFormally, it is written as: \\[cov(X,Y)=E(X-E(X))(Y-E(Y))=E(XY)-E(X)E(Y)\\]\nIt is important to note that the magnitude is meaningless; only the direction is interpretable.\n\n\n\n7.8.2 Correlation\n\nCorrelation is a normalized measure of covariance\nIt is calculated as: \\[\\rho_{X,Y}=\\frac{cov(X,Y)}{\\sigma_X \\sigma_Y}\\]\nIt varies between -1 and 1.\nWhat is correlation of two independent variables?"
  },
  {
    "objectID": "07_probability.html#regression",
    "href": "07_probability.html#regression",
    "title": "7  Probability",
    "section": "7.9 Regression",
    "text": "7.9 Regression\n\n7.9.1 Ordinary least squares\n\nOrdinary least squares regression (OLS) is probably the most widely-used model in political science.\nIt is all about drawing a line through data.\nThis allows us to evaluate the relationship (the association) between \\(x\\) on \\(y\\).\nThe dependent variable, \\(y\\), must be continuous, generally speaking.\nThe main question is which line to draw.\n\n\nLine and equation (\\(\\hat{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1} x_{i}\\)) on board\n\n\n7.9.2 Residuals\n\nIn basically any set of data, no line can pass through every point (observation).\nWe will always have make some error in predicting values.\nThe error between the line and some point is referred to as the residual.\nIf we refer to our predicted value as \\(\\hat{y}\\), then we can calculate the residual for each observation with the following equation: \\[e_i = y_i - \\hat{y}_i\\]\n\n\n\n7.9.3 Finding the right line\n\nOLS determines the “best” line by minimizing the sum of squared residuals.\nPlug in all the values for the slope amd intercept and calculate the sum of squared residuals for these infinity combinations.\nThat is a lot of work.\nThe best solution turns out to be calculus.\nWe want to minimize the sum of squared residuals with respect to our \\(\\beta\\)’s.\n\n\n\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "08_simulations.html",
    "href": "08_simulations.html",
    "title": "8  Simulations",
    "section": "",
    "text": "FiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "09_textanalysis.html#strings",
    "href": "09_textanalysis.html#strings",
    "title": "9  Text analysis",
    "section": "9.1 Strings",
    "text": "9.1 Strings\n\nIn R, a piece of text is represented as a sequence of characters (letters, numbers, and symbols).\nA string is a sequence of characters, which is used for storing text.\n\nFor example, “methods” is a string that includes characters: m, e, t, h, o, d, s.\n\nCreating strings is very straightforward in RStudio. We assign character values to a variable, being sure to enclose the character values (the text) in double or single quotation marks.\n\nWe can create strings of single words, or whole sentences if we so wish.\n\n\n\nstring1 &lt;- \"camp\" \nstring1\n\n[1] \"camp\"\n\nstring2 &lt;- \"I love methods camps.\"\nstring2\n\n[1] \"I love methods camps.\"\n\n\n\nWe can also create a vector of strings.\n\n\nstring3 &lt;- c(\"I\", \"love\", \"methods\", \"camp\", \".\")\nstring3\n\n[1] \"I\"       \"love\"    \"methods\" \"camp\"    \".\""
  },
  {
    "objectID": "09_textanalysis.html#string-manipulation",
    "href": "09_textanalysis.html#string-manipulation",
    "title": "9  Text analysis",
    "section": "9.2 String manipulation",
    "text": "9.2 String manipulation\n\nOften, strings, and more broadly text, contain information that we want to extract for the purpose of our research.\n\nFor example, perhaps we wanted to count the number of times a certain country was mentioned during the U.S. President’s annual State of the Union Address.\n\nFor tasks such as these, we can use regular expressions (also known as ‘regex’), which search for one or more specified pattern of characters.\n\nThese patterns can be exact matches, or more general.\n\n\n\ntest &lt;- \"test\"\n\n\nRegular expressions can be used to:\n\nExtract information from text.\nParsing text.\nCleaning/replacing strings.\n\n\n\n\n\n\n\n\nNote\n\n\n\nFortunately, the syntax for regular expressions is relatively stable across all programming languages (e.g., Java, Python, R).\n\n\n\n9.2.1 Regular expression basics\n\nAnchors: ^ and"
  },
  {
    "objectID": "09_textanalysis.html#stringr",
    "href": "09_textanalysis.html#stringr",
    "title": "9  Text analysis",
    "section": "9.3 Stringr",
    "text": "9.3 Stringr\n\nTo install \"stringr\" use the function install.packages(). Then, load it to your current session with library():\n\n\n# installing 'stringr'\ninstall.packages(\"stringr\")\n\nInstalling package into '/home/runner/work/_temp/Library'\n(as 'lib' is unspecified)\n\n# load 'stringr'\nlibrary(stringr)\n\n\nstringr provides functions for both (a) basic string manipulations and (b) regular expression operations. Some basic functions are listed below:\n\n\n\n\nFunction\nDescription\n\n\n\n\nstr_c()\nstring concatenation\n\n\nstr_length()\nnumber of characters\n\n\nstr_sub()\nextracts substrings\n\n\nstr_dup()\nduplicates characters\n\n\nstr_trim()\nremoves leading and trailing whitespace\n\n\nstr_pad()\npads a string\n\n\nstr_wrap()\nwraps a string paragraph\n\n\nstr_trim()\ntrims a string"
  },
  {
    "objectID": "09_textanalysis.html#simple-text-analysis",
    "href": "09_textanalysis.html#simple-text-analysis",
    "title": "9  Text analysis",
    "section": "9.4 Simple text analysis",
    "text": "9.4 Simple text analysis\n\n9.4.1 Counts\n\n\n9.4.2 tf-idf\n\n\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "10_wrapup.html#project-management",
    "href": "10_wrapup.html#project-management",
    "title": "10  Wrap up",
    "section": "10.1 Project management",
    "text": "10.1 Project management\n\n10.1.1 RStudio projects\n\nRStudio projects are an excellent way to keep all the files associated with a project (data, R scripts, results, figures, etc.) in one place on your computer.\nTo create a new project file, click File &gt; New Project, then:\n\n\n\n10.1.2 Storing raw data"
  },
  {
    "objectID": "10_wrapup.html#other-resources",
    "href": "10_wrapup.html#other-resources",
    "title": "10  Wrap up",
    "section": "10.2 Other resources",
    "text": "10.2 Other resources\n\n10.2.1 Overleaf\n\n\n\n\nOverleaf is a collaborative cloud-based LaTeX editor designed for writing, editing, and publishing documents.\n\nLaTeX is a software used for typesetting technical documents. It is used widely in our discipline for the preparation for manuscripts to journals and other publishing venues.\n\nUT Austin actually provides free access to Overleaf Professional to all graduate students using your UT email.\nOverleaf Professional upgrades include:\n\nReal-time collaboration\nReal-time track changes and visible collaborator cursor(s)\nReal-time PDF preview of your document while editing and writing\nFull history view of your documents\nTwo-way sync with Dropbox and GitHub\nReference manager sync and advanced reference search.\nUT Austin resource portal, including UT Austin templates, FAQs, and resource links\n\n\n\n\n\n\n\n\nImportant\n\n\n\nLaTeX is actually the markup language that powers this website! If you are curious about general syntax and commands, you can access our repository at any time to get a closer look.\n\n\n\n\n10.2.2 Zotero\n\n\n\n\nZotero is an open-source reference manager used to store, manage, and cite bibliographic references, such as books and articles.\nWhen it is time to write, you can insert your sources directly into your paper as in-text citations via a word processor plugin, which generates a bibliography in your style of choice.\n\nThis can save a lot of time, especially when you have to change citation styles for submission to another journal.\n\nYou can download the software for free here.\n\nYou can also find a guide on how to install it here.\n\n\n\n\n\n\n\n\nNote\n\n\n\nZotero is one of many other reference managers out there. Alternatives include Mendeley and EndNote, among others. You should choose whatever option best suits your needs.\n\n\n\n10.2.2.1 Benefits of Zotero\n\nIf you have not yet chosen a reference manager or are considering switching, below are some advantages of Zotero:\n\nWorks as a standalone desktop software with plugins for Chrome, Safari, and Firefox\nFull compatibility with Google docs\nFree plugin for Word and LibreOffice included\nIncludes most popular citation styles with more styles available on the Zotero Style Repository\nDrag and drop PDF files into the library, extracting metadata such as authors, year, etc.\nAllows advanced searches of all content in your library using full-text PDF indexing\nUse cloud storage (optional) and sync libraries across devices\nCreate unlimited private or public groups and collaborate by sharing files and citations\n300MB of free cloud storage and 2GB of storage for $20 USD/year (equal to $1.67 per month)\n\nHere is a comprehensive guide to unlocking all of Zotero’s potential."
  },
  {
    "objectID": "10_wrapup.html#methods-at-ut",
    "href": "10_wrapup.html#methods-at-ut",
    "title": "10  Wrap up",
    "section": "10.3 Methods at UT",
    "text": "10.3 Methods at UT\n\n10.3.1 Required methods courses\n\nScope and Methods of Political Science\n\nStatistics I (Statistics/linear regression)\n\nStatistics II (Linear regression and more)\nStatistics III (Maximum likelihood estimation)\n\nOnly required if your major field is methods\n\n\n\n\n10.3.2 Other methods courses\n\nStatistics/econometrics:\n\nBayesian Statistics\nCausal Inference\nMath Methods for Political Analysis\nTime Series and Panel Data\nPanel and Multilevel Analysis\n\n\n\n\n10.3.3 More courses\n\nFormal Theory\n\nIntro to Formal Political Analysis\nFormal Political Analysis II\nFormal Theories of International Relations\n\nEverything else\n\nConceptualization and Measurement\nExperimental Methods in Political Science\nQualitative Methods\nNetwork Analysis\nSeminar in Field Experiments\n\n\n\n\n10.3.4 Other departments at UT\nYou can also take courses through the Economics, Mathematics, or Statistics (Statistics and Data Science) departments.\n\nM.S. in Statistics\n\nSoftware and Topic Short Courses - R, Python, Stata, etc.\n\nMore info here.\n\n\n\n10.3.5 Other resources\nSummer programs at UT:\n\nShort courses in statistics\n\nDepartment sometimes offers scholarships to cover part of the cost.\n\n\nSummer programs outside UT:\n\nICPSR (Inter-university Consortium for Political and Social Research)\n\nAnn Arbor, Michigan\n\nEITM (Empirical Implications of Theoretical Models)\n\nHouston and other locations (Michigan, Duke, Berkeley, Emory)\n\nIQMR (Institute for Qualitative and Multi-Method Research)\n\nSyracuse, NY\n\n\n\n\n\n\nFiveThirtyEight. 2021. “Tracking Congress In The Age Of Trump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service. 2019. “Department of Agriculture Agricultural Research Service.” https://fdc.nal.usda.gov/."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "FiveThirtyEight. 2021. “Tracking Congress\nIn The Age Of\nTrump [Dataset].” https://projects.fivethirtyeight.com/congress-trump-score/.\n\n\nU. S. Department of Agriculture [USDA], Agricultural Research Service.\n2019. “Department of Agriculture Agricultural Research\nService.” https://fdc.nal.usda.gov/."
  }
]