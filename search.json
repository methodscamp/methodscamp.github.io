[
  {
    "objectID": "index.html#class-schedule",
    "href": "index.html#class-schedule",
    "title": "Methods Camp",
    "section": "Class schedule",
    "text": "Class schedule\n\n\n\nDate\nTime\nLocation\n\n\n\n\nThurs, Aug. 10\n9:00 AM - 4:00 PM\nRLP 1.302E\n\n\nFri, Aug. 11\n9:00 AM - 4:00 PM\nRLP 1.302E\n\n\nSat, Aug. 12\nNo class\n-\n\n\nSun, Aug. 13\nNo class\n-\n\n\nMon, Aug. 14\n9:00 AM - 4:00 PM\nRLP 1.302E\n\n\nTues, Aug. 15\n9:00 AM - 4:00 PM\nRLP 1.302E\n\n\nWeds, Aug. 16\n9:00 AM - 4:00 PM\nRLP 1.302E\n\n\n\nOn class days, we will have a lunch break from 12:00-1:00 PM. We’ll also take short breaks periodically during the morning and afternoon sessions as needed."
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "Methods Camp",
    "section": "Description",
    "text": "Description\nWelcome to Introduction to Methods for Political Science, aka “Methods Camp”! In the past our incoming students have told us their math skills are rusty and they would like to be better prepared for UT’s methods courses. Methods Camp is designed to give everyone a chance to brush up on some skills in preparation for the Stats I and Formal Theory I courses. The other goal of Methods Camp is to allow you to get to know your cohort. We hope that struggling with matrix algebra and the dreaded chain rule will still prove to be a good bonding exercise.\nAs you can see from the above schedule, we’ll be meeting on Thursday, August 10th and Friday, August 11th as well as from Monday, August 14th through Wednesday, August 16th. Classes at UT begin the start of the following week on Monday, August 22nd. Below is a tentaive schedule outlining what will be covered in the class, although we may rearrange things a bit if we find we’re going too slowly or too quickly through any of the material."
  },
  {
    "objectID": "index.html#course-outline",
    "href": "index.html#course-outline",
    "title": "Methods Camp",
    "section": "Course outline",
    "text": "Course outline\n1 Thursday morning: R and RStudio\n\nIntroductions\nRStudio (materials are on the website as zipped RStudio projects)\nObjects (vectors, matrices, data frames)\nBasic functions (mean(), length(), etc.)\n\n2 Thursday afternoon: tidyverse basics I\n\nPackages: installation and loading (including the tidyverse)\nData wrangling with dplyr (basic verbs, including the new .by = syntax)\nData visualization basics with ggplot2\nData loading (.csv, .rds, .dta, .xlsx)\nQuarto fundamentals\n\n3 Friday morning: Matrices\n\nMatrices\nSystems of linear equations\nMatrix operations (multiplication, transpose, inverse, determinant).\nSolving systems of linear equations in matrix form (and why that’s cool)\nIntroduction to OLS\n\n4 Friday afternoon: tidyverse basics II\n\nData merging and pivoting (*_join(), pivot_*())\nValue recoding (if_else(), case_when())\nMissing values\nData visualization extensions: facets, text annotations\n\n5 Monday morning: Functions and loops\n\nFunctions\nFor-loops and lapply()\nFinding R help (help files, effective Googling, ChatGPT)\n\n6 Monday afternoon: Calculus\n\nLimits (not sure how to teach this in an R-centric way yet, but there must be a way)\nDerivatives (symbolic, numerical, automatic)\nIntegrals\n\n7 Tuesday morning: Probability\n\nConcepts: probability, random variables, etc.\nPMF, PDF, CDF, etc.\nDistributions (binomial, normal; different functions in R and how to use them)\nExpectation and variance\n\n8 Tuesday afternoon: Simulations\n\nSimulations (ideas, seed setting, etc.)\nSampling\nBootstrapping\n\n9 Wednesday morning: Text analysis\n\nString manipulation with stringr\nSimple text analysis (counts, tf-idf, etc.) with tidytext and visualization\n\n10 Wednesday afternoon: Wrap-up\n\nProject management fundamentals (RStudio projects, keeping raw data, etc.)\nSelf-study resources and materials\nOther software (Overleaf, Zotero, etc.)\nMethods at UT"
  },
  {
    "objectID": "index.html#contact-info",
    "href": "index.html#contact-info",
    "title": "Methods Camp",
    "section": "Contact info",
    "text": "Contact info\nIf you have any questions during or outside of methods camp, you can contact Andrés at andres.cruz at utexas dot edu and Matt at mjmartin at utexas dot edu."
  },
  {
    "objectID": "01_r_rstudio.html#installing-r-and-rstudio",
    "href": "01_r_rstudio.html#installing-r-and-rstudio",
    "title": "1  R and RStudio",
    "section": "1.1 Installing R and RStudio",
    "text": "1.1 Installing R and RStudio\nR is a programming language optimized for statistics and data analysis. Most people use R from RStudio, a graphical user interface (GUI) that includes a file pane, a graphics pane, and other goodies. Both R and RStudio are open source, i.e., free as in beer and free as in freedom!\nYour first steps should be to install R and RStudio, in that order (if you have installed these programs before, make sure that your versions are up-to-date—if not, follow the instructions below):\n\nDownload and install R from the official website, CRAN. Click on “Download R for &lt;Windows/Mac&gt;” and follow the instructions. If you have a Mac, make sure to select the version appropriate for your system (Apple Silicon for newer M1/M2 Macs and Intel for older Macs).\nDownload and install RStudio from the official website. Scroll down and select the installer for your operating system.\n\nAfter these two steps, you can open RStudio in your system, as you would with any program. You should see something like this:\n\nThat’s it for the installation! We also strongly recommend that you change a couple of RStudio’s default settings:1\n\nTools &gt; Global Options &gt; General &gt; Uncheck \"Restore .RData into workspace at startup\"\nTools &gt; Global Options &gt; General &gt; Save workspace to .RData on Exit &gt; Select \"Never\"\nTools &gt; Appearance to change to a dark theme, if you want! Pros: better for night sessions, hacker vibes…"
  },
  {
    "objectID": "01_r_rstudio.html#setting-up-for-methods-camp",
    "href": "01_r_rstudio.html#setting-up-for-methods-camp",
    "title": "1  R and RStudio",
    "section": "1.2 Setting up for Methods Camp",
    "text": "1.2 Setting up for Methods Camp\nTODO: how to download the materials and open the RStudio project (include discussion on .zip files). How to make sure that everything’s fine (see top-right for RStudio project)."
  },
  {
    "objectID": "01_r_rstudio.html#short-intro-to-r",
    "href": "01_r_rstudio.html#short-intro-to-r",
    "title": "1  R and RStudio",
    "section": "1.3 Short intro to R",
    "text": "1.3 Short intro to R\nTODO: objects and common functions. Explain how to run Quarto code blocks, and how to render a document to html."
  },
  {
    "objectID": "01_r_rstudio.html#footnotes",
    "href": "01_r_rstudio.html#footnotes",
    "title": "1  R and RStudio",
    "section": "",
    "text": "The idea behind these settings is to force R to start from scratch with each new session. No lingering objects avoids misunderstandings and helps with reproducibility!↩︎"
  },
  {
    "objectID": "03_matrices.html#introduction",
    "href": "03_matrices.html#introduction",
    "title": "3  Matrices",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\n\n3.1.1 Scalars\n\nOne number (12, for example) is referred to as a scalar.\nEach scalar in a matrix is an element of that matrix.\n\n\\[\\begin{bmatrix}\n12\n\\end{bmatrix}\\]\n\n\n\n\n\n\nNote\n\n\n\nThis is also called a 1 x 1 (“one by one”) matrix.\n\n\n\n\n3.1.2 Vectors\n\nWe can put several scalars together to make a vector.\nHere is an example: \\[\\begin{bmatrix}\n    12 \\\\\n    14 \\\\\n    15\n    \\end{bmatrix}\n    = b\\]\nSince this is a column of numbers, we cleverly refer to it as a column vector.\nHere is another example of a vector: \\[\\begin{bmatrix}\n12 & 14 & 15\n\\end{bmatrix}\n= d\\]\nThis, in contrast, is called a row vector."
  },
  {
    "objectID": "03_matrices.html#operators",
    "href": "03_matrices.html#operators",
    "title": "3  Matrices",
    "section": "3.2 Operators",
    "text": "3.2 Operators\n\n3.2.1 Summation\n\nThe summation operator, \\(\\sum\\), lets us perform an operation on a sequence of numbers, which is often but not always a vector.\n\n\\[x = \\begin{bmatrix}\n12 & 7 & -2 & 0 & 1\n\\end{bmatrix}\\]\n\nWe can then calculate the sum of the first three elements of the vector, which is expressed as follows: \\[\\sum_{i=1}^3 x_i\\]\nThen, we do the following math: \\[12+7+-2=17\\]\n\n\n\n3.2.2 Product\n\nThe product operator, \\(\\prod\\), can also perform operations over a sequence of elements in a vector.\n\n\\[z = \\begin{bmatrix}\n5 & -3 & 5 & 1\n\\end{bmatrix}\\]\n\nWe can then calculate the calculate the product of the four elements in the vector, which is expressed as follows: \\[\\prod_{i=1}^4 z_i\\]\nThen, we do the following math: \\[5*-3*5*1=-75\\]"
  },
  {
    "objectID": "03_matrices.html#matrices",
    "href": "03_matrices.html#matrices",
    "title": "3  Matrices",
    "section": "3.3 Matrices",
    "text": "3.3 Matrices\n\n3.3.1 Basics\n\nWe can append vectors together to form a matrix:\n\n\\[\\begin{bmatrix}\n12 & 14 & 15 \\\\\n115 & 22 & 127 \\\\\n193 & 29 & 219\n\\end{bmatrix}\n= A\\]\n\nThe number of rows and columns of a matrix constitute the dimensions of the matrix.\nThe first number (“r”) is the number of rows and the second number (“c” here) is the number of columns in the matrix.\n\n\n\n\n\n\n\nImportant\n\n\n\nFind a way to remember “r x c” permanently. The order of the dimensions never changes.\n\n\n\nThe matrix \\(A\\) above, for example, is a \\(3x3\\) matrix.\nWe often use capital letters (sometimes also bold-faced) to represent matrices.\n\n\n\n3.3.2 Structure\n\nHow do we refer to specific elements of the matrix?\nMatrix \\(A\\) is an \\(m\\times n\\) matrix where \\(m=n=3\\)\nMore generally, matrix \\(B\\) is an \\(m\\times n\\) matrix where the elements look like this: \\[B=\n\\begin{bmatrix}\nb_{11} & b_{12} & b_{13} & \\ldots & b_{1n} \\\\\nb_{21} & b_{22} & b_{23} & \\ldots & b_{2n} \\\\\n\\vdots & \\vdots & \\vdots & \\ldots & \\vdots \\\\\nb_{m1} & b_{m2} & b_{m3} & \\ldots & b_{mn}\n\\end{bmatrix}\\]\nThus \\(b_{23}\\) refers to the second unit down and third across.\n\n\n\n\n\n\n\nReminder\n\n\n\nWhen trying to identify a specific element, the first subscript is the element’s row and the second subscript is the element’s column (always in that order)."
  },
  {
    "objectID": "03_matrices.html#matrix-operations",
    "href": "03_matrices.html#matrix-operations",
    "title": "3  Matrices",
    "section": "3.4 Matrix operations",
    "text": "3.4 Matrix operations\n\n3.4.1 Addition and subtraction\n\nAddition and subtraction are straightforward operations.\nMatrices must have exactly the same dimensions for both of these operations.\nWe add or subtract each element with the corresponding element from the other matrix.\nThis is expressed as follows:\n\n\\[A \\pm B=C\\]\n\\[c_{ij}=a_{ij} \\pm b_{ij} \\text{ }\\forall i,j\\]\n\\[\\begin{bmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\n\\pm\n\\begin{bmatrix}\nb_{11} & b_{12} & b_{13}\\\\\nb_{21} & b_{22} & b_{23}\\\\\nb_{31} & b_{32} & b_{33}\n\\end{bmatrix}\\] \\[=\\] \\[\\begin{bmatrix}\na_{11}\\pm b_{11} & a_{12}\\pm b_{12} & a_{13}\\pm b_{13}\\\\\na_{21}\\pm b_{21} & a_{22}\\pm b_{22} & a_{23}\\pm b_{23}\\\\\na_{31}\\pm b_{31} & a_{32}\\pm b_{32} & a_{33}\\pm b_{33}\n\\end{bmatrix}\\]\n\nPractice\n\\[A= \\begin{bmatrix}\n1 & 4 & 2 \\\\\n-2 & -1 & 0 \\\\\n0 & -1 & 3\n\\end{bmatrix}\\]\n\\[B = \\begin{bmatrix}\n5 & 1 & 0 \\\\\n2 & -1 & 0 \\\\\n7 & 1 & 2\n\\end{bmatrix}\\]\nCalculate \\(A+B\\)\n\nPractice\n\\[A= \\begin{bmatrix}\n6 & -2 & 8 & 12 \\\\\n4 & 42 & 8 & -6 \\\\\n-14 & 5 & 0 & 0\n\\end{bmatrix}\\]\n\\[B = \\begin{bmatrix}\n18 & 42 & 3 & 7 \\\\\n0 & -42 & 15 & 4 \\\\\n-7 & 0 & 21 & -18\n\\end{bmatrix}\\]\nCalculate \\(A-B\\)\n\n\n3.4.2 Scalar multiplication\n\nScalar multiplication is very intuitive.\nAs we know, a scalar is a single number, or a 1 x 1 matrix.\nWe multiply each value in the matrix by the scalar to perform this operation.\nThis is expressed as follows: \\[A =\n\\begin{bmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\\] \\[cA =\n\\begin{bmatrix}\nca_{11} & ca_{12} & ca_{13}\\\\\nca_{21} & ca_{22} & ca_{23}\\\\\nca_{31} & ca_{32} & ca_{33}\n\\end{bmatrix}\\]\n\n\nPractice \\[A= \\begin{bmatrix}\n    1 & 4 & 2 \\\\\n    8 & -1 & 3 \\\\\n    0 & -2 & 3\n    \\end{bmatrix}\\] \\[ B = \\begin{bmatrix}\n    -15 & 1 & 5 \\\\\n    2 & -42 & 0 \\\\\n    7 & 1 & 6\n    \\end{bmatrix}\\]\nCalculate \\(2\\times A\\) and \\(-3 \\times B\\)\n\n\n3.4.3 Matrix multiplication\n\nTwo matrices must be conformable for them to be multiplied together.\nThis means that the number of columns in the first matrix equals the number of rows in the second.\nWhen multiplying \\(A \\times B\\), if \\(A\\) is \\(m \\times n\\), \\(B\\) must have \\(n\\) rows.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe conformability requirement never changes. Before multiplying anything, check to make sure the matrices are indeed conformable.\n\n\n\nThe resulting matrix will have the same number of rows as the first matrix and the number of columns in the second.\nFor example, if \\(A\\) is \\(i \\times k\\) and \\(B\\) is \\(k \\times j\\), then \\(A \\times B\\) will be \\(i \\times j\\).\n\n\nWhich of the following can we multiply? What will be the dimensions of the resulting matrix? \\[\\begin{aligned}\nb=\n\\begin{bmatrix}\n2 \\\\\n3\\\\\n4\\\\\n1\n\\end{bmatrix}\nM =\n\\begin{bmatrix}\n1 & 0 & 2\\\\\n1 & 2 & 4\\\\\n2 & 3 & 2\n\\end{bmatrix}\nL =\n\\begin{bmatrix}\n6 & 5 & -1\\\\\n1 & 4 & 3\n\\end{bmatrix}\n\\end{aligned}\\]\n\n\n\n\n\n\nWarning\n\n\n\nWhen multiplying matrices, order matters.\n\n\n\nWhy can’t we multiply in the opposite order?\n\n\n\n3.4.4 Multiplication steps\n\nMultiply each row by each column, summing up each pair of multiplied terms.\n\n\n\n\n\n\n\nNote\n\n\n\nThis is sometimes to referred to as the “dot product,” where we multiply matching members, then sum up.\n\n\n\nThe element in position \\(ij\\) is the sum of the products of elements in the \\(i\\)th row of the first matrix (\\(A\\)) and the corresponding elements in the \\(j\\)th column of the second matrix (\\(B\\)). \\[c_{ij}=\\sum_{k=1}^n a_{ik}b_{kj}\\]\n\n\n\n3.4.5 Example\n\nSuppose a company manufactures two kinds of furniture: chairs and sofas.\n\nA chair costs $100 for wood, $270 for cloth, and $130 for feathers.\nEach sofa costs $150 for wood, $420 for cloth, and $195 for feathers.\n\n\n\n\n\n\nChair\nSofa\n\n\n\n\nWood\n100\n150\n\n\nCloth\n270\n420\n\n\nFeathers\n130\n195\n\n\n\n\nThe same information about unit cost (\\(C\\)) can be presented as a matrix.\n\n\\[C = \\begin{bmatrix}\n100 & 150\\\\\n270 & 420\\\\\n130 & 195\n\\end{bmatrix}\\]\n\n\n\n\n\n\nNote\n\n\n\nNote that each of the three rows of this 3 x 2 matrix represents a material (wood, cloth, or feathers), and each of the two columns represents a product (chair or coach). The elements are the unit cost (in USD).\n\n\n\n\nNow, suppose that the company will produce 45 chairs and 30 sofas this month.\nThis production quantity can be represented in the following table, and also as a 2 x 1 matrix (\\(Q\\)).\n\n\n\n\nProduct\nQuantity\n\n\n\n\nChair\n45\n\n\nSofa\n30\n\n\n\n\\[Q = \\begin{bmatrix}\n45 \\\\\n30\n\\end{bmatrix}\\]\n\nThe “total expenditure” is equal to the “unit cost” times the “production quantity” (the number of units).\nThe total expenditure (\\(E\\)) for each material this month is calculated by multiplying these two matrices.\n\n\\[\\begin{aligned} E = CQ =\n\\begin{bmatrix}\n100 & 150\\\\\n270 & 420\\\\\n130 & 195\n\\end{bmatrix}\n\\begin{bmatrix}\n45 \\\\\n30\n\\end{bmatrix} =\n\\begin{bmatrix}\n(100)(45) + (150)(30) \\\\\n(270)(45) + (420)(30) \\\\\n(130)(45) + (195)(30)\n\\end{bmatrix} =\n\\begin{bmatrix}\n9,000 \\\\\n24,750 \\\\\n11,700\n\\end{bmatrix}\n\\end{aligned}\\]\n\nMultiplying the 3 x 2 Cost matrix (\\(C\\)) times the 2 x 1 Quantity matrix (\\(Q\\)) yields the 3 x 1 Expenditure matrix (\\(E\\)).\nAs a result of this matrix multiplication, we determine that this month the company will incur expenditures of:\n\n$9,000 for wood\n$24,750 for cloth\n$11,700 for feathers.\n\n\n\n\n3.4.6 Properties\n\nAddition and subtraction:\n\nAssociative: \\((A \\pm B) \\pm C = A \\pm (B \\pm C)\\)\nCommunicative: \\(A \\pm B = B \\pm A\\)\n\nMultiplication:\n\n\\(AB \\neq BA\\)\n\\(A(BC) = (AB)C\\)\n\\(A(B+C) = AB + AC\\)\n\\((A+B)C = AC + BC\\)"
  },
  {
    "objectID": "03_matrices.html#special-matrices",
    "href": "03_matrices.html#special-matrices",
    "title": "3  Matrices",
    "section": "3.5 Special matrices",
    "text": "3.5 Special matrices\nSquare matrix:\n\nThe diagonal of a square matrix is a set of numbers consisting of the elements on the line from the upper-left-hand to the lower-right-hand corner of the matrix. Only a square matrix has a diagonal.\nThe trace of a matrix is simply the sum of the diagonal elements of the matrix. So, then, a matrix must be square to have a trace.\n\nDiagonal matrix:\n\nIn a diagonal matrix, all of the elements of the matrix that are not on the diagonal are equal to zero.\n\nScalar matrix:\n\nA scalar matrix is a diagonal matrix where the diagonal elements are all equal to each other. In other words, we’re really only concerned with one scalar (or element) held in the diagonal.\n\nIdentity matrix:\n\nThe identity matrix is a scalar matrix with all of the diagonal elements equal to one.\nAll of the off-diagonal elements are equal to zero.\nThe capital letter I is reserved for the identity matrix."
  },
  {
    "objectID": "03_matrices.html#transpose",
    "href": "03_matrices.html#transpose",
    "title": "3  Matrices",
    "section": "3.6 Transpose",
    "text": "3.6 Transpose\n\nThe transpose is the original matrix with the rows and the columns interchanged.\nThe notation is either \\(J'\\) (“J prime”) or \\(J^T\\) (“J transpose”).\n\n\\[J =\n\\begin{bmatrix}\n4 & 5\\\\\n3 & 0\\\\\n7 & -2\n\\end{bmatrix}\\]\n\\[J' = J^T =\n\\begin{bmatrix}\n4 & 3 & 7 \\\\\n5 & 0 & -2\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "03_matrices.html#inverse",
    "href": "03_matrices.html#inverse",
    "title": "3  Matrices",
    "section": "3.7 Inverse",
    "text": "3.7 Inverse\n\nJust like a number has a reciprocal, a matrix has an inverse.\nWhen we multiply a matrix by its inverse we get the identity matrix (which is like “1” for matrices).\n\n\\[A × A^{-1} = I\\]\n\nThe inverse of A is A-1 only when:\n\n\\[AA^{-1} = A^{-1}A = I\\]\n\nSometimes there is no inverse at all.\nFor now, don’t worry about calculating the inverse of a matrix manually. This is the type of task we use RStudio for.\n\n\n3.7.1 RStudio example\n\n# Create 3 different vectors\n# using combine method.\na1 &lt;- c(3, 2, 5)\na2 &lt;- c(2, 3, 2)\na3 &lt;- c(5, 2, 4)\n  \n# bind the three vectors into a matrix \n# using rbind() which is basically\n# row-wise binding.\nA &lt;- rbind(a1, a2, a3)\n  \n# print the original matrix\nprint(A)\n\n   [,1] [,2] [,3]\na1    3    2    5\na2    2    3    2\na3    5    2    4\n\n# Use the solve() function to calculate the inverse.\nT1 &lt;- solve(A)\n  \n# print the inverse of the matrix\nprint(T1)\n\n              a1          a2         a3\n[1,] -0.29629630 -0.07407407  0.4074074\n[2,] -0.07407407  0.48148148 -0.1481481\n[3,]  0.40740741 -0.14814815 -0.1851852"
  },
  {
    "objectID": "05_functions.html#basics",
    "href": "05_functions.html#basics",
    "title": "5  Functions and loops",
    "section": "5.1 Basics",
    "text": "5.1 Basics\n\n5.1.1 What is a function?\n\nAnything that takes input(s) and gives one defined output.\nThey assign a unique value in its range (\\(y\\) values) for each value in its domain ( \\(x\\) values).\nIn math, this usually looks something like \\(f(x) = 3x + 4\\).\n\n\\(x\\) is the argument that the function takes.\nFor any \\(x\\), multiply \\(x\\) by 3 and then add 4\nAlternative but equivalent notation: \\(y = 3x + 4\\)\n\\(y\\) is “a function of” \\(x\\), so \\(y\\) = \\(f(x)\\)\n\nWe describe functions with both equations and graphs.\n\n\n\n5.1.2 Function machine\n\n\n\n5.1.3 Visualization\nWhen graphed, we can’t draw vertical line through a function. Why not?"
  },
  {
    "objectID": "05_functions.html#types-of-functions",
    "href": "05_functions.html#types-of-functions",
    "title": "5  Functions and loops",
    "section": "5.2 Types of functions",
    "text": "5.2 Types of functions\n\n5.2.1 Linear functions\n\nWe can easily make a function that describes a line.\n\n\\[y=mx+b\\] - \\(m\\) is the slope (for every one unit increase in \\(x\\), \\(y\\) increases \\(m\\) units).\n\n\\(b\\) is the y-intercept: the value of \\(y\\) when \\(x=0\\).\nMore generally, \\(y=a+bx\\) - \\(a\\) is the intercept and \\(b\\) is the slope.\n\n\n\n5.2.2 Quadratic\n\nThese lines have one curve. \\[y=ax^2 + bx + c\\]\n\\(a\\), \\(b\\), and \\(c\\) don’t have well-defined meanings here.\nIf \\(a\\) is negative, the function opens downward; if \\(a\\) is positive,it opens upward.\nNote that \\(x^2\\) always returns positive values.\n\n\n\n\n\n\n\n\n\n5.2.3 Cubic\n\nThese lines (generally) have two curves (inflection points).\n\\(y=ax^3 + bx^2 + cx +d\\)\n\\(a\\), \\(b\\), \\(c\\), and \\(d\\) don’t have well-defined meanings here.\n\n\n\n\n\n\n\n\n\n5.2.4 Polynomial\n\\[y=ax^n + bx^{n-1} + ... + c\\] - These functions have (maximum) \\(n-1\\) changes in direction (turning points). - They also have (maximum) \\(n\\) x-intercepts. - They can be made arbitrarily precise.\n\n\n5.2.5 Exponential\n\\[y = ab^{x}\\] or \\[f(x)=ab^x\\]\n\nHere our independent variable, or input (\\(x\\)), is the exponent.\n\n\n\n5.2.6 Trigonometric functions\n\nThese functions include sine, cosine, and tangent.\nThey are interesting (to some), but not usually useful for social science."
  },
  {
    "objectID": "05_functions.html#logarithms-and-exponents",
    "href": "05_functions.html#logarithms-and-exponents",
    "title": "5  Functions and loops",
    "section": "5.3 Logarithms and exponents",
    "text": "5.3 Logarithms and exponents\n\n5.3.1 Logarithms\n\nLogarithms are basically the opposite (inverse) of exponents.\nThey ask how many times you must raise the base to get \\(x\\).\n\\(log_a(b)=x\\) is asking “a raised to what power x gives b?\n\\(\\log_3(81) = 4\\) because \\(3^4=81\\)\nLogarithms can be undefined.\nThe base cannot be 0, 1, or negative.\n\n\n\n5.3.2 Relationships\nIf, \\[ log_ax=b\\] then, \\[a^{log_{a}x}=a^b\\] and \\[x=a^b\\]\n\n\n5.3.3 Basic rules\n\\[\\dfrac{\\log_x n}{\\log_x m} = \\log_m n\\]\n\\[\\log_x(ab) = \\log_xa + \\log_xb \\]\n\\[\\log_x\\left(\\frac{a}{b}\\right) = \\log_xa - \\log_xb\\]\n\\[\\log_xa^b = b \\log_x a\\]\n\\[\\log_x 1 = 0\\]\n\\[log_{x}x=1\\]\n\\[m^{\\log_m(a)} = a\\]\n\n\n5.3.4 Natural logarithms\n\nWe most often use natural logarithms.\nThis means log\\(_e(x)\\), often written ln\\((x)\\).\n\\(e \\approx 2.7183\\).\nln(x) and its exponent opposite, \\(e^x\\), have nice properties when we hit calculus.\n\n\n\n5.3.5 Definition of e\n\nImagine you invest $1 in a bank and receive 100% interest for one year, and the bank pays you back once a year: \\[(1+1)^1= 2\\]\nWhen it pays you twice a year with compound interest:\n\n\\[(1+1/2)^2=2.25\\]\n\nIf it pays you three times a year:\n\n\\[(1+1/3)^3=2.37...\\]\n\nWhat will happen when the bank pays you once a month? Once a day?\n\n\n\\[(1+\\frac{1}{n})^{n}\\]\n\nHowever, there is limit to what you can get\n\n\\[\\lim_{n\\to\\infty} (1 + \\dfrac{1}{n})^n = 2.7183... = e\\]\n\nFor any interest rate \\(k\\) and number of times the bank pays you \\(t\\): \\[\\lim_{n\\to\\infty} (1 + \\dfrac{k}{n})^{nt} = e^{kt}\\]\n\\(e\\) is important for defining exponential growth. Since \\(ln(e^x) = x\\), the natural logarithm helps us turn exponential functions into linear ones.\n\n\nPractice\nSolve the problems below, simplifying as much as you can. \\[log_{10}(1000)\\] \\[log_2(\\dfrac{8}{32})\\] \\[10^{log_{10}(300)}\\] \\[ln(1)\\] \\[ln(e^2)\\] \\[ln(5e)\\]"
  },
  {
    "objectID": "05_functions.html#functions-of-functions",
    "href": "05_functions.html#functions-of-functions",
    "title": "5  Functions and loops",
    "section": "5.4 Functions of functions",
    "text": "5.4 Functions of functions\n\n5.4.1 Basics\n\nFunctions can take other functions as arguments.\nThis means that outside function takes output of inside function as its input.\nThis is typically written as \\(f(g(x))\\).\nSay we have the exterior function f(x)=\\(x^2\\) and the interior function g(x)=\\(x-3\\).\nThen if we want f(g(x)), we would subtract 3 from any input, and then square the result.\nWe write this \\((x-3)^2\\), NOT \\(x^2-3\\).\n\n\n\n5.4.2 PMF, PDF, and CDF\n\nPMF - probability mass function\n\nThis gives the probability that a discrete random variable is exactly equal to some value.\n\nPDF - probability density function\n\nThis gives the probability that a continuous random variable falls within a particular range of values.\n\nCDF - cumulative distribution function\n\nThis gives the probability that a random variable X takes a value less than or equal to \\(x\\)."
  },
  {
    "objectID": "06_calculus.html#theory",
    "href": "06_calculus.html#theory",
    "title": "6  Calculus",
    "section": "6.1 Theory",
    "text": "6.1 Theory\n\nCalculus is about dealing with infinitesimal values.\nWe are going to focus on two big ideas:\n\nDerivatives\nIntegrals\n\n\n\n6.1.1 Derviative\n\n“Derivative” is just a fancy term for slope.\nSlope is the rate of change \\(\\frac{\\delta y}{\\delta x}\\) or \\(\\frac{d y}{d x}\\).\nSpecifically, the derivative is the instantaneous rate of change.\nWe need slope for our statistics, which are all about fitting lines.\nWe also need slope for taking maxima and minima.\nThe equation for a line is \\(y = mx + b\\). What is its slope?\n\n\n\n6.1.2 Calculating derivatives\n\nSlope is rise over run, which is \\(\\dfrac{f(x+\\Delta x)-f(x)}{\\Delta x}\\)\nTo see why, consider the slope of a line connecting two points: \\[m = \\displaystyle\\frac{f(x_2) - f(x_1)}{x_2-x_1}\\]\nWe can define \\(x_2 = x_1 + \\Delta x\\) (or equivalently \\(\\Delta x = x_2 - x_1\\)) \\[m = \\dfrac{f(x_1+ \\Delta x) - f(x_1)}{\\Delta x}\\]\n\n\n\nAs we’ve seen, for a curve, we need to be infinitely close for our line’s defining points, yielding \\[\\lim_{\\Delta x\\to 0} \\frac{f(x+ \\Delta x)-f(x)}{\\Delta x}\\]\nThis gives us this instantaneous slope (rate of change) of a function at every point on its domain. The above equation is the definition of the derivative.\n\n\n\n6.1.3 Notation\n\n\\(\\frac{d}{dx} f(x)\\) is read “The derivative of \\(f\\) of \\(x\\) with respect to \\(x\\).” - You can also say “The instantaneous rate of change in \\(f\\) of \\(x\\) with respect to \\(x\\).”\nIf \\(y=f(x)\\), \\(\\frac{dy}{dx}\\) is “The derivative of \\(y\\) with respect to \\(x\\)”. - Warning: Do not try to cancel out the \\(d\\)’s, no matter how tempting it is.\nThere is the advantage of always specifying the variable with respect to which we’re differentiating (it’s the one in the denominator).\n\n\nLagrange’s prime notation: - \\(f'(x)\\) (read: “\\(f\\) prime \\(x\\)”) is the derivative of \\(f(x)\\). - This is useful when it is clear which variable were are referring to (e.g., when there’s only one).\n\n\nWhat is \\(\\dfrac{d(x^2)}{dx}\\)? - \\(x^2\\) - \\(2 x^{2-1}\\) -\\(2x\\)\nWhat is \\(\\frac{d(4x^3)}{dx}\\)?\n\n\\(4x^3\\)\n\\(4*3 x^{3-1}\\)\n\\(12x^2\\)\n\n\n\nPractice\nTake the derivative of each of these. \\[x^3\\] \\[3x^2\\] \\[60x^{11}\\] \\[x\\] \\[\\frac{4}{x^2} \\] \\[9 \\sqrt{x}\\] \\[6 x^{5/2}\\] \\[11,596,232\\]\n\nEvaluate the derivatives at \\(x=2\\) and \\(x=-1\\) \\[x^3\\] \\[3x^2\\] \\[60x^{11}\\] \\[x\\] \\[\\frac{4}{x^2} \\] \\[9 \\sqrt{x}\\] \\[6 x^{5/2}\\] \\[11,596,232\\]\n\nPractice\nTake the derivative of each of these. \\[x^3\\] \\[3x^2\\] \\[60x^{11}\\] \\[x\\] \\[\\frac{4}{x^2} \\] \\[9 \\sqrt{x}\\] \\[6 x^{5/2}\\] \\[11,596,232\\]\n\nEvaluate the derivatives at \\(x=2\\) and \\(x=-1\\) \\[x^3\\] \\[3x^2\\] \\[60x^{11}\\] \\[x\\] \\[\\frac{4}{x^2} \\] \\[9 \\sqrt{x}\\] \\[6 x^{5/2}\\] \\[11,596,232\\]\n\n\n\n6.1.4 Special functions\nA few functions have particular rules:\n\n\\(\\frac{d (ln(x))}{dx}=\\frac{1}{x}\\)\n\\(\\dfrac{d (log_b(x))}{dx}=\\dfrac{1}{x*ln(b)}\\)\n\\(\\frac{d (e^x)}{dx}=e^x\\)\n\\(\\frac{d (a^x)}{dx}=a^x ln(a)\\)\n\\(\\frac{dy}{dx}c=0\\)\n\\(\\frac{d (x^x)}{dx}=x^x (1+ln(x))\\)\n\n\n\n6.1.5 Derivatives with addition and substraction\n\nEasiest rule to remember: \\[\\frac{d (f(x) \\pm g(x))}{dx}=f'(x) \\pm g'(x)\\]\n\n\nPractice\nTake the derivative of each of these \\[x^2 + x +5\\] \\[x^4 - 4x^3 + 5x^2 + 8x - 6\\] \\[3x^5 - 6x^2\\] \\[5x^2 + 8 \\sqrt{x} - \\frac{1}{x}\\] \\[ln(x) + 5e^x - 4x^3\\]"
  },
  {
    "objectID": "06_calculus.html#advanced-rules",
    "href": "06_calculus.html#advanced-rules",
    "title": "6  Calculus",
    "section": "6.2 Advanced rules",
    "text": "6.2 Advanced rules\n\n6.2.1 Product rule\n\nA little more complicated: \\[\\frac{d (f(x) \\times g(x))}{dx}=f'(x)g(x) + g'(x)f(x)\\]\nExample: \\(2x \\times 3x\\)\n\n\nPractice\nTake the derivative of each of these: \\[x^3 * x\\] \\[e^x * x^2\\] \\[ln(x) * x^{-3}\\]\nRemember, \\(\\frac{d (f(x) * g(x))}{dx}=f'(x)g(x) + g'(x)f(x)\\).\n\n\n6.2.2 Quotient rule\n\\[\\frac{d \\frac{f(x)}{g(x)}}{dx}=\\frac{f'(x)g(x) - g'(x)f(x)}{[g(x)]^2}\\] If you’re having trouble with this, just apply the product rule to: \\[\\frac{d[f(x)*g^{-1}(x)]}{dx}\\]\nRemember, \\(\\frac{d \\frac{f(x)}{g(x)}}{dx}=\\frac{f'(x)g(x) - g'(x)f(x)}{[g(x)]^2}\\).\n\n\n6.2.3 Chain rule\n\\[\\frac{d [f(g(x))]}{dx}=f'(g(x)) * g'(x)\\]\nLet’s take the derivative of a function of a function: \\[\\frac{d[ln(x^2)]}{dx}\\] \\[f(x)=ln(x), g(x)=\\color{red}{x^2}\\] \\[f'(x)=\\color{blue}{\\frac{1}{x}}\\color{black}{, g'(x)=2x}\\] \\[ \\frac{\\color{blue}{1}}{\\color{red}{x^2}}*2x = \\frac{2}{x}\\]\n\nPractice\nTake the derivative of each of these: \\[ (3x^4-8)^2 \\] \\[e^{x^2}\\] Remember, \\(\\frac{d (f(g(x))}{dx}=f'(g(x)) * g'(x)\\).\n\n\n6.2.4 Second derivative\n\nSame process as taking single derivative, except input for second derivative is output from first.\nSecond derivative tells us whether the slope of a function is increasing, decreasing, or staying the same at any point \\(x\\) on the function’s domain.\nExample: driving a car.\n\n\\(f(x)\\) = distance traveled at time \\(x\\)\n\\(f'(x)\\) = speed at time \\(x\\)\n\\(f''(x)\\) = acceleration at time \\(x\\)\n\n\n\nGraph \\(f(x) = x^2\\), \\(f'(x)\\), and \\(f''(x)\\).\n\n\\[\\frac{d^2(x^4)}{dx^2}=f''(x^4)\\] - First, we take the first derivative: \\[f'(x^4)=4x^3\\] - Then we use that output to take the second derivative: \\[f''(x^4)=f'(4x^3)=12x^2\\]\nPractice\nTake the second derivative of the following functions: \\[x^5\\] \\[6x^2\\] \\[4 ln(x)\\] \\[3x\\] \\[4x^{3/2}\\]"
  },
  {
    "objectID": "06_calculus.html#differentiable-and-continuous-functions",
    "href": "06_calculus.html#differentiable-and-continuous-functions",
    "title": "6  Calculus",
    "section": "6.3 Differentiable and Continuous Functions",
    "text": "6.3 Differentiable and Continuous Functions\n\nInformally: A function is continuous at a point if its graph has no holes or breaks at that point\nFormally: A function is continuous at a point \\(a\\) if: \\[\\displaystyle\\lim_{x \\to a} f(x)=f(a)\\]\n\n\nContinuity requires 3 conditions to hold:\n\n\\(f(a)\\) is defined (\\(a\\) is in the domain of \\(f\\))\n\\(\\displaystyle\\lim_{x \\to a} f(x)\\) exists\n\\(\\displaystyle\\lim_{x \\to a} f(x) = f(a)\\) (the value of \\(f\\) equals the limit of \\(f\\) at \\(a\\))\n\n\nDifferentiable:\n\nIf \\(f'(x)\\) exists, \\(f\\) is differentiable at \\(x\\).\nIf \\(f\\) is differentiable at every point of an open interval \\(I\\), \\(f\\) is differentiable on \\(I\\).\nGraph must have a (non-vertical) tangent line at each point, be relatively smooth, and not contain any breaks, bends, or cusps.\n\n\n\nIf a function is differentiable at a point, it is also continuous at that point.\nIf a function is continuous at a point, it is not necessarily differentiable at that point.\n\n\n6.3.1 When is f not differentiable?\nWhen does \\(f'(x)\\) not exist?\n\nWhen the function is discontinuous at that point.\n\nJump or break in the graph.\n\nThere are different slopes approaching the point from the left and from the right.\n\nCorner point\n\nWhen the graph of the function has a vertical tangent line at that point.\n\nCusp\nVertical inflection point"
  },
  {
    "objectID": "06_calculus.html#extrema-and-optimization",
    "href": "06_calculus.html#extrema-and-optimization",
    "title": "6  Calculus",
    "section": "6.4 Extrema and optimization",
    "text": "6.4 Extrema and optimization\nOptimization lets us find the minimum or maximum value a function takes.\n\nFormal theory\n\nUtility maximization, continuous choices\n\nOrdinary Least Squares (OLS)\n\nFocuses on minimizing the squared errors between observed data and values predicted by a regression\n\nMaximum Likelihood Estimation (MLE)\n\nFocuses on maximizing a likelihood function, given observed values\n\n\n\n6.4.1 Extrema\nInformally, a maximum is just the highest value a function takes, and a minimum is the lowest value.\n\nEasy to identify extrema (maxima or minima) intuitively by looking at a graph of the function.\n\nMaxima are high points (“peaks”)\nMinima are low points (“valleys”)\n\nExtrema can be local or global.\n\n\n\n6.4.2 Identifying extrema\nThe derivative of a function gives the rate of change. - When the derivative is zero (or fails to exist), the function has usually reached a (local) maximum or minimum.\n\nWhy?\n\n\nAt a maximum, the function must be increasing before the point and decreasing after it.\nAt a minimum, the function must be decreasing before the point and increasing after it.\nSo we’ll start by identifying points where this is the case (“critical points” or “stationary points”).\n\nA technical note:\nA point where \\(f'(x)=0\\) or \\(f'(x)\\) does not exist is called a critical point (or stationary point). Local extrema occur at critical points, but not all critical points are extrema. For instance, sometimes the graph is changing between concave and convex (“inflection points”). Sometimes the function is not differentiable at that point for other reasons, as discussed earlier.\n\nSo we can find the local maxima and/or minima of a function by taking the derivative, setting it equal to zero, and solving for x (or whatever).\n\\[f'(x)=0\\]\nThis gives us the first-order condition (FOC).\n\n\n6.4.3 Minimum or maximum?\nBUT we don’t know if we’ve found a maximum or minimum, or even if we’ve found an extremum or just an inflection point.\n\n\n6.4.4 Second derivatives\nThe second derivative gives us the rate of change of the rate of change of the original function. So it tells us whether the slope is getting larger or smaller.\n\\[f(x) = x^2\\] \\[f'(x) = 2x\\] \\[f''(x) = 2\\]\n\nSecond Derivative Test - Start by identifying \\(f''(x)\\)\n\nSubstitute in the stationary points \\((x^*)\\) identified from the FOC\n\\(f''(x^*) &gt; 0\\) we have a local minimum\n\\(f''(x^*) &lt; 0\\) we have a local maximum\n\\(f''(x^*) = 0\\) we (may) have an inflection point - need to calculate higher-order derivatives (don’t worry about this now)\n\nCollectively these give use the Second-Order Condition (SOC).\n\n\n6.4.5 Local vs. Global Extrema\nTo find the minimum/maximum on some interval, compare the local min/max to the value of the function at the interval’s endpoints.\n\nTo find the global minimum/maximum, check the function’s limits as it approaches \\(+ \\infty\\) and \\(- \\infty\\).\nExtreme value theorem: if a real-valued function \\(f\\) is continuous on the closed interval [a,b], then \\(f\\) must attain a (global) maximum and a (global) minimum."
  },
  {
    "objectID": "06_calculus.html#partial-derivatives",
    "href": "06_calculus.html#partial-derivatives",
    "title": "6  Calculus",
    "section": "6.5 Partial derivatives",
    "text": "6.5 Partial derivatives\n\nCan take derivative with respect to different variables\nNotation: For a function \\(fy=(x,z)=xz\\), we might want to know how the function changes with \\(x\\):\n\n\\[ \\displaystyle\\frac{\\partial}{\\partial_x}f(x,y) = \\frac{\\partial_y}{\\partial_x} = \\partial_x f\\]\n\nTreat all other variables as constants and take derivative with respect to the variable of interest (here \\(x\\)).\n\n\nHow do we take a partial derivative?\nTreat all other variables as constants and take derivative with respect to the variable of interest.\nFrom our earlier example: \\[y = f(x,z) = xz \\] \\[ \\displaystyle\\frac{\\partial_y}{\\partial_x} = ?\\]\n\n\\[y = f(x,z) = xz \\] \\[ \\displaystyle\\frac{\\partial_y}{\\partial_x} = z\\]\nWhy? Because the partial derivative of \\(xz\\) with respect to \\(x\\) treats \\(z\\) as a constant.\nWhat is \\(\\displaystyle\\frac{\\partial_y}{\\partial_z}?\\)\n\n6.5.1 Application\n\n\\(\\frac{\\partial (x^2y+xy^2-x)}{\\partial x}\\)\nWe apply the addition rule to take the derivative of each term with respect to x.\n\\(\\frac{\\partial (x^2y)}{\\partial x}\\)+\\(\\frac{\\partial (xy^2)}{\\partial x}\\)+\\(\\frac{\\partial (-x)}{\\partial x}\\)\n\\(2xy+y^2-1\\)\n\n\n\n\\(\\frac{\\partial (x^2y+xy^2-x)}{\\partial y}\\)\nWe apply the addition rule to take the derivative of each term with respect to y\n\\(\\frac{\\partial (x^2y)}{\\partial y}\\)+\\(\\frac{\\partial (xy^2)}{\\partial y}\\)+\\(\\frac{\\partial (-x)}{\\partial y}\\)\n\\(x^2+2xy\\)\n\n\nPractice\nTake the partial derivative with respect to x and to y of the following functions. What would the notation for each look like?\n\\[3xy-x\\] \\[ln(xy)\\] \\[x^3+y^3+x^4y^4\\] \\[e^{xy}\\]"
  },
  {
    "objectID": "06_calculus.html#integrals",
    "href": "06_calculus.html#integrals",
    "title": "6  Calculus",
    "section": "6.6 Integrals",
    "text": "6.6 Integrals\n\n6.6.1 Area under a curve\nOften we want to find the area under a curve. - Net effect of change - Cumulative density functions (CDFs) - Expected values and utilities\nSometimes this is easy. What’s the area under the curve between \\(x=-1\\) and \\(x=1\\) for this function? \\[f(x) =\n\\begin{cases}\n\\frac{1}{3} & \\text{for } x \\in [0, 3] \\\\\n0 & \\text{otherwise}\n\\end{cases}\\]\nHint: We can draw this and look at the graph. Remember \\(Area = \\ell*w\\)\n\nSometimes (usually) finding the area under a curve is harder. But this is basically the question behind integration.\n\n\n6.6.2 Integrals as summation\nYou’re familiar with summation notation.\n\\[\\displaystyle\\sum_{i=1}^{n} i\\]\nBut this only works when we have discrete values to add. When we need to add continuously, we have to use something else. Specifically, integrals.\n\n\n6.6.3 Definite integrals\nLet’s say we have a function \\[ y = x^2 \\] And we want to find the area under the curve from \\(x=0\\) to \\(x=1\\). To find the area we’re interested in here, we can use the definite integral.\nGenerally speaking, the notation looks like this:\n\\[\\displaystyle\\int_{x=a}^{b} f(x),dx\\]\nHere \\(a\\) is the lower limit of integration, \\(b\\) is the upper limit of integration, our function \\(f(x)\\) is our integrand, and \\(x\\) is our variable of integration.\n\nFor our question, we’re looking for \\[\\displaystyle\\int_{x=0}^{1} f(x) dx\\]\nWhich will give us a real number denoting the area under the curve of our function (\\(y=x^2\\)) between \\(x=0\\) and \\(x=1\\).\n\nIf \\(f\\) is continuous on \\([a,b]\\) or bounded on \\([a,b]\\) with a finite number of discontinuities, then \\(f\\) is integrable on \\([a,b]\\).\n\n\n6.6.4 Indefinite integrals\nThe indefinite integral, or anti-derivative, \\(F(x)\\) is the inverse of the function \\(f'(x)\\). \\[F(x)= \\displaystyle\\int f(x) \\text{ } dx\\] This means if you take the derivative of \\(F(x)\\), you wind up back at \\(f(x)\\). \\[F' = f \\text{ or } \\displaystyle\\frac{dF(x)}{dx} = f(x)\\]\nThis process is called anti-differentiation, or indefinite integration.\n\nWhile the definite integral gives us a real number (the total area under a curve), the indefinite integral gives us a function.\nWe need the concept of indefinite integrals to help us solve definite integrals.\n\n\n6.6.5 Solving definite integrals\n\\[\\displaystyle\\int_{a}^{b} f(x) \\text{ } dx = F(b)-F(a) = F(x)\\bigg|_{a}^{b}\\] ### Constant of integraton\nA quick note:\n\\(C\\) in the following slides is the called the “constant of integration.” We need to add it when we define all antiderivatives (integrals) of a function because the anti-derivative “undoes” the derivative.\nRemember that the derivative of any constant is zero. So if we find an integral \\(F(x)\\) whose derivative is \\(f(x)\\), adding (or subtracting) any constant will give us another integral \\(F(x)+C\\) whose derivative is also \\(f(x)\\).\n\n\n6.6.6 Rules of integration\n\\[ \\displaystyle\\int_{a}^{a}f(x) \\text{ }dx = 0\\]\n\\[\\displaystyle\\int_{a}^{b} f(x) \\text{ } dx = -\\displaystyle\\int_{b}^{a}f(x)dx\\]\n\\[\\int a \\text{ }dx = ax + C \\text { where $a$ is a constant}\\]\n\\[\\displaystyle\\int af(x)dx = a\\displaystyle\\int f(x) \\text{ }dx \\text{ where $a$ is a constant}\\]\n\n\n6.6.7 More rules\n\\[\\int (f(x) + g(x)) \\text{ } dx = \\int f(x) dx + \\int g(x)dx\\]\n\\[\\int x^n dx = \\frac{x^{n+1}}{n+1} + C \\qquad \\forall n \\neq -1\\]\n\\[\\int x^{-1}dx = \\ln |x| + C\\]\n\n\n6.6.8 Solving the problem\nRemember our function \\(y=x^2\\) and our goal of finding the area under the curve from \\(x=0\\) to \\(x=1\\).\n\nFind the indefinite integral, \\(F(x)\\)\n\n\\(\\displaystyle\\int x^2 \\text{ } dx\\)\n\\(\\displaystyle\\frac{x^3}{3}+C\\)\n\n\n\n\nEvaluate at our lowest and highest points, \\(F(0)\\) and \\(F(1)\\).\n\n\\(F(0) = 0\\)\n\\(F(1) = \\displaystyle\\frac{1}{3}\\)\nTechnically \\(0 + C\\) and \\(\\displaystyle\\frac{1}{3} + C\\), but the C’s will fall out in the next step\n\nCalculate \\(F(1) - F(0)\\)\n\n\\(\\displaystyle\\frac{1}{3} - 0 = \\displaystyle\\frac{1}{3}\\)\n\n\n\nPractice — indefinite integrals\n\\[\\int x^2 \\text{ } dx\\] \\[\\int 3x^2\\text{ } dx\\] \\[\\int x\\text{ } dx\\] \\[\\int 3x^2 + 2x - 7\\text{ }dx\\] \\[\\int \\dfrac{2}{x}\\text{ }dx\\]\n\nPractice — definite integrals\n\\[\\displaystyle\\int_{1}^{7} x^2 \\text{ } dx\\] \\[\\displaystyle\\int_{1}^{10} 3x^2 \\text{ } dx\\] \\[\\int_7^7 x\\text{ } dx\\] \\[\\displaystyle\\int_{1}^{5} 3x^2 + 2x - 7\\text{ }dx\\] \\[\\int_{1}^{e} \\dfrac{2}{x}\\text{ }dx\\]\n\n\n6.6.9 Integration by parts\n\nWhat if we want to integrate the product of two functions? How to evaluate \\(\\displaystyle\\int [f(x)g(x)]dx\\)?\nThere’s a formula for that: integration by parts.\nWe can derive the formula from the product rule for derivatives, which you already know.\n\n\n\\[\\dfrac{d(f(x)g(x))}{d(x)} = f^{'}(x)g(x) + g^{'}(x)f(x)\\]\n\\[\\displaystyle\\int \\dfrac{d(f(x)g(x))}{d(x)} dx= \\displaystyle\\int [f^{'}(x)g(x) + g^{'}(x)f(x)]dx\\]\n\\[f(x)g(x) = \\displaystyle\\int f^{'}(x)g(x)dx + \\displaystyle\\int g^{'}(x)f(x)dx\\]\n\n\nNote that we can’t just plug in our two original functions into this formula. We have some work to do first.\nBoard example: \\[\\int x \\sqrt{x}dx\\]"
  },
  {
    "objectID": "07_probability.html#what-is-probability",
    "href": "07_probability.html#what-is-probability",
    "title": "7  Probability",
    "section": "7.1 What is probability?",
    "text": "7.1 What is probability?\n\nFrequency with which an event occurs.\n\nTypically: \\[Pr(A) = P(A) = \\pi(A) = \\dfrac{\\text{Number of ways an event can occur}}{\\text{Total number of possible outcomes}}\\]\n\nProbability predicts real-world events using theoretical quantities.\n\nFormally, it assigns a likelihood of occurrence to each event in sample space\nWe use the probability space triplet (\\(\\Omega, S, P\\)), which are the sample space, event space, and probability mapping, respectively.\n\nWe can consider probability as a function that maps \\(\\Omega \\to \\mathbb{R}\\).\nWe can conceive it in terms of relative frequency or subjective belief."
  },
  {
    "objectID": "07_probability.html#kolmogorovs-axioms",
    "href": "07_probability.html#kolmogorovs-axioms",
    "title": "7  Probability",
    "section": "7.2 Kolmogorov’s axioms",
    "text": "7.2 Kolmogorov’s axioms\n\n\\(Pr(S_i)\\in\\mathbb{R},\\hspace{2mm} 1 \\geq Pr(S_i)\\geq 0 \\qquad \\forall S_i\\in S\\)\n\nWhere \\(S\\) is the event space, \\(S_i\\) are events.\nProbabilities must be non-negative.\n\n\\(Pr(\\Omega) = 1\\)\n\nWhere \\(\\Omega\\) is the sample space.\nSomething has to happen.\nProbabilities sum/integrate to 1.\n\n\\(Pr\\left(\\bigcup_{i = 1}^\\infty S_i\\right) = \\sum_{i=1}^\\infty Pr(S_i) \\iff Pr(S_i \\cap S_j) = 0\\hspace{2mm} \\forall i\\neq j\\)\n\nThe probability of disjoint (mutually exclusive) sets is equal to the sum of their individual probabilities."
  },
  {
    "objectID": "07_probability.html#some-definitions",
    "href": "07_probability.html#some-definitions",
    "title": "7  Probability",
    "section": "7.3 Some definitions",
    "text": "7.3 Some definitions\n\nRandom variable: a variable whose value is determined by the outcome of a random process.\n\nSometimes also called a stochastic variable.\nMay be discrete or continuous.\n\nDistribution (of a random variable): the set of values the variable might take.\n\nProbability mass function / probability density function defines the probability with which each value occurs.\nAlways sums / integrates to 1.\n\nRealization (of a random variable): a particular value taken by the variable.\n\n\n\nPopulation: the entire set of objects (people, cases, etc.) in which we are interested.\n\nOften denoted \\(N\\).\n\nSample: a subset of the population we can observe, from which we try to make generalizations about the population.\n\nOften denoted \\(n\\).\n\nFrequency distribution: a count of how often a variable takes each of its possible values.\n\nThe number of members of a sample that take each value of a variable.\n\nIndependent random variables: two variables are statistically independent if the value of one does not affect the value of the other.\n\nFormally, \\(Pr(A \\cap B)=Pr(A)Pr(B)\\)"
  },
  {
    "objectID": "07_probability.html#discrete-probability",
    "href": "07_probability.html#discrete-probability",
    "title": "7  Probability",
    "section": "7.4 Discrete probability",
    "text": "7.4 Discrete probability\n\nA sample space in which there are a (finite or infinite) countable number of outcomes\nEach realization of random process has a discrete probability of occurring.\n\n\\(f(X=x_i)=P(X=x_i)\\) is the probability the variable takes the value \\(x_i\\).\n\n\n\n7.4.1 Probability Mass Function (PMF)\nProbability of each occurrence encoded in probability mass function (PMF)\n\n\\(0 \\leq f(x_i) \\leq 1\\)\n\nProbability of any value occurring must be between 0 and 1.\n\n\\(\\displaystyle\\sum_{x}f(x_i) = 1\\)\n\nProbabilities of all values must sum to 1.\n\n\n\n\n7.4.2 Discrete distribution\n\nWhat’s the probability that we’ll roll a 3 on one die roll: \\[Pr(y=3) = \\dfrac{1}{6}\\]\nIf one roll of the die is an “experiment.”\nWe can think of a 3 as a “success.”\n\\(Y \\sim Bernoulli \\left(\\frac{1}{6} \\right)\\)\nFair coins are \\(\\sim Bernoulli(.5)\\), for example.\nMore generally, \\(Bernoulli(\\pi )\\).\n\n\\(\\pi\\) represents the probability of success.\n\n\n\n\nDrawing a specific card from a deck: \\[Pr(y=\\text{ace of spades}) = \\dfrac{1}{52}\\]\nDrawing any card with a specific value from a deck: \\[Pr(y=ace) = \\dfrac{4}{52}\\]\nGetting a specific value on two dice rolls: \\[Pr(y=8) = \\dfrac{5}{36}\\]\nWe can express the probability mass function in tabular format or in a graph."
  },
  {
    "objectID": "07_probability.html#continuous-probability",
    "href": "07_probability.html#continuous-probability",
    "title": "7  Probability",
    "section": "7.5 Continuous probability",
    "text": "7.5 Continuous probability\n\nWhat happens when our outcome is continuous?\nThere are an infinite number of outcomes.\nThis makes the denominator of our fraction difficult to work with.\nThe probability of the whole space must equal 1.\nEven if all events are equally likely, \\(\\dfrac{1}{\\infty} =0\\)\n\n\n7.5.1 Basics\n\nThe domain may not span -\\(\\infty\\) to \\(\\infty\\).\n\nEven space between 0 and 1 is infinite.\n\nThe domain is defined as the area under the probability density function.\nTwo common examples are the uniform and bell curves.\n\n\n\n7.5.2 Probability Density Function (PDF)\n\nSimilar to PMF from before, but for continuous variables.\nGives the probability a value falls within a particular interval\n\n\\(P[a\\le X\\le b] = \\displaystyle\\int_a^b f(x) \\, dx\\)\nTotal area under the curve is 1.\n\\(P(a &lt; X &lt; b)\\) is the area under the curve between \\(a\\) and \\(b\\) (where \\(b &gt; a\\))."
  },
  {
    "objectID": "07_probability.html#cumulative-density-function-cdf",
    "href": "07_probability.html#cumulative-density-function-cdf",
    "title": "7  Probability",
    "section": "7.6 Cumulative Density Function (CDF)",
    "text": "7.6 Cumulative Density Function (CDF)\n\n7.6.1 Discrete\n\nCumulatve density function is probability X will take a value of x or lower.\nPDF is written \\(f(x)\\), and CDF is written \\(F'(x)\\). \\[F_X(x) = Pr(X\\leq x)\\]\nFor discrete CDFs, that means summing up over all values.\nWhat is the probability of rolling a 6 or lower with two dice? \\(F(6)=?\\)\n\n\n\n7.6.2 Continuous\n\nWe can’t sum probabilities for continuous distributions (remember the 0 problem).\nSolution: integration \\[F_Y(y) = \\int_{-\\infty}^{y} f(y) dy\\]\nExamples of uniform distribution."
  },
  {
    "objectID": "07_probability.html#statistics",
    "href": "07_probability.html#statistics",
    "title": "7  Probability",
    "section": "7.7 Statistics",
    "text": "7.7 Statistics\n\n7.7.1 Introduction\n\nWhile probability allows us to make predictions about events using distributions, statistics uses events to make estimates about distributions and variables.\nIt is the process of learning from data.\nA statistic is a summary of data, capturing some theoretically-relevant quantity.\nBroad categories of numerical and categorical.\n\n\n\n7.7.2 Univariate statistics\n\nThese measure a single variable.\nReadily expressed in graphical form.\nCommon examples:\n\nCentral tendency (mean, median, and mode)\nVariance\n\n\n\n\n7.7.3 Examples of univariate statistics\n\nThe mean (\\(\\bar{x}\\)) is calculated by summing the data, then dividing by the number of observations: \\[\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\\]\nThe median is found by ordering the observations from highest to lowest and finding the one in the middle.\nThe mode is the most common number.\n\n\\[x= \\begin{bmatrix} 1 & 2 & 3 & 4 & 5 & 6 & 6 & 7 & 8 & 9 \\end{bmatrix}\\]\n\nWhat are the mean, median, and mode of x?\n\n\n\n7.7.4 Measures of central tendency\n\nMean balances values on either side.\nMedian balances observations on either side.\nMode finds the most typical observation.\nWhich is the best? Like most of what you’ll learn in statistics, it depends.\n\n\n\n7.7.5 Deviations from central tendency\n\nConsider two data sets: \\[\\begin{aligned}\nx= \\begin{bmatrix} 1 & 1.5 & 2 & 2.5 & 5.5 & 8.5 & 9 & 9.5 & 10 \\end{bmatrix}\n\\end{aligned}\\] \\[\\begin{aligned}\ny= \\begin{bmatrix} 4.5 & 4.8 & 5 & 5.3 & 5.5 & 5.7 & 6 & 6.2 & 6.5 \\end{bmatrix}\n\\end{aligned}\\]\nWhat is the mean of each?\nWhat is the median of each?\nAre they similar distributions?\n\n\n\n7.7.6 Variance\n\nWe use variance to measure the spread of a single variable.\nFormally defined as the squared deviation from the mean (\\(\\mu\\)).\nFor discrete random variables, it is written \\(Var(x)=\\sigma^2=\\displaystyle\\frac{1}{n}\\displaystyle\\sum_{i=1}^n(x_i-\\mu)^2\\)\nFor continuous random variables, it is written \\(Var(x)=\\sigma^2=\\displaystyle\\int (x-\\mu)^2 f(x) \\text{ }dx\\)\n\n\n\n7.7.7 Standard deviation\n\nSometimes variance doesn’t make sense, either mathematically or conceptually.\n\nNot always clear how to interpret “squared deviation from the mean.”\n\nInstead, will frequently see standard deviation, which is square root of variance.\nIt is written \\(\\sigma\\)."
  },
  {
    "objectID": "07_probability.html#bivariate-statistics",
    "href": "07_probability.html#bivariate-statistics",
    "title": "7  Probability",
    "section": "7.8 Bivariate statistics",
    "text": "7.8 Bivariate statistics\n\n7.8.1 Covariance\n\nWhile measures of central tendency and variance/standard deviation provide useful summaries of a single variable, they don’t provide insights into relationships between variables.\nFor that, we need bivariate statistics.\nMost common and straightforward is covariance.\n\n\n\nColloquially, can think of covariance as measure of linear deviation from mean.\nWhen values from one variable are above their mean, are values from the other above or below their mean?\nPut another way, if I told you the value of x was high, would you expect values of y to be high or low?\nFormally, it is written as: \\[cov(X,Y)=E(X-E(X))(Y-E(Y))=E(XY)-E(X)E(Y)\\]\nIt is important to note that the magnitude is meaningless; only the direction is interpretable.\n\n\n\n7.8.2 Correlation\n\nCorrelation is a normalized measure of covariance\nIt is calculated as: \\[\\rho_{X,Y}=\\frac{cov(X,Y)}{\\sigma_X \\sigma_Y}\\]\nIt varies between -1 and 1.\nWhat is correlation of two independent variables?"
  },
  {
    "objectID": "07_probability.html#regression",
    "href": "07_probability.html#regression",
    "title": "7  Probability",
    "section": "7.9 Regression",
    "text": "7.9 Regression\n\n7.9.1 Ordinary least squares\n\nOrdinary least squares regression (OLS) is probably the most widely-used model in political science.\nIt is all about drawing a line through data.\nThis allows us to evaluate the relationship (the association) between \\(x\\) on \\(y\\).\nThe dependent variable, \\(y\\), must be continuous, generally speaking.\nThe main question is which line to draw.\n\n\nLine and equation (\\(\\hat{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1} x_{i}\\)) on board\n\n\n7.9.2 Residuals\n\nIn basically any set of data, no line can pass through every point (observation).\nWe will always have make some error in predicting values.\nThe error between the line and some point is referred to as the residual.\nIf we refer to our predicted value as \\(\\hat{y}\\), then we can calculate the residual for each observation with the following equation: \\[e_i = y_i - \\hat{y}_i\\]\n\n\n\n7.9.3 Finding the right line\n\nOLS determines the “best” line by minimizing the sum of squared residuals.\nPlug in all the values for the slope amd intercept and calculate the sum of squared residuals for these infinity combinations.\nThat is a lot of work.\nThe best solution turns out to be calculus.\nWe want to minimize the sum of squared residuals with respect to our \\(\\beta\\)’s."
  },
  {
    "objectID": "10_wrapup.html#methods-at-ut",
    "href": "10_wrapup.html#methods-at-ut",
    "title": "10  Wrap up",
    "section": "10.1 Methods at UT",
    "text": "10.1 Methods at UT\n\n10.1.1 Required methods courses\n\nScope and Methods of Political Science\n\nStatistics I (Statistics/linear regression)\n\nStatistics II (Linear regression and more)\nStatistics III (Maximum likelihood estimation)\n\nOnly required if your major field is methods\n\n\n\n\n10.1.2 Other methods courses\n\nStatistics/econometrics:\n\nBayesian Statistics\nCausal Inference\nMath Methods for Political Analysis\nTime Series and Panel Data\nPanel and Multilevel Analysis\n\n\n\n\n10.1.3 More courses\n\nFormal Theory\n\nIntro to Formal Political Analysis\nFormal Political Analysis II\nFormal Theories of International Relations\n\nEverything else\n\nConceptualization and Measurement\nExperimental Methods in Political Science\nQualitative Methods\nNetwork Analysis\nSeminar in Field Experiments\n\n\n\n\n10.1.4 Other departments at UT\nYou can also take courses through the Economics, Mathematics, or Statistics (Statistics and Data Science) departments.\n\nM.S. in Statistics\n\nSoftware and Topic Short Courses - R, Python, Stata, etc.\n\nMore info here.\n\n\n\n10.1.5 Other resources\nSummer programs at UT:\n\nShort courses in statistics\n\nDepartment sometimes offers scholarships to cover part of the cost.\n\n\nSummer programs outside UT:\n\nICPSR (Inter-university Consortium for Political and Social Research)\n\nAnn Arbor, Michigan\n\nEITM (Empirical Implications of Theoretical Models)\n\nHouston and other locations (Michigan, Duke, Berkeley, Emory)\n\nIQMR (Institute for Qualitative and Multi-Method Research)\n\nSyracuse, NY"
  }
]