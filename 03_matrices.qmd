# Matrices

## Introduction

### Scalars

-   One number (for example, 12) is referred to as a scalar.

-   Each scalar in a matrix is an *element* of that matrix.

$$\begin{bmatrix}
12
\end{bmatrix}$$

::: callout-note
This is also called a 1 x 1 ("one by one") matrix.
:::

### Vectors

-   We can put several scalars together to make a vector.

-   Here is an example: $$\begin{bmatrix}
        12 \\
        14 \\
        15
        \end{bmatrix}
        = b$$

-   Since this is a column of numbers, we cleverly refer to it as a *column vector*.

-   Here is another example of a vector: $$\begin{bmatrix}
    12 & 14 & 15
    \end{bmatrix}
    = d$$

-   This, in contrast, is called a *row vector*.

#### Vector construction in RStudio

-   Vectors are very easy to construct in RStudio.
-   Here are two examples:

```{r}
# Making a simple column vector
col_vector <- matrix(1:12)
col_vector

# Making a simple row vector
row_vector <- 15:23
row_vector
```

## Operators

### Summation

-   The summation operator $\sum$ lets us perform an operation on a sequence of numbers, which is often but not always a vector.

$$x = \begin{bmatrix}
12 & 7 & -2 & 0 & 1
\end{bmatrix}$$

-   We can then calculate the sum of the first three elements of the vector, which is expressed as follows: $$\sum_{i=1}^3 x_i$$

-   Then, we do the following math: $$12+7+(-2)=17$$

### Product

-   The product operator $\prod$ can also perform operations over a sequence of elements in a vector.

$$z = \begin{bmatrix}
5 & -3 & 5 & 1
\end{bmatrix}$$

-   We can then calculate the calculate the product of the four elements in the vector, which is expressed as follows: $$\prod_{i=1}^4 z_i$$

-   Then, we do the following math: $$5 \times -3 \times 5 \times 1=-75$$ \## Matrices

#### Operators in RStudio

```{r}
# Summation
mat <- c(5,-3,5,1)
sum(mat)

# Product
prod(mat)
```

### Basics

-   We can append vectors together to form a matrix:

$$\begin{bmatrix}
12 & 14 & 15 \\
115 & 22 & 127 \\
193 & 29 & 219
\end{bmatrix}
= A$$

-   The number of rows and columns of a matrix constitute the dimensions of the matrix.

-   The first number is the number of rows ("r") and the second number is the number of columns ("c") in the matrix.

::: callout-important
Find a way to remember "r x c" *permanently*. The order of the dimensions never changes.
:::

-   Matrix $A$ above, for example, is a $3x3$ matrix.

-   We often use capital letters (sometimes **bold-faced**) to represent matrices.

#### Appending in RStudio

-   We use `rbind()` to create a matrix, in which each vector will be a row.
-   If we use `cbind()`, then each vector will be a column.

```{r}
# Create some vectors
vec_1 <- 1:4
vec_2 <- 5:8
vec_3 <- 9:12
vec_4 <- 13:16

# rbind
rbind_mat <- rbind(vec_1, vec_2, vec_3, vec_4)
rbind_mat

# cbind
cbind_mat <- cbind(vec_1, vec_2, vec_3, vec_4)
cbind_mat
```

### Structure

-   How do we refer to specific elements of the matrix?

-   Matrix $A$ is an $m\times n$ matrix where $m=n=3$

-   More generally, matrix $B$ is an $m\times n$ matrix where the elements look like this: $$B=
    \begin{bmatrix}
    b_{11} & b_{12} & b_{13} & \ldots & b_{1n} \\
    b_{21} & b_{22} & b_{23} & \ldots & b_{2n} \\
    \vdots & \vdots & \vdots & \ldots & \vdots \\
    b_{m1} & b_{m2} & b_{m3} & \ldots & b_{mn}
    \end{bmatrix}$$

-   Thus $b_{23}$ refers to the second unit down and third across.

::: callout-tip
## Reminder

When trying to identify a specific element, the first subscript is the element's row and the second subscript is the element's column (*always* in that order).
:::

#### Constructing matrices in RStudio

-   Matrices are very easy to construct in RStudio.
-   The basic syntax is `matrix(data, nrow, ncol, byrow, dimnames)`.
    -   `data` is the input vector which becomes the data elements of the matrix.
    -   `nrow` is the number of rows to be created.
    -   `ncol` is the number of columns to be created.
    -   `byrow` is a logical clue. If TRUE then the input vector elements are arranged by row.
    -   `dimname` is the names assigned to the rows and columns.
-   Here are some examples:

```{r}
# Elements are arranged sequentially by row.
M <- matrix(c(1:12), nrow = 4, byrow = TRUE)
print(M)

# Elements are arranged sequentially by column.
N <- matrix(c(1:12), nrow = 4, byrow = FALSE)
print(N)

# Define the column and row names.
rownames = c("row1", "row2", "row3", "row4")
colnames = c("col1", "col2", "col3")

P <- matrix(c(1:12), nrow = 4, byrow = TRUE, dimnames = list(rownames, colnames))

print(P)

# Access the element at 1st row and 3rd column.
print(P[1,3])

# Access the element at 4th row and 2nd column.
print(P[4,2])
```

## Matrix operations

### Addition and subtraction

-   Addition and subtraction are straightforward operations.

-   Matrices must have *exactly* the same dimensions for both of these operations.

-   We add or subtract each element with the corresponding element from the other matrix.

-   This is expressed as follows:

$$A \pm B=C$$

$$c_{ij}=a_{ij} \pm b_{ij} \text{ }\forall i,j$$

$$\begin{bmatrix}
a_{11} & a_{12} & a_{13}\\
a_{21} & a_{22} & a_{23}\\
a_{31} & a_{32} & a_{33}
\end{bmatrix}
\pm
\begin{bmatrix}
b_{11} & b_{12} & b_{13}\\
b_{21} & b_{22} & b_{23}\\
b_{31} & b_{32} & b_{33}
\end{bmatrix}$$ $$=$$ $$\begin{bmatrix}
a_{11}\pm b_{11} & a_{12}\pm b_{12} & a_{13}\pm b_{13}\\
a_{21}\pm b_{21} & a_{22}\pm b_{22} & a_{23}\pm b_{23}\\
a_{31}\pm b_{31} & a_{32}\pm b_{32} & a_{33}\pm b_{33}
\end{bmatrix}$$

#### Add and subtract in RStudio

```{r}
# Create two 2x3 matrices.
matrix1 <- matrix(c(3, 9, -1, 4, 2, 6), nrow = 2)
print(matrix1)

matrix2 <- matrix(c(5, 2, 0, 9, 3, 4), nrow = 2)
print(matrix2)

# Add the matrices.
result1 <- matrix1 + matrix2
cat("Result of addition","\n")
print(result1)

# Subtract the matrices
result2 <- matrix1 - matrix2
cat("Result of subtraction","\n")
print(result2)
```

------------------------------------------------------------------------

**Practice**

$$A= \begin{bmatrix}
1 & 4 & 2 \\
-2 & -1 & 0 \\
0 & -1 & 3
\end{bmatrix}$$

$$B = \begin{bmatrix}
5 & 1 & 0 \\
2 & -1 & 0 \\
7 & 1 & 2
\end{bmatrix}$$

Calculate $A+B$

------------------------------------------------------------------------

**Practice**

$$A= \begin{bmatrix}
6 & -2 & 8 & 12 \\
4 & 42 & 8 & -6 \\
-14 & 5 & 0 & 0
\end{bmatrix}$$

$$B = \begin{bmatrix}
18 & 42 & 3 & 7 \\
0 & -42 & 15 & 4 \\
-7 & 0 & 21 & -18
\end{bmatrix}$$

Calculate $A-B$

### Scalar multiplication

-   Scalar multiplication is very intuitive.

-   As we know, a scalar is a single number, or a 1 x 1 matrix.

-   We multiply each value in the matrix by the scalar to perform this operation.

-   This is expressed as follows: $$A = 
    \begin{bmatrix}
    a_{11} & a_{12} & a_{13}\\
    a_{21} & a_{22} & a_{23}\\
    a_{31} & a_{32} & a_{33}
    \end{bmatrix}$$ $$cA = 
    \begin{bmatrix}
    ca_{11} & ca_{12} & ca_{13}\\
    ca_{21} & ca_{22} & ca_{23}\\
    ca_{31} & ca_{32} & ca_{33}
    \end{bmatrix}$$

#### Scalar multiplication in RStudio

-   All we need to do is take an established matrix and multiply it by some scalar.

```{r}
matrix1
matrix1*3
```

------------------------------------------------------------------------

**Practice** $$A= \begin{bmatrix}
    1 & 4 & 2 \\
    8 & -1 & 3 \\
    0 & -2 & 3
    \end{bmatrix}$$ $$ B = \begin{bmatrix}
    -15 & 1 & 5 \\
    2 & -42 & 0 \\
    7 & 1 & 6
    \end{bmatrix}$$

Calculate $2\times A$ and $-3 \times B$

### Matrix multiplication

-   Two matrices must be *conformable* for them to be multiplied together.

-   This means that the number of columns in the first matrix equals the number of rows in the second.

-   When multiplying $A \times B$, if $A$ is $m \times n$, $B$ must have $n$ rows.

::: callout-important
The conformability requirement *never* changes. Before multiplying anything, check to make sure the matrices are indeed conformable.
:::

-   The resulting matrix will have the same number of rows as the first matrix and the number of columns in the second.

-   For example, if $A$ is $i \times k$ and $B$ is $k \times j$, then $A \times B$ will be $i \times j$.

------------------------------------------------------------------------

Which of the following can we multiply? What will be the dimensions of the resulting matrix? $$\begin{aligned}
B=
\begin{bmatrix}
2 \\
3\\
4\\
1
\end{bmatrix}
M = 
\begin{bmatrix}
1 & 0 & 2\\
1 & 2 & 4\\
2 & 3 & 2
\end{bmatrix}
L = 
\begin{bmatrix}
6 & 5 & -1\\
1 & 4 & 3 
\end{bmatrix}
\end{aligned}$$

::: callout-warning
## Warning

When multiplying matrices, *order matters*.
:::

-   Why can't we multiply in the opposite order?

### Multiplication steps

-   Multiply each row by each column, summing up each pair of multiplied terms.

::: callout-note
This is sometimes to referred to as the "dot product," where we multiply matching members, then sum up.
:::

-   The element in position $ij$ is the sum of the products of elements in the $i$th row of the first matrix ($A$) and the corresponding elements in the $j$th column of the second matrix ($B$). $$c_{ij}=\sum_{k=1}^n a_{ik}b_{kj}$$

#### Example

-   Suppose a company manufactures two kinds of furniture: chairs and sofas.

    -   A chair costs \$100 for wood, \$270 for cloth, and \$130 for feathers.

    -   Each sofa costs \$150 for wood, \$420 for cloth, and \$195 for feathers.

|          | Chair | Sofa |
|----------|-------|------|
| Wood     | 100   | 150  |
| Cloth    | 270   | 420  |
| Feathers | 130   | 195  |

-   The same information about unit cost ($C$) can be presented as a matrix.

$$C = \begin{bmatrix}
100 & 150\\
270 & 420\\
130 & 195
\end{bmatrix}$$

::: callout-note
Note that each of the three rows of this 3 x 2 matrix represents a material (wood, cloth, or feathers), and each of the two columns represents a product (chair or coach). The elements are the unit cost (in USD).
:::

------------------------------------------------------------------------

-   Now, suppose that the company will produce 45 chairs and 30 sofas this month.

-   This production quantity can be represented in the following table, and also as a 2 x 1 matrix ($Q$).

| Product | Quantity |
|---------|----------|
| Chair   | 45       |
| Sofa    | 30       |

$$Q = \begin{bmatrix}
45 \\
30 
\end{bmatrix}$$

-   The "total expenditure" is equal to the "unit cost" times the "production quantity" (the number of units).

-   The total expenditure ($E$) for each material this month is calculated by multiplying these two matrices.

$$\begin{aligned} E = CQ =
\begin{bmatrix}
100 & 150\\
270 & 420\\
130 & 195
\end{bmatrix}
\begin{bmatrix}
45 \\
30 
\end{bmatrix} =
\begin{bmatrix}
(100)(45) + (150)(30) \\
(270)(45) + (420)(30) \\
(130)(45) + (195)(30)
\end{bmatrix} =
\begin{bmatrix}
9,000 \\
24,750 \\
11,700
\end{bmatrix}
\end{aligned}$$

-   Multiplying the 3 x 2 Cost matrix ($C$) times the 2 x 1 Quantity matrix ($Q$) yields the 3 x 1 Expenditure matrix ($E$).

-   As a result of this matrix multiplication, we determine that this month the company will incur expenditures of:

    -   \$9,000 for wood
    -   \$24,750 for cloth
    -   \$11,700 for feathers.

#### Matrix multiplication in RStudio

-   We must make sure the matrices are conformable, as we do for our manual calculations.
-   Then, we can multiply them together without issue.
-   When multiplying together matrices in RStudio, remember to use the `%*%` operator, otherwise you will receive an error message.

::: callout-warning
If you have a missing value or `NA` in one of the matrices you are trying to multiply, you will have NAs in your resulting matrix.
:::

```{r}
# Creating matrices
m <- matrix(1:8, nrow=2) # 
n <- matrix(8:15, nrow=4)
m
n

# Multiplying matrices using operator
m%*%n
```

## Properties

-   Addition and subtraction:

    -   Associative: $(A \pm B) \pm C = A \pm (B \pm C)$

    -   Communicative: $A \pm B = B \pm A$

-   Multiplication:

    -   $AB \neq BA$

    -   $A(BC) = (AB)C$

    -   $A(B+C) = AB + AC$

    -   $(A+B)C = AC + BC$

## Special matrices

Square matrix:

-   The **diagonal** of a square matrix is a set of numbers consisting of the elements on the line from the upper-left-hand to the lower-right-hand corner of the matrix. Only a square matrix has a diagonal.

-   The **trace** of a matrix is simply the sum of the diagonal elements of the matrix. So, then, a matrix must be square to have a trace.

Diagonal matrix:

-   In a **diagonal matrix**, all of the elements of the matrix that are not on the diagonal are equal to zero.

Scalar matrix:

-   A **scalar matrix** is a diagonal matrix where the diagonal elements are all equal to each other. In other words, we're really only concerned with one scalar (or element) held in the diagonal.

Identity matrix:

-   The **identity matrix** is a scalar matrix with all of the diagonal elements equal to one.

-   All of the off-diagonal elements are equal to zero.

-   The capital letter I is reserved for the identity matrix.

## Transpose

-   The transpose is the original matrix with the rows and the columns interchanged.

-   The notation is either $J'$ ("J prime") or $J^T$ ("J transpose").

$$J =
\begin{bmatrix}
4 & 5\\
3 & 0\\
7 & -2
\end{bmatrix}$$

$$J' = J^T = 
\begin{bmatrix}
4 & 3 & 7 \\
5 & 0 & -2
\end{bmatrix}$$

#### Transpose in RStudio

-   We use `t()` to get the transpose.

```{r}
# Construct our matrix
J <- matrix(c(4,5,3,0,7,-2), nrow = 3, byrow = TRUE,)
J
t(J)
```

## Inverse

-   Just like a number has a reciprocal, a matrix has an inverse.

-   When we multiply a matrix by its inverse we get the identity matrix (which is like "1" for matrices).

$$A Ã— A^{-1} = I$$

-   The inverse of A is A-1 only when:

$$AA^{-1} = A^{-1}A = I$$

-   Sometimes there is no inverse at all.

::: callout-note
For now, don't worry about calculating the inverse of a matrix manually. This is the type of task we use RStudio for.
:::

#### Examples

-   We use the `solve()` function to calculate the inverse of a matrix.

```{r}
# Create 3 different vectors
# using combine method.
a1 <- c(3, 2, 5)
a2 <- c(2, 3, 2)
a3 <- c(5, 2, 4)
  
# bind the three vectors into a matrix 
# using rbind() which is basically
# row-wise binding.
A <- rbind(a1, a2, a3)
  
# print the original matrix
print(A)
  
# Use the solve() function to calculate the inverse.
T1 <- solve(A)
  
# print the inverse of the matrix
print(T1)
```

## Linear systems and matrices

-   A system of equations can be represented by an *augmented matrix*.

-   System of equations: $${\color{red}{3}}x + {\color{green}{6}}y = {\color{blue}{12}}$$ $${\color{red}{5}}x + {\color{green}{10}}y = {\color{blue}{25}}$$

-   In an augmented matrix, each row represents one equation in the system and each column represents a variable or the constant terms. $$\begin{bmatrix}
    {\color{red}{3}} & {\color{green}{6}} & {\color{blue}{12}}\\
    {\color{red}{5}} & {\color{green}{10}} & {\color{blue}{25}}
    \end{bmatrix}$$

## OLS and matrices

-   We can use the logic above to calculate estimates for our ordinary least squares (OLS) models.

-   OLS is a linear regression technique used to find the best-fitting line for a set of data points (observations) by minimizing the residuals (the differences between the observed and predicted values).

-   We minimize the *sum of the squared errors*.

### Dependent variable

-   Suppose, for example, we have a sample consisting of $n$ observations.

-   The dependent variable is denoted as an $n \times1$ column vector.

$$Y = \begin{bmatrix}
y_1 \\
y_2 \\
y_3 \\
\vdots \\
y_n
\end{bmatrix}$$

### Independent variables

-   Suppose there are $k$ independent variables and a constant term, meaning $k+1$ columns and $n$ rows.

-   We can represent these variables as an $n \times (k+1)$ matrix, expressed as follows:

$$X= \begin{bmatrix}
1 & x_{11} & \dots & x_{1k} \\
1 & x_{21} & \dots & x_{2k} \\
\vdots & \vdots & \dots & \vdots \\
1 & x_{n1} & \dots & x_{nk}
\end{bmatrix}$$

-   $x_{ij}$ is the $i$-th observation of the $j$-th independent variable.

### Linear regression model

-   Let's say we have 173 observations (n = 173) and 2 IVs (k = 3).

-   This can be expressed as the following linear equation: $$y = \beta_0 + \beta_1x_1 + \beta_2x_2 + \epsilon$$

-   In matrix form, we have: $$\begin{aligned} \begin{bmatrix}
    y_1 \\
    y_2 \\
    \vdots \\
    y_n
    \end{bmatrix} = \begin{bmatrix}
    1 & x_{11} & x_{21} \\
    1 & x_{21} & x_{22} \\
    \vdots & \vdots & \vdots \\
    1 & x_{1173} & x_{2173} 
    \end{bmatrix} \begin{bmatrix}
    \beta_0 \\
    \beta_1 \\
    \beta_2 
    \end{bmatrix} + \begin{bmatrix}
    \epsilon_1 \\
    \epsilon_2 \\
    \vdots \\
    \epsilon_{173}
    \end{bmatrix}\end{aligned} $$

-   All 173 equations can be represented by: $$y=X\beta+\epsilon$$

### Estimates

-   Without getting too much into the mechanics, we can calculate our coefficient estimates with matrix algebra using the following equation:

$$\hat{\beta} = (X'X)^{-1}X'Y$$

-   Read aloud, we say "X prime X inverse, X prime Y".

-   The little hat on our beta ($\hat{\beta}$) signifies that these are estimates, that is our OLS estimators.

-   Remember, the OLS method is to choose $\hat{\beta}$ such that the sum of squared residuals ("SSR") is minimized.

#### Example in RStudio

-   We will load the `mtcars` data set (our favorite) for this example, which contains data about many different car models.

```{r}
cars_df <- mtcars
```

-   Now, we want to estimate the association between `hp` (horsepower) and `wt` (weight), our independent variables, and `mpg` (miles per gallon), our dependent variable.

-   First, we transform our dependent variable into a matrix, using the `as.matrix` function and specifying the column of the `mtcars` data set to create a column vector of our observed values for the DV.

```{r}
Y <- as.matrix(cars_df[,1])
Y
```

-   Next, we do the same thing for our independent variables of interest, and our constant.

```{r}
# create two separate matrices for IVs
X1 <- as.matrix(cars_df[,4])
X2 <- as.matrix(cars_df[,6])

# create constant column

# bind them altogether into one matrix
constant <-  rep(1,nrow(X1))
X <- cbind(constant,X1,X2)
X
```

-   Next, we calculate $X'X$, $X'Y$, and $(X'X)^{-1}$.

::: callout-reminder
Don't forget to use `%*%` for matrix multiplication!
:::

```{r}
# X prime X
XpX <- t(X)%*%X

# X prime X inverse
XpXinv <- solve(XpX)

# X prime Y
XpY <- t(X)%*%Y

# beta coefficient estimates
bhat <- XpXinv %*% XpY
bhat
```
